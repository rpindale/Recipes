{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Apple Cranberry Pecan Salad</td>\n",
       "      <td>6 cups baby spinach 1 Granny Smith apple, thi...</td>\n",
       "      <td>To make the vinaigrette, whisk together olive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salad</td>\n",
       "      <td>Asian Pasta Salad</td>\n",
       "      <td>8 ounces elbows pasta 1 California Avocado, h...</td>\n",
       "      <td>To make the dressing, whisk together soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick-easy</td>\n",
       "      <td>Vegetable Kabobs</td>\n",
       "      <td>2 cups cremini mushrooms 1 cup cherry tomatoe...</td>\n",
       "      <td>Preheat oven to 400 degrees F. In a small bow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salad</td>\n",
       "      <td>Harvest Cobb Salad</td>\n",
       "      <td>4 slices bacon, diced 2 large eggs 6 cups cho...</td>\n",
       "      <td>To make the poppy seed dressing, whisk togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicken-recipes</td>\n",
       "      <td>Quick Chicken and Broccoli Stir Fry</td>\n",
       "      <td>1 pound boneless, skinless chicken breasts, c...</td>\n",
       "      <td>In a small bowl, whisk together soy sauce, oy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                title  \\\n",
       "0        appetizer          Apple Cranberry Pecan Salad   \n",
       "1            salad                    Asian Pasta Salad   \n",
       "2       quick-easy                     Vegetable Kabobs   \n",
       "3            salad                   Harvest Cobb Salad   \n",
       "4  chicken-recipes  Quick Chicken and Broccoli Stir Fry   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0   6 cups baby spinach 1 Granny Smith apple, thi...   \n",
       "1   8 ounces elbows pasta 1 California Avocado, h...   \n",
       "2   2 cups cremini mushrooms 1 cup cherry tomatoe...   \n",
       "3   4 slices bacon, diced 2 large eggs 6 cups cho...   \n",
       "4   1 pound boneless, skinless chicken breasts, c...   \n",
       "\n",
       "                                        instructions  \n",
       "0   To make the vinaigrette, whisk together olive...  \n",
       "1   To make the dressing, whisk together soy sauc...  \n",
       "2   Preheat oven to 400 degrees F. In a small bow...  \n",
       "3   To make the poppy seed dressing, whisk togeth...  \n",
       "4   In a small bowl, whisk together soy sauce, oy...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "colin = pd.read_csv('colin_webscrap.csv')\n",
    "colin.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(colin.shape)\n",
    "colin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4479, 4)\n",
      "(1608, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>side</td>\n",
       "      <td>Moroccan Couscous Recipe (with Roasted Veggies)</td>\n",
       "      <td>1  large red bell pepper, (cored and diced) 2 ...</td>\n",
       "      <td>Preheat oven to 475 degrees. Spray a 18 by 13-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>main-dish</td>\n",
       "      <td>Honey Garlic Chicken (Oven Baked)</td>\n",
       "      <td>1 1/2 lbs bonless skinless chicken breasts (, ...</td>\n",
       "      <td>Preheat oven to 400 degrees. Line a rimmed 18 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>main-dish</td>\n",
       "      <td>Best Turkey Chili Recipe</td>\n",
       "      <td>2 Tbsp olive oil 20 oz 93% lean ground turkey ...</td>\n",
       "      <td>Heat 1 Tbsp olive oil in a large pot over medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>bars</td>\n",
       "      <td>Lemon Cream Pie Bars</td>\n",
       "      <td>1 1/2 cups finely crushed graham cracker crumb...</td>\n",
       "      <td>Preheat oven to 350 degrees. Butter an 8 by 8-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>muffins</td>\n",
       "      <td>How to Make Homemade Donuts in 15 Minutes</td>\n",
       "      <td>1 1/4 cups (176g) all-purpose flour ((scoop an...</td>\n",
       "      <td>Pour about 1/2-inch oil into a large saute pan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                            title  \\\n",
       "4001       side  Moroccan Couscous Recipe (with Roasted Veggies)   \n",
       "3029  main-dish                Honey Garlic Chicken (Oven Baked)   \n",
       "2732  main-dish                         Best Turkey Chili Recipe   \n",
       "584        bars                             Lemon Cream Pie Bars   \n",
       "3361    muffins        How to Make Homemade Donuts in 15 Minutes   \n",
       "\n",
       "                                            ingredients  \\\n",
       "4001  1  large red bell pepper, (cored and diced) 2 ...   \n",
       "3029  1 1/2 lbs bonless skinless chicken breasts (, ...   \n",
       "2732  2 Tbsp olive oil 20 oz 93% lean ground turkey ...   \n",
       "584   1 1/2 cups finely crushed graham cracker crumb...   \n",
       "3361  1 1/4 cups (176g) all-purpose flour ((scoop an...   \n",
       "\n",
       "                                           instructions  \n",
       "4001  Preheat oven to 475 degrees. Spray a 18 by 13-...  \n",
       "3029  Preheat oven to 400 degrees. Line a rimmed 18 ...  \n",
       "2732  Heat 1 Tbsp olive oil in a large pot over medi...  \n",
       "584   Preheat oven to 350 degrees. Butter an 8 by 8-...  \n",
       "3361  Pour about 1/2-inch oil into a large saute pan...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan = pd.read_csv('cooking_classy_text_data.csv')\n",
    "ryan.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(ryan.shape)\n",
    "ryan.isna().sum()\n",
    "ryan = ryan.sample(frac=1, random_state=42)\n",
    "#ryan.head()\n",
    "print(ryan.drop_duplicates('title').shape)\n",
    "ryan = ryan.drop_duplicates('title')\n",
    "ryan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ryan = ryan.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicates\n",
    "colin.drop_duplicates('title').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Title</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Gnocchi, Mushroom and Kale Soup</td>\n",
       "      <td>Sauté the veggies. Heat oil in a large stockpo...</td>\n",
       "      <td>2 tablespoons olive oil 1 medium white onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Greek Salmon Salad Bowls</td>\n",
       "      <td>Cook the salmon. Season the salmon with a few ...</td>\n",
       "      <td>1 pound salmon filets fine sea salt and freshl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Pasta alla Boscaiola</td>\n",
       "      <td>Soften the mushrooms. In a medium saucepan, st...</td>\n",
       "      <td>3 cups vegetable broth 1 ounce dried porcini m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Lemony Lentil Soup</td>\n",
       "      <td>Stovetop Instructions:  Sauté the veggies. Hea...</td>\n",
       "      <td>1 tablespoon olive oil 1 medium white onion, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Guinness Beef Stew</td>\n",
       "      <td>Sear the beef. Generously season the beef with...</td>\n",
       "      <td>3 tablespoons olive oil, divided 3 pounds beef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cat                            Title  \\\n",
       "0  main-course  Gnocchi, Mushroom and Kale Soup   \n",
       "1  main-course         Greek Salmon Salad Bowls   \n",
       "2  main-course             Pasta alla Boscaiola   \n",
       "3  main-course               Lemony Lentil Soup   \n",
       "4  main-course               Guinness Beef Stew   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Sauté the veggies. Heat oil in a large stockpo...   \n",
       "1  Cook the salmon. Season the salmon with a few ...   \n",
       "2  Soften the mushrooms. In a medium saucepan, st...   \n",
       "3  Stovetop Instructions:  Sauté the veggies. Hea...   \n",
       "4  Sear the beef. Generously season the beef with...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  2 tablespoons olive oil 1 medium white onion, ...  \n",
       "1  1 pound salmon filets fine sea salt and freshl...  \n",
       "2  3 cups vegetable broth 1 ounce dried porcini m...  \n",
       "3  1 tablespoon olive oil 1 medium white onion, p...  \n",
       "4  3 tablespoons olive oil, divided 3 pounds beef...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = pd.read_csv('GSOScrapped.csv')\n",
    "print(ed.shape)\n",
    "ed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.drop_duplicates('Title').shape\n",
    "ed = ed.drop_duplicates('Title')\n",
    "ed = ed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1362, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'Title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = ed.rename(columns={'Title':'title'})\n",
    "ryan = ryan.rename(columns={'category':'cat'})\n",
    "print(ryan.columns)\n",
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4052, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = colin.append(ed).reset_index().drop('index',axis=1)\n",
    "merged = merged.append(ryan).reset_index().drop('index', axis=1)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>healthy</td>\n",
       "      <td>Mango Salsa {with Avocado!}</td>\n",
       "      <td>2 cups peeled and diced mangoes, ((about 2 sma...</td>\n",
       "      <td>In a medium mixing bowl toss together all ingr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>drinks</td>\n",
       "      <td>Sparkling Limeade with Honey Recipe</td>\n",
       "      <td>1 liter club soda or sparkling water (, chille...</td>\n",
       "      <td>In a pitcher whisk together 1/2 cup water and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>treats</td>\n",
       "      <td>Cookies and Cream Muddy Buddies</td>\n",
       "      <td>6 cups Corn Chex Cereal 1/2 cup very finely cr...</td>\n",
       "      <td>Measure 6 cups Corn Chex Cereal into a large m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>drinks</td>\n",
       "      <td>Brazilian Limeade</td>\n",
       "      <td>4 cups cold water, (divided) 3/4 cup fresh lim...</td>\n",
       "      <td>To a blender jar add 3 cups water, lime juice,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>3-Ingredient Queso Cheese Dip</td>\n",
       "      <td>1 cup half and half 1 Tbsp Argo Corn Starch 8 ...</td>\n",
       "      <td>In a medium saucepan whisk together half and h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cat                                title  \\\n",
       "4047    healthy          Mango Salsa {with Avocado!}   \n",
       "4048     drinks  Sparkling Limeade with Honey Recipe   \n",
       "4049     treats      Cookies and Cream Muddy Buddies   \n",
       "4050     drinks                    Brazilian Limeade   \n",
       "4051  appetizer        3-Ingredient Queso Cheese Dip   \n",
       "\n",
       "                                            ingredients  \\\n",
       "4047  2 cups peeled and diced mangoes, ((about 2 sma...   \n",
       "4048  1 liter club soda or sparkling water (, chille...   \n",
       "4049  6 cups Corn Chex Cereal 1/2 cup very finely cr...   \n",
       "4050  4 cups cold water, (divided) 3/4 cup fresh lim...   \n",
       "4051  1 cup half and half 1 Tbsp Argo Corn Starch 8 ...   \n",
       "\n",
       "                                           instructions  \n",
       "4047  In a medium mixing bowl toss together all ingr...  \n",
       "4048  In a pitcher whisk together 1/2 cup water and ...  \n",
       "4049  Measure 6 cups Corn Chex Cereal into a large m...  \n",
       "4050  To a blender jar add 3 cups water, lime juice,...  \n",
       "4051  In a medium saucepan whisk together half and h...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course           618\n",
       "dessert               498\n",
       "breakfast             259\n",
       "appetizer             194\n",
       "main-dish             194\n",
       "                     ... \n",
       "pizzas                  8\n",
       "holidays/spring         7\n",
       "spreads                 6\n",
       "tarts-and-pastries      5\n",
       "instant-pot             3\n",
       "Name: cat, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course        896\n",
       "dessert            713\n",
       "appetizers         363\n",
       "breakfast          259\n",
       "quick-easy         207\n",
       "holidays           199\n",
       "chicken-recipes    179\n",
       "drinks             156\n",
       "healthy            151\n",
       "pasta              136\n",
       "vegetarian         124\n",
       "asian              109\n",
       "soup               105\n",
       "seasonal            92\n",
       "slow-cooker         76\n",
       "baked-goods         54\n",
       "one-pot             39\n",
       "sauces              37\n",
       "game-day            35\n",
       "seafood             29\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged.cat == 'ice-cream', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'poultry', 'cat'] = 'chicken-recipes'\n",
    "merged.loc[merged.cat == 'instant-pot', 'cat'] = 'slow-cooker'\n",
    "merged.loc[merged.cat == 'italian', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'treats', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'bars', 'cat'] = 'dessert'\n",
    "merged = merged.drop(merged[merged.cat == 'mexican'].index)\n",
    "merged = merged.drop(merged[merged.cat == 'side'].index)\n",
    "merged.loc[merged.cat == 'appetizer', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'pastas', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'bread', 'cat'] = 'baked-goods'\n",
    "merged.loc[merged.cat == 'snacks', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'beverages', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'entree','cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'drink', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'smoothies', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'spreads', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'salsas-sauces', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'dip', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'pizzas', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'sandwiches', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'sandwich', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'fall', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'summer', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'side-dish', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'salad', 'cat'] = 'vegetarian'\n",
    "merged.loc[merged.cat == 'meal-prep', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'thanksgiving', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'christmas', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'instant-pot-recipes', 'cat'] = 'slow-cooker'\n",
    "merged.loc[merged.cat == 'fall-faves', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'cookies', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'holidays/christmas', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'cake', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'meat', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'asian-inspired', 'cat'] = 'asian'\n",
    "merged.loc[merged.cat == 'main-dish', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'tarts-and-pastries'] = 'dessert'\n",
    "merged.loc[merged.cat == 'holidays/spring'] ='holidays'\n",
    "merged.loc[merged.cat == 'holidays/valentines'] ='holidays'\n",
    "merged.loc[merged.cat == 'holidays/halloween'] ='holidays'\n",
    "merged.loc[merged.cat == 'muffins'] ='baked-goods'\n",
    "merged.loc[merged.cat == 'pie-cheesecake'] ='dessert'\n",
    "merged.loc[merged.cat == 'holidays/thanksgiving'] ='holidays'\n",
    "\n",
    "\n",
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course        0.226320\n",
       "dessert            0.180096\n",
       "appetizers         0.091690\n",
       "breakfast          0.065421\n",
       "quick-easy         0.052286\n",
       "holidays           0.050265\n",
       "chicken-recipes    0.045213\n",
       "drinks             0.039404\n",
       "healthy            0.038141\n",
       "pasta              0.034352\n",
       "vegetarian         0.031321\n",
       "asian              0.027532\n",
       "soup               0.026522\n",
       "seasonal           0.023238\n",
       "slow-cooker        0.019197\n",
       "baked-goods        0.013640\n",
       "one-pot            0.009851\n",
       "sauces             0.009346\n",
       "game-day           0.008841\n",
       "seafood            0.007325\n",
       "Name: cat, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.cat.value_counts()/len(merged.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged.cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.cat = pd.Categorical(merged.cat)\n",
    "merged['y'] = merged.cat.cat.codes\n",
    "merged.y = [np.int64(x) for x in merged.y]\n",
    "merged.y = pd.Series(merged.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =merged.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3959,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.hstack(merged['title'] + merged['ingredients']+ merged['instructions'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 7061)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import one_hot , Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "ttrain, ttest, ingtrain, ingtest, insttrain, insttest, y1train, y1test = train_test_split(merged.title, merged.ingredients, \n",
    "                                                                                        merged.instructions, merged.cat, test_size=.3, \n",
    "                                                                                        random_state = 420)\n",
    "count = CountVectorizer()\n",
    "xtraincounts = count.fit_transform(xtrain)\n",
    "xtraincounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(xtraincounts, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36423833726430066"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testvector = count.transform(xtest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030101367351615615"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraincounts = count.fit_transform(ttrain)\n",
    "clf = MultinomialNB().fit(xtraincounts, ytrain)\n",
    "testvector = count.transform(ttest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03468213915648437"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraincounts = count.fit_transform(ingtrain)\n",
    "clf = MultinomialNB().fit(xtraincounts, ytrain)\n",
    "testvector = count.transform(ingtest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03532390832786299"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraincounts = count.fit_transform(insttrain)\n",
    "clf = MultinomialNB().fit(xtraincounts, ytrain)\n",
    "testvector = count.transform(insttest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeitup = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3370574200484416"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeitup.fit(xtrain, ytrain)\n",
    "predicted=pipeitup.predict(xtest)\n",
    "metrics.f1_score(ytest, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "textclf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l1',\n",
    "                         alpha=1e-3, random_state=420,\n",
    "                         max_iter=5, tol=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3370574200484416"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textclf.fit(xtrain, ytrain)\n",
    "predict = textclf.predict(xtest)\n",
    "metrics.f1_score(ytest, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4224085760409363"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeitupagain = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC(C=4, random_state=420))\n",
    "])\n",
    "\n",
    "pipeitupagain.fit(xtrain,ytrain)\n",
    "predict = pipeitupagain.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4390843800812082"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeitupagain = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC(random_state=420, tol=1e-5))\n",
    "])\n",
    "\n",
    "pipeitupagain.fit(xtrain,ytrain)\n",
    "predict = pipeitupagain.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting LInear SVC and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4189517394295968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "c1 = LinearSVC(random_state=420, tol=1e-5)\n",
    "c2 = SVC(C=4, random_state=420)\n",
    "vote = VotingClassifier(estimators=[('1',c1), ('2',c2)],\n",
    "                       voting = 'hard')\n",
    "pipeitupagain = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', vote)\n",
    "])\n",
    "\n",
    "pipeitupagain.fit(xtrain,ytrain)\n",
    "predict = pipeitupagain.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42893254932183844"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = BaggingClassifier(base_estimator=LinearSVC(random_state=420, tol=1e-5),\n",
    "                       n_estimators=100, random_state=420)\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', bag)\n",
    "])\n",
    "pipe.fit(xtrain, ytrain)\n",
    "predict = pipe.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4279478859111562"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', xgboost.XGBClassifier(objective='multi:softprob',\n",
    "                                max_depth=3, n_estimators=700))\n",
    "])\n",
    "pipe.fit(xtrain, ytrain)\n",
    "predict = pipe.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2843, 152, 559, 316, 1, 449, 1204, 54, 53, 23, 240, 2, 262, 578, 316, 2477, 152, 69, 143, 1, 62, 5, 30, 251, 143, 1, 62, 102, 108, 35, 143, 1, 95, 71, 38, 25, 241, 5, 147, 181, 569, 5180, 5181, 12, 1345, 1625, 5, 719, 46, 342, 5, 719, 46, 187, 12, 366, 149, 317, 2478, 387, 2, 1133, 4067, 12, 2844, 449, 556, 48, 8, 1626, 953, 672, 311, 17, 1, 61, 457, 63, 21, 61, 208, 126, 2140, 2, 2638, 7, 6, 27, 350, 39, 30, 72, 20, 56, 18, 316, 1, 295, 16, 57, 15, 89, 1, 860, 146, 9, 239, 5182, 6, 861, 265, 4, 105, 3, 316, 4, 6, 322, 278, 1, 59, 85, 56, 651, 333, 106, 604, 18, 3, 106, 23, 4, 3, 350, 56, 18, 69, 1, 632, 1, 295, 16, 360, 15, 89, 146, 9, 3, 69, 55, 451, 1, 633, 56, 40, 7, 3, 35, 1, 295, 16, 2, 5, 98, 15, 89, 394, 9, 401, 18, 7, 3, 25, 241, 152, 247, 1068, 1, 121, 316, 1, 40, 9, 79, 56, 306, 159, 9, 3, 269, 400, 6, 173, 40, 2479, 449, 140, 1, 49, 16, 57, 15, 12, 9, 3, 449, 215, 270, 6, 617, 47, 1, 75, 8, 6, 318, 750, 990, 13, 17, 1, 21, 122, 182, 44, 134, 217, 8, 801, 13, 126, 41, 56, 12, 105, 4, 6, 522, 250, 739, 1, 335, 16, 141, 4, 14, 509, 12, 538, 16, 141, 4, 14, 807]\n",
      "787\n"
     ]
    }
   ],
   "source": [
    "## To DO: tokenize using keras tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(xtrain)\n",
    "vocabsize = len(t.word_index) + 1\n",
    "encoded = t.texts_to_sequences(xtrain)\n",
    "tencoded = t.texts_to_sequences(ttrain)\n",
    "ingencoded = t.texts_to_sequences(str(ingtrain))\n",
    "instencoded = t.texts_to_sequences([str(x) for x in insttrain])\n",
    "encodedtest = t.texts_to_sequences(xtest)\n",
    "print(encoded[1])\n",
    "\n",
    "maxlength = max([len(x) for x in encoded])\n",
    "print(maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_glove():\n",
    "    embeddings_index = dict()\n",
    "    f = open('./glove.6B.100d.txt') # replace this with the path to your downloaded txt file\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    # create a weight matrix for words in training docs\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "[  76  559  331 3130   38  354   87  240    5   38  212   45    5   14\n",
      "   10  177   32    5   26  230  233  375    2   76  559    5    2    5\n",
      "   26  275    2   11   10  287 4065    6   83  111   28   65   60    2\n",
      "   11   10   87    8    3  275    9  189   59   85    7    6   30  243\n",
      "   92  106    2   14   11   10   87    3   45   32  233  375   76  559\n",
      "  264    1   76  559 4066  237   31  117    4    6  195   39   30   72\n",
      "   20   89  394    4 1445   32  192   58  400    6  195   65  275   31\n",
      "  192   98    1  235  444   87   31    7  243  481  110  275   31   22\n",
      "  243  214   20  180  235   89  376  283   31    4 1284    1   49   19\n",
      "    2    5   15  268    9  215  415    1   58 1564    3  594   13    6\n",
      "  612  265   77   67   20    1   65    7  287   45  110   22    6   20\n",
      "  848   28  140   31    8 1371  164  686 1285 1098    3  428   13    3\n",
      "   31    4  930    6  589   67 1372    1  335    9  494  133  445 1016\n",
      "  145  524  576 2047   16  169   15   33   89 3131  273 2048   58    7\n",
      "    3  331   45 1393 2637  104  344    6 1446 5179 2840  203   58 2841\n",
      "    3  331   45    6 1394 1660    1 2841    3  331   45 1393    6  744\n",
      " 1079  541   31    7   64  331   45 1393  308    4 1991  391  105   31\n",
      "    4   64  397  250    1  538    9  586   42  154  621   55  122  472\n",
      "  122  959  119   58  338  100  225 1447  577   15  273  207   16 2842\n",
      " 1305   58  406  236  703  451    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.initializers import Constant\n",
    "import math\n",
    "# to Do: add constants that you might need here\n",
    "n_classes=20\n",
    "embeddingdim = 100\n",
    "\n",
    "word_index=t.word_index\n",
    "\n",
    "embeddings_index = load_glove()\n",
    "embedding_matrix = np.random.random((len(word_index)+1, embeddingdim))\n",
    "for word, i in word_index.items():\n",
    "    embeddingvector = embeddings_index.get(word)\n",
    "    if embeddingvector is not None:\n",
    "        if len(embedding_matrix[i]) != len(embeddingvector):\n",
    "            print('could not be broadcast input array from shape ', str(len(embedding_matrix[i])),\n",
    "                 ' into shape ', str(len(embeddingvector)), ' Please make sure your embedding dim is equal to embedding vector file Glove')\n",
    "            exit(1)\n",
    "        \n",
    "        embedding_matrix[i] = embeddingvector\n",
    "        \n",
    "\n",
    "###To Do:  pad the train and test data \n",
    "padded = pad_sequences(encoded, maxlen=maxlength, padding='post')\n",
    "tpadded = pad_sequences(tencoded, maxlen=maxlength, padding='post')\n",
    "ingpadded = pad_sequences(ingencoded, maxlen=maxlength, padding='post')\n",
    "instpadded = pad_sequences(instencoded, maxlen=maxlength, padding='post')\n",
    "paddedtest = pad_sequences(encodedtest, maxlen=maxlength, padding='post')\n",
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 787)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 787, 100)     920500      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 787, 100)     0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 787, 32)      9632        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 787, 24)      9624        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 787, 64)      32064       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 787, 120)     0           ['conv1d_5[0][0]',               \n",
      "                                                                  'conv1d_6[0][0]',               \n",
      "                                                                  'conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 157, 120)    0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 157, 120)     0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 155, 128)     46208       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 19, 128)     0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 15, 256)      164096      ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 1, 256)      0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 20)           1300        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,224,576\n",
      "Trainable params: 1,224,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(8)(x)\n",
    "x = Conv1D(256, 5, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(10)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "#x = Dense(32, activation = 'softplus')(x)\n",
    "#x = Dropout(.2)(x)\n",
    "preds = Dense(20, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=.0003, decay=.00008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 5s 39ms/step - loss: 2.8722 - accuracy: 0.1779 - val_loss: 2.6304 - val_accuracy: 0.2062\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 2.6472 - accuracy: 0.2086 - val_loss: 2.5349 - val_accuracy: 0.2441\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 2.5546 - accuracy: 0.2476 - val_loss: 2.4063 - val_accuracy: 0.3611\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 2.3608 - accuracy: 0.3475 - val_loss: 2.2213 - val_accuracy: 0.3763\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 2.2125 - accuracy: 0.3908 - val_loss: 2.1007 - val_accuracy: 0.3939\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 2.1364 - accuracy: 0.4024 - val_loss: 2.0849 - val_accuracy: 0.4141\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 2.0781 - accuracy: 0.4154 - val_loss: 2.0118 - val_accuracy: 0.4091\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 2.0330 - accuracy: 0.4230 - val_loss: 2.0476 - val_accuracy: 0.4150\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.9852 - accuracy: 0.4284 - val_loss: 1.9438 - val_accuracy: 0.4360\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.9670 - accuracy: 0.4374 - val_loss: 1.9018 - val_accuracy: 0.4512\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.9202 - accuracy: 0.4432 - val_loss: 1.8456 - val_accuracy: 0.4478\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.8850 - accuracy: 0.4515 - val_loss: 1.8697 - val_accuracy: 0.4411\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.8250 - accuracy: 0.4746 - val_loss: 1.8514 - val_accuracy: 0.4545\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.8158 - accuracy: 0.4724 - val_loss: 1.8619 - val_accuracy: 0.4369\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.7892 - accuracy: 0.4709 - val_loss: 1.7747 - val_accuracy: 0.4655\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.7692 - accuracy: 0.4720 - val_loss: 1.7602 - val_accuracy: 0.4630\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.7230 - accuracy: 0.4937 - val_loss: 1.7198 - val_accuracy: 0.4714\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.6952 - accuracy: 0.4908 - val_loss: 1.7643 - val_accuracy: 0.4672\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.6808 - accuracy: 0.5002 - val_loss: 1.7332 - val_accuracy: 0.4790\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 1.6575 - accuracy: 0.4980 - val_loss: 1.7176 - val_accuracy: 0.4781\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.6329 - accuracy: 0.5031 - val_loss: 1.7116 - val_accuracy: 0.4756\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.6292 - accuracy: 0.5114 - val_loss: 1.6631 - val_accuracy: 0.4907\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.5961 - accuracy: 0.5204 - val_loss: 1.6514 - val_accuracy: 0.4924\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.5853 - accuracy: 0.5204 - val_loss: 1.6605 - val_accuracy: 0.4975\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.5537 - accuracy: 0.5200 - val_loss: 1.6344 - val_accuracy: 0.5051\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.5481 - accuracy: 0.5189 - val_loss: 1.6448 - val_accuracy: 0.5118\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.5073 - accuracy: 0.5355 - val_loss: 1.6261 - val_accuracy: 0.4924\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.4923 - accuracy: 0.5413 - val_loss: 1.6791 - val_accuracy: 0.4924\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.4925 - accuracy: 0.5464 - val_loss: 1.6322 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.4615 - accuracy: 0.5547 - val_loss: 1.6028 - val_accuracy: 0.5042\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.4584 - accuracy: 0.5475 - val_loss: 1.6000 - val_accuracy: 0.5135\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.4112 - accuracy: 0.5572 - val_loss: 1.6262 - val_accuracy: 0.4975\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 1.4016 - accuracy: 0.5583 - val_loss: 1.5818 - val_accuracy: 0.5067\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.3906 - accuracy: 0.5543 - val_loss: 1.5956 - val_accuracy: 0.5059\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.3599 - accuracy: 0.5727 - val_loss: 1.5696 - val_accuracy: 0.5126\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.3438 - accuracy: 0.5789 - val_loss: 1.5772 - val_accuracy: 0.5118\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.3547 - accuracy: 0.5752 - val_loss: 1.5802 - val_accuracy: 0.5168\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 1.3211 - accuracy: 0.5734 - val_loss: 1.5812 - val_accuracy: 0.5034\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 1.3159 - accuracy: 0.5817 - val_loss: 1.5884 - val_accuracy: 0.5059\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.2830 - accuracy: 0.5929 - val_loss: 1.5801 - val_accuracy: 0.5143\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 1.2718 - accuracy: 0.5929 - val_loss: 1.5960 - val_accuracy: 0.5118\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.2440 - accuracy: 0.5955 - val_loss: 1.6343 - val_accuracy: 0.5101\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.2486 - accuracy: 0.5994 - val_loss: 1.6406 - val_accuracy: 0.5008\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.2168 - accuracy: 0.6030 - val_loss: 1.6154 - val_accuracy: 0.5143\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.1946 - accuracy: 0.6099 - val_loss: 1.5659 - val_accuracy: 0.5076\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.1771 - accuracy: 0.6131 - val_loss: 1.6311 - val_accuracy: 0.5059\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.1552 - accuracy: 0.6204 - val_loss: 1.6382 - val_accuracy: 0.5067\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.1270 - accuracy: 0.6261 - val_loss: 1.5823 - val_accuracy: 0.5303\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.1329 - accuracy: 0.6189 - val_loss: 1.6802 - val_accuracy: 0.5084\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.0993 - accuracy: 0.6333 - val_loss: 1.6181 - val_accuracy: 0.5202\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.1033 - accuracy: 0.6326 - val_loss: 1.6374 - val_accuracy: 0.5135\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.0577 - accuracy: 0.6420 - val_loss: 1.6141 - val_accuracy: 0.5067\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 1.0786 - accuracy: 0.6460 - val_loss: 1.7102 - val_accuracy: 0.4933\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.0042 - accuracy: 0.6637 - val_loss: 1.6633 - val_accuracy: 0.5067\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 1.0218 - accuracy: 0.6564 - val_loss: 1.8942 - val_accuracy: 0.4958\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.9966 - accuracy: 0.6651 - val_loss: 1.6562 - val_accuracy: 0.5236\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 0.9578 - accuracy: 0.6774 - val_loss: 1.7028 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 0.9321 - accuracy: 0.6904 - val_loss: 1.6309 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 0.9215 - accuracy: 0.6810 - val_loss: 1.6970 - val_accuracy: 0.5084\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 3s 32ms/step - loss: 0.9271 - accuracy: 0.6803 - val_loss: 1.6988 - val_accuracy: 0.5236\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.9074 - accuracy: 0.6972 - val_loss: 1.7908 - val_accuracy: 0.4874\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.8812 - accuracy: 0.6940 - val_loss: 1.7356 - val_accuracy: 0.5135\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.8903 - accuracy: 0.6929 - val_loss: 1.7123 - val_accuracy: 0.5126\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.8263 - accuracy: 0.7178 - val_loss: 1.7522 - val_accuracy: 0.5101\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.8374 - accuracy: 0.7135 - val_loss: 1.8196 - val_accuracy: 0.5143\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.8181 - accuracy: 0.7178 - val_loss: 1.7610 - val_accuracy: 0.5093\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.8163 - accuracy: 0.7174 - val_loss: 1.8409 - val_accuracy: 0.5051\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.7721 - accuracy: 0.7366 - val_loss: 1.7808 - val_accuracy: 0.5025\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.7697 - accuracy: 0.7337 - val_loss: 1.8326 - val_accuracy: 0.4949\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.7412 - accuracy: 0.7420 - val_loss: 1.7652 - val_accuracy: 0.5051\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.7513 - accuracy: 0.7394 - val_loss: 1.7723 - val_accuracy: 0.5025\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.7365 - accuracy: 0.7456 - val_loss: 1.8517 - val_accuracy: 0.5093\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.7045 - accuracy: 0.7589 - val_loss: 1.8542 - val_accuracy: 0.5101\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.6720 - accuracy: 0.7705 - val_loss: 1.9373 - val_accuracy: 0.5109\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.6933 - accuracy: 0.7600 - val_loss: 1.8193 - val_accuracy: 0.5093\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.6440 - accuracy: 0.7817 - val_loss: 1.9752 - val_accuracy: 0.5227\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.6562 - accuracy: 0.7827 - val_loss: 1.9737 - val_accuracy: 0.4832\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.6254 - accuracy: 0.7900 - val_loss: 1.9321 - val_accuracy: 0.4958\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.6089 - accuracy: 0.7932 - val_loss: 1.9034 - val_accuracy: 0.4975\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.6123 - accuracy: 0.7903 - val_loss: 1.9975 - val_accuracy: 0.4949\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.5750 - accuracy: 0.7972 - val_loss: 2.1477 - val_accuracy: 0.5017\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.5763 - accuracy: 0.7997 - val_loss: 2.2518 - val_accuracy: 0.4680\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.5530 - accuracy: 0.8138 - val_loss: 2.2973 - val_accuracy: 0.4941\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.5487 - accuracy: 0.8058 - val_loss: 2.1804 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.5199 - accuracy: 0.8192 - val_loss: 2.2529 - val_accuracy: 0.4630\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.5285 - accuracy: 0.8170 - val_loss: 2.0984 - val_accuracy: 0.4966\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.5049 - accuracy: 0.8293 - val_loss: 2.1829 - val_accuracy: 0.5076\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.4992 - accuracy: 0.8246 - val_loss: 2.1907 - val_accuracy: 0.5152\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.4565 - accuracy: 0.8401 - val_loss: 2.4284 - val_accuracy: 0.5152\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.4783 - accuracy: 0.8329 - val_loss: 2.3684 - val_accuracy: 0.4764\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.4522 - accuracy: 0.8481 - val_loss: 2.2660 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.4482 - accuracy: 0.8419 - val_loss: 2.4006 - val_accuracy: 0.4731\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.4321 - accuracy: 0.8535 - val_loss: 2.3273 - val_accuracy: 0.4907\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.4191 - accuracy: 0.8517 - val_loss: 2.5424 - val_accuracy: 0.4899\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.4048 - accuracy: 0.8542 - val_loss: 2.4789 - val_accuracy: 0.5210\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.3842 - accuracy: 0.8625 - val_loss: 2.5716 - val_accuracy: 0.4941\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.3811 - accuracy: 0.8676 - val_loss: 2.4285 - val_accuracy: 0.4840\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.3921 - accuracy: 0.8661 - val_loss: 2.4405 - val_accuracy: 0.5143\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 3s 34ms/step - loss: 0.3831 - accuracy: 0.8672 - val_loss: 2.5882 - val_accuracy: 0.5034\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 3s 33ms/step - loss: 0.3753 - accuracy: 0.8719 - val_loss: 2.7065 - val_accuracy: 0.4865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbddeebae80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 4s 65ms/step - loss: 2.8193 - sparse_top_k_categorical_accuracy: 0.4078 - val_loss: 2.6116 - val_sparse_top_k_categorical_accuracy: 0.4571\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 2.6643 - sparse_top_k_categorical_accuracy: 0.4493 - val_loss: 2.5692 - val_sparse_top_k_categorical_accuracy: 0.4924\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 2.5955 - sparse_top_k_categorical_accuracy: 0.4681 - val_loss: 2.5433 - val_sparse_top_k_categorical_accuracy: 0.5034\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 2.5480 - sparse_top_k_categorical_accuracy: 0.4915 - val_loss: 2.5022 - val_sparse_top_k_categorical_accuracy: 0.4916\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 2.4703 - sparse_top_k_categorical_accuracy: 0.5125 - val_loss: 2.3758 - val_sparse_top_k_categorical_accuracy: 0.5295\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 2.3760 - sparse_top_k_categorical_accuracy: 0.5402 - val_loss: 2.2763 - val_sparse_top_k_categorical_accuracy: 0.5875\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 2.2469 - sparse_top_k_categorical_accuracy: 0.5695 - val_loss: 2.1964 - val_sparse_top_k_categorical_accuracy: 0.5833\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 2.1564 - sparse_top_k_categorical_accuracy: 0.6012 - val_loss: 2.0716 - val_sparse_top_k_categorical_accuracy: 0.6355\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 2.1083 - sparse_top_k_categorical_accuracy: 0.6131 - val_loss: 2.0353 - val_sparse_top_k_categorical_accuracy: 0.6414\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 2.0774 - sparse_top_k_categorical_accuracy: 0.6171 - val_loss: 1.9957 - val_sparse_top_k_categorical_accuracy: 0.6540\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 2.0186 - sparse_top_k_categorical_accuracy: 0.6193 - val_loss: 2.0548 - val_sparse_top_k_categorical_accuracy: 0.6330\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.9864 - sparse_top_k_categorical_accuracy: 0.6348 - val_loss: 1.9453 - val_sparse_top_k_categorical_accuracy: 0.6633\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.9754 - sparse_top_k_categorical_accuracy: 0.6427 - val_loss: 1.9253 - val_sparse_top_k_categorical_accuracy: 0.6726\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.9252 - sparse_top_k_categorical_accuracy: 0.6424 - val_loss: 1.9310 - val_sparse_top_k_categorical_accuracy: 0.6692\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.9150 - sparse_top_k_categorical_accuracy: 0.6525 - val_loss: 1.9601 - val_sparse_top_k_categorical_accuracy: 0.6591\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.8807 - sparse_top_k_categorical_accuracy: 0.6561 - val_loss: 1.8700 - val_sparse_top_k_categorical_accuracy: 0.6911\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.8595 - sparse_top_k_categorical_accuracy: 0.6669 - val_loss: 1.9055 - val_sparse_top_k_categorical_accuracy: 0.6709\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.8374 - sparse_top_k_categorical_accuracy: 0.6752 - val_loss: 1.8311 - val_sparse_top_k_categorical_accuracy: 0.6911\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.8084 - sparse_top_k_categorical_accuracy: 0.6756 - val_loss: 1.7934 - val_sparse_top_k_categorical_accuracy: 0.7062\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.7862 - sparse_top_k_categorical_accuracy: 0.6698 - val_loss: 1.7995 - val_sparse_top_k_categorical_accuracy: 0.7062\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.7641 - sparse_top_k_categorical_accuracy: 0.6900 - val_loss: 1.8221 - val_sparse_top_k_categorical_accuracy: 0.7121\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.7448 - sparse_top_k_categorical_accuracy: 0.6918 - val_loss: 1.8469 - val_sparse_top_k_categorical_accuracy: 0.7096\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.7377 - sparse_top_k_categorical_accuracy: 0.6943 - val_loss: 1.7531 - val_sparse_top_k_categorical_accuracy: 0.7264\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.7233 - sparse_top_k_categorical_accuracy: 0.6918 - val_loss: 1.8596 - val_sparse_top_k_categorical_accuracy: 0.6843\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.7210 - sparse_top_k_categorical_accuracy: 0.6983 - val_loss: 1.7503 - val_sparse_top_k_categorical_accuracy: 0.7264\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.6793 - sparse_top_k_categorical_accuracy: 0.7214 - val_loss: 1.8202 - val_sparse_top_k_categorical_accuracy: 0.6911\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.6508 - sparse_top_k_categorical_accuracy: 0.7120 - val_loss: 1.7577 - val_sparse_top_k_categorical_accuracy: 0.7197\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.6517 - sparse_top_k_categorical_accuracy: 0.7099 - val_loss: 1.7185 - val_sparse_top_k_categorical_accuracy: 0.7214\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.6405 - sparse_top_k_categorical_accuracy: 0.7268 - val_loss: 1.7023 - val_sparse_top_k_categorical_accuracy: 0.7433\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.6207 - sparse_top_k_categorical_accuracy: 0.7275 - val_loss: 1.7320 - val_sparse_top_k_categorical_accuracy: 0.7399\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.6133 - sparse_top_k_categorical_accuracy: 0.7326 - val_loss: 1.8863 - val_sparse_top_k_categorical_accuracy: 0.7062\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.6263 - sparse_top_k_categorical_accuracy: 0.7246 - val_loss: 1.7024 - val_sparse_top_k_categorical_accuracy: 0.7357\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.5748 - sparse_top_k_categorical_accuracy: 0.7391 - val_loss: 1.6718 - val_sparse_top_k_categorical_accuracy: 0.7424\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.5687 - sparse_top_k_categorical_accuracy: 0.7394 - val_loss: 1.6635 - val_sparse_top_k_categorical_accuracy: 0.7315\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.5532 - sparse_top_k_categorical_accuracy: 0.7311 - val_loss: 1.6405 - val_sparse_top_k_categorical_accuracy: 0.7567\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.5353 - sparse_top_k_categorical_accuracy: 0.7416 - val_loss: 1.6355 - val_sparse_top_k_categorical_accuracy: 0.7475\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.5392 - sparse_top_k_categorical_accuracy: 0.7438 - val_loss: 1.6384 - val_sparse_top_k_categorical_accuracy: 0.7609\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.5171 - sparse_top_k_categorical_accuracy: 0.7438 - val_loss: 1.6256 - val_sparse_top_k_categorical_accuracy: 0.7551\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.4841 - sparse_top_k_categorical_accuracy: 0.7539 - val_loss: 1.6378 - val_sparse_top_k_categorical_accuracy: 0.7618\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.4873 - sparse_top_k_categorical_accuracy: 0.7589 - val_loss: 1.6402 - val_sparse_top_k_categorical_accuracy: 0.7635\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.4858 - sparse_top_k_categorical_accuracy: 0.7535 - val_loss: 1.6500 - val_sparse_top_k_categorical_accuracy: 0.7315\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.4719 - sparse_top_k_categorical_accuracy: 0.7593 - val_loss: 1.7294 - val_sparse_top_k_categorical_accuracy: 0.7365\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.4392 - sparse_top_k_categorical_accuracy: 0.7730 - val_loss: 1.6432 - val_sparse_top_k_categorical_accuracy: 0.7340\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.4304 - sparse_top_k_categorical_accuracy: 0.7744 - val_loss: 1.6012 - val_sparse_top_k_categorical_accuracy: 0.7635\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.4341 - sparse_top_k_categorical_accuracy: 0.7791 - val_loss: 1.6765 - val_sparse_top_k_categorical_accuracy: 0.7264\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.3982 - sparse_top_k_categorical_accuracy: 0.7842 - val_loss: 1.7020 - val_sparse_top_k_categorical_accuracy: 0.7281\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.3843 - sparse_top_k_categorical_accuracy: 0.7799 - val_loss: 1.6226 - val_sparse_top_k_categorical_accuracy: 0.7391\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.3883 - sparse_top_k_categorical_accuracy: 0.7813 - val_loss: 1.5689 - val_sparse_top_k_categorical_accuracy: 0.7643\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.3712 - sparse_top_k_categorical_accuracy: 0.7925 - val_loss: 1.6145 - val_sparse_top_k_categorical_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 1.3441 - sparse_top_k_categorical_accuracy: 0.7965 - val_loss: 1.6134 - val_sparse_top_k_categorical_accuracy: 0.7576\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.3778 - sparse_top_k_categorical_accuracy: 0.7846 - val_loss: 1.5573 - val_sparse_top_k_categorical_accuracy: 0.7710\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.3270 - sparse_top_k_categorical_accuracy: 0.8015 - val_loss: 1.5718 - val_sparse_top_k_categorical_accuracy: 0.7719\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.3244 - sparse_top_k_categorical_accuracy: 0.8012 - val_loss: 1.5849 - val_sparse_top_k_categorical_accuracy: 0.7761\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.3310 - sparse_top_k_categorical_accuracy: 0.8037 - val_loss: 1.5483 - val_sparse_top_k_categorical_accuracy: 0.7677\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.3019 - sparse_top_k_categorical_accuracy: 0.8058 - val_loss: 1.5870 - val_sparse_top_k_categorical_accuracy: 0.7559\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.2810 - sparse_top_k_categorical_accuracy: 0.8149 - val_loss: 1.6943 - val_sparse_top_k_categorical_accuracy: 0.7542\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2771 - sparse_top_k_categorical_accuracy: 0.8131 - val_loss: 1.6789 - val_sparse_top_k_categorical_accuracy: 0.7264\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.2632 - sparse_top_k_categorical_accuracy: 0.8188 - val_loss: 1.6525 - val_sparse_top_k_categorical_accuracy: 0.7635\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.2550 - sparse_top_k_categorical_accuracy: 0.8167 - val_loss: 1.5644 - val_sparse_top_k_categorical_accuracy: 0.7761\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.2472 - sparse_top_k_categorical_accuracy: 0.8156 - val_loss: 1.5841 - val_sparse_top_k_categorical_accuracy: 0.7609\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.2222 - sparse_top_k_categorical_accuracy: 0.8300 - val_loss: 1.6201 - val_sparse_top_k_categorical_accuracy: 0.7694\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.2105 - sparse_top_k_categorical_accuracy: 0.8297 - val_loss: 1.6826 - val_sparse_top_k_categorical_accuracy: 0.7525\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 1.1935 - sparse_top_k_categorical_accuracy: 0.8300 - val_loss: 1.6051 - val_sparse_top_k_categorical_accuracy: 0.7677\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.1775 - sparse_top_k_categorical_accuracy: 0.8390 - val_loss: 1.6562 - val_sparse_top_k_categorical_accuracy: 0.7727\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.1807 - sparse_top_k_categorical_accuracy: 0.8398 - val_loss: 1.6835 - val_sparse_top_k_categorical_accuracy: 0.7576\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.1840 - sparse_top_k_categorical_accuracy: 0.8427 - val_loss: 1.7065 - val_sparse_top_k_categorical_accuracy: 0.7534\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.1622 - sparse_top_k_categorical_accuracy: 0.8372 - val_loss: 1.7499 - val_sparse_top_k_categorical_accuracy: 0.7542\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.1473 - sparse_top_k_categorical_accuracy: 0.8412 - val_loss: 1.7070 - val_sparse_top_k_categorical_accuracy: 0.7567\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.1341 - sparse_top_k_categorical_accuracy: 0.8517 - val_loss: 1.6583 - val_sparse_top_k_categorical_accuracy: 0.7525\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.0988 - sparse_top_k_categorical_accuracy: 0.8535 - val_loss: 1.6607 - val_sparse_top_k_categorical_accuracy: 0.7601\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.0804 - sparse_top_k_categorical_accuracy: 0.8528 - val_loss: 1.7239 - val_sparse_top_k_categorical_accuracy: 0.7694\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.0831 - sparse_top_k_categorical_accuracy: 0.8596 - val_loss: 1.8098 - val_sparse_top_k_categorical_accuracy: 0.7332\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.0891 - sparse_top_k_categorical_accuracy: 0.8629 - val_loss: 1.6760 - val_sparse_top_k_categorical_accuracy: 0.7635\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.0400 - sparse_top_k_categorical_accuracy: 0.8715 - val_loss: 1.6629 - val_sparse_top_k_categorical_accuracy: 0.7727\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.0294 - sparse_top_k_categorical_accuracy: 0.8787 - val_loss: 1.6998 - val_sparse_top_k_categorical_accuracy: 0.7626\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.0317 - sparse_top_k_categorical_accuracy: 0.8701 - val_loss: 1.7588 - val_sparse_top_k_categorical_accuracy: 0.7576\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.0133 - sparse_top_k_categorical_accuracy: 0.8697 - val_loss: 1.6856 - val_sparse_top_k_categorical_accuracy: 0.7517\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.0078 - sparse_top_k_categorical_accuracy: 0.8842 - val_loss: 1.6238 - val_sparse_top_k_categorical_accuracy: 0.7736\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.9886 - sparse_top_k_categorical_accuracy: 0.8722 - val_loss: 1.6639 - val_sparse_top_k_categorical_accuracy: 0.7694\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.9864 - sparse_top_k_categorical_accuracy: 0.8816 - val_loss: 1.7520 - val_sparse_top_k_categorical_accuracy: 0.7593\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.9809 - sparse_top_k_categorical_accuracy: 0.8827 - val_loss: 1.6973 - val_sparse_top_k_categorical_accuracy: 0.7534\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.9319 - sparse_top_k_categorical_accuracy: 0.8925 - val_loss: 1.6858 - val_sparse_top_k_categorical_accuracy: 0.7677\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.9292 - sparse_top_k_categorical_accuracy: 0.8946 - val_loss: 1.6214 - val_sparse_top_k_categorical_accuracy: 0.7702\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.9120 - sparse_top_k_categorical_accuracy: 0.8979 - val_loss: 1.6939 - val_sparse_top_k_categorical_accuracy: 0.7668\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.8903 - sparse_top_k_categorical_accuracy: 0.9044 - val_loss: 1.7521 - val_sparse_top_k_categorical_accuracy: 0.7719\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.8986 - sparse_top_k_categorical_accuracy: 0.8990 - val_loss: 1.7233 - val_sparse_top_k_categorical_accuracy: 0.7710\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.8921 - sparse_top_k_categorical_accuracy: 0.9015 - val_loss: 1.7704 - val_sparse_top_k_categorical_accuracy: 0.7542\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.8642 - sparse_top_k_categorical_accuracy: 0.9098 - val_loss: 1.8666 - val_sparse_top_k_categorical_accuracy: 0.7559\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.8451 - sparse_top_k_categorical_accuracy: 0.9130 - val_loss: 1.8510 - val_sparse_top_k_categorical_accuracy: 0.7458\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.8544 - sparse_top_k_categorical_accuracy: 0.9058 - val_loss: 1.8940 - val_sparse_top_k_categorical_accuracy: 0.7559\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.8485 - sparse_top_k_categorical_accuracy: 0.9145 - val_loss: 1.7735 - val_sparse_top_k_categorical_accuracy: 0.7668\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.8333 - sparse_top_k_categorical_accuracy: 0.9127 - val_loss: 1.8478 - val_sparse_top_k_categorical_accuracy: 0.7416\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.8041 - sparse_top_k_categorical_accuracy: 0.9184 - val_loss: 1.8394 - val_sparse_top_k_categorical_accuracy: 0.7778\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.7868 - sparse_top_k_categorical_accuracy: 0.9199 - val_loss: 2.0771 - val_sparse_top_k_categorical_accuracy: 0.7197\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.7735 - sparse_top_k_categorical_accuracy: 0.9235 - val_loss: 1.8461 - val_sparse_top_k_categorical_accuracy: 0.7820\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.7737 - sparse_top_k_categorical_accuracy: 0.9257 - val_loss: 1.8546 - val_sparse_top_k_categorical_accuracy: 0.7643\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.7490 - sparse_top_k_categorical_accuracy: 0.9304 - val_loss: 1.8810 - val_sparse_top_k_categorical_accuracy: 0.7702\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.7323 - sparse_top_k_categorical_accuracy: 0.9285 - val_loss: 1.9065 - val_sparse_top_k_categorical_accuracy: 0.7710\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.7436 - sparse_top_k_categorical_accuracy: 0.9296 - val_loss: 1.9303 - val_sparse_top_k_categorical_accuracy: 0.7559\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.7010 - sparse_top_k_categorical_accuracy: 0.9318 - val_loss: 2.0074 - val_sparse_top_k_categorical_accuracy: 0.7660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbda9bb1ee0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = [keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "\n",
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 787)]             0         \n",
      "                                                                 \n",
      " embedding_6 (Embedding)     (None, 787, 100)          920500    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 787, 100)          0         \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 32)                12864     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 934,024\n",
      "Trainable params: 934,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(32, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.2)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(20, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.007, decay=.0008, centered=True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 26s 276ms/step - loss: 2.6009 - accuracy: 0.2656 - val_loss: 2.2093 - val_accuracy: 0.3788\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 24s 275ms/step - loss: 2.1257 - accuracy: 0.3973 - val_loss: 2.0042 - val_accuracy: 0.3981\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 1.9040 - accuracy: 0.4460 - val_loss: 1.8361 - val_accuracy: 0.4562\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 1.7140 - accuracy: 0.4951 - val_loss: 1.8074 - val_accuracy: 0.4747\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 1.6026 - accuracy: 0.5262 - val_loss: 1.7364 - val_accuracy: 0.4941\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 24s 276ms/step - loss: 1.4774 - accuracy: 0.5604 - val_loss: 1.6637 - val_accuracy: 0.4975\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 25s 289ms/step - loss: 1.3500 - accuracy: 0.5980 - val_loss: 1.7092 - val_accuracy: 0.5168\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 25s 287ms/step - loss: 1.2495 - accuracy: 0.6258 - val_loss: 1.6808 - val_accuracy: 0.5253\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 25s 290ms/step - loss: 1.1715 - accuracy: 0.6424 - val_loss: 1.6611 - val_accuracy: 0.5093\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 25s 288ms/step - loss: 1.0918 - accuracy: 0.6716 - val_loss: 1.7072 - val_accuracy: 0.5051\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 25s 289ms/step - loss: 1.0112 - accuracy: 0.6904 - val_loss: 1.7981 - val_accuracy: 0.5168\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.9752 - accuracy: 0.7005 - val_loss: 1.7683 - val_accuracy: 0.5152\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 23s 270ms/step - loss: 0.9172 - accuracy: 0.7182 - val_loss: 1.8655 - val_accuracy: 0.5093\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.8708 - accuracy: 0.7348 - val_loss: 1.9024 - val_accuracy: 0.4907\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.8180 - accuracy: 0.7495 - val_loss: 1.8873 - val_accuracy: 0.5093\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.7752 - accuracy: 0.7575 - val_loss: 1.8603 - val_accuracy: 0.5025\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.7339 - accuracy: 0.7705 - val_loss: 1.9044 - val_accuracy: 0.5042\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 24s 276ms/step - loss: 0.6904 - accuracy: 0.7871 - val_loss: 2.0076 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 24s 277ms/step - loss: 0.6666 - accuracy: 0.7961 - val_loss: 1.9777 - val_accuracy: 0.4949\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.6074 - accuracy: 0.8120 - val_loss: 2.0574 - val_accuracy: 0.5093\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 25s 292ms/step - loss: 0.5897 - accuracy: 0.8098 - val_loss: 2.0412 - val_accuracy: 0.4992\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 25s 291ms/step - loss: 0.5729 - accuracy: 0.8160 - val_loss: 2.0784 - val_accuracy: 0.5101\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 26s 295ms/step - loss: 0.5662 - accuracy: 0.8257 - val_loss: 2.1805 - val_accuracy: 0.4916\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 25s 292ms/step - loss: 0.5223 - accuracy: 0.8380 - val_loss: 2.2259 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 24s 279ms/step - loss: 0.4884 - accuracy: 0.8546 - val_loss: 2.2483 - val_accuracy: 0.5084\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 24s 277ms/step - loss: 0.4837 - accuracy: 0.8495 - val_loss: 2.3031 - val_accuracy: 0.5109\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 25s 289ms/step - loss: 0.4634 - accuracy: 0.8567 - val_loss: 2.2482 - val_accuracy: 0.4941\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.4464 - accuracy: 0.8679 - val_loss: 2.2672 - val_accuracy: 0.5143\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 25s 288ms/step - loss: 0.3937 - accuracy: 0.8802 - val_loss: 2.3904 - val_accuracy: 0.4714\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 25s 289ms/step - loss: 0.3919 - accuracy: 0.8820 - val_loss: 2.3858 - val_accuracy: 0.4983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbda9420d60>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=30, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "174/174 [==============================] - 50s 279ms/step - loss: 2.6690 - sparse_top_k_categorical_accuracy: 0.4630 - val_loss: 2.6639 - val_sparse_top_k_categorical_accuracy: 0.3822\n",
      "Epoch 2/30\n",
      "174/174 [==============================] - 46s 265ms/step - loss: 2.1951 - sparse_top_k_categorical_accuracy: 0.5651 - val_loss: 1.9739 - val_sparse_top_k_categorical_accuracy: 0.6591\n",
      "Epoch 3/30\n",
      "174/174 [==============================] - 45s 260ms/step - loss: 1.8943 - sparse_top_k_categorical_accuracy: 0.6546 - val_loss: 1.8179 - val_sparse_top_k_categorical_accuracy: 0.6877\n",
      "Epoch 4/30\n",
      "174/174 [==============================] - 44s 254ms/step - loss: 1.6969 - sparse_top_k_categorical_accuracy: 0.7052 - val_loss: 1.7027 - val_sparse_top_k_categorical_accuracy: 0.7239\n",
      "Epoch 5/30\n",
      "174/174 [==============================] - 46s 262ms/step - loss: 1.5417 - sparse_top_k_categorical_accuracy: 0.7510 - val_loss: 1.6681 - val_sparse_top_k_categorical_accuracy: 0.7458\n",
      "Epoch 6/30\n",
      "174/174 [==============================] - 46s 263ms/step - loss: 1.3925 - sparse_top_k_categorical_accuracy: 0.7983 - val_loss: 1.5571 - val_sparse_top_k_categorical_accuracy: 0.7778\n",
      "Epoch 7/30\n",
      "174/174 [==============================] - 45s 260ms/step - loss: 1.2863 - sparse_top_k_categorical_accuracy: 0.8246 - val_loss: 1.5540 - val_sparse_top_k_categorical_accuracy: 0.7753\n",
      "Epoch 8/30\n",
      "174/174 [==============================] - 47s 270ms/step - loss: 1.1967 - sparse_top_k_categorical_accuracy: 0.8412 - val_loss: 1.5761 - val_sparse_top_k_categorical_accuracy: 0.7710\n",
      "Epoch 9/30\n",
      " 21/174 [==>...........................] - ETA: 40s - loss: 1.1318 - sparse_top_k_categorical_accuracy: 0.8631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0a37e29cc4c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTopKCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=30, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 787)]             0         \n",
      "                                                                 \n",
      " embedding_9 (Embedding)     (None, 787, 100)          920500    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 787, 100)          0         \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 64)                31872     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 953,672\n",
      "Trainable params: 953,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.35)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(64, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.35)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(20, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.005, decay=.0008, centered = True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "347/347 [==============================] - 93s 265ms/step - loss: 2.6672 - accuracy: 0.2299 - val_loss: 2.3169 - val_accuracy: 0.3510\n",
      "Epoch 2/20\n",
      "347/347 [==============================] - 90s 261ms/step - loss: 2.1403 - accuracy: 0.3977 - val_loss: 1.9427 - val_accuracy: 0.4074\n",
      "Epoch 3/20\n",
      "347/347 [==============================] - 94s 270ms/step - loss: 1.8790 - accuracy: 0.4580 - val_loss: 1.8221 - val_accuracy: 0.4503\n",
      "Epoch 4/20\n",
      "347/347 [==============================] - 86s 248ms/step - loss: 1.7153 - accuracy: 0.5092 - val_loss: 1.6737 - val_accuracy: 0.5025\n",
      "Epoch 5/20\n",
      "347/347 [==============================] - 89s 258ms/step - loss: 1.6040 - accuracy: 0.5399 - val_loss: 1.6126 - val_accuracy: 0.5194\n",
      "Epoch 6/20\n",
      "347/347 [==============================] - 92s 266ms/step - loss: 1.5022 - accuracy: 0.5540 - val_loss: 1.5556 - val_accuracy: 0.5253\n",
      "Epoch 7/20\n",
      "347/347 [==============================] - 91s 262ms/step - loss: 1.4155 - accuracy: 0.5861 - val_loss: 1.6926 - val_accuracy: 0.5051\n",
      "Epoch 8/20\n",
      "347/347 [==============================] - 87s 251ms/step - loss: 1.3236 - accuracy: 0.6088 - val_loss: 1.5341 - val_accuracy: 0.5572\n",
      "Epoch 9/20\n",
      "347/347 [==============================] - 93s 268ms/step - loss: 1.2725 - accuracy: 0.6117 - val_loss: 1.5217 - val_accuracy: 0.5598\n",
      "Epoch 10/20\n",
      "347/347 [==============================] - 89s 257ms/step - loss: 1.2116 - accuracy: 0.6250 - val_loss: 1.5319 - val_accuracy: 0.5497\n",
      "Epoch 11/20\n",
      "347/347 [==============================] - 89s 257ms/step - loss: 1.1498 - accuracy: 0.6431 - val_loss: 1.5143 - val_accuracy: 0.5572\n",
      "Epoch 12/20\n",
      "347/347 [==============================] - 95s 275ms/step - loss: 1.1027 - accuracy: 0.6730 - val_loss: 1.5229 - val_accuracy: 0.5614\n",
      "Epoch 13/20\n",
      "347/347 [==============================] - 90s 259ms/step - loss: 1.0667 - accuracy: 0.6781 - val_loss: 1.5345 - val_accuracy: 0.5480\n",
      "Epoch 14/20\n",
      "347/347 [==============================] - 95s 275ms/step - loss: 1.0231 - accuracy: 0.6933 - val_loss: 1.5010 - val_accuracy: 0.5530\n",
      "Epoch 15/20\n",
      "347/347 [==============================] - 88s 253ms/step - loss: 1.0114 - accuracy: 0.6936 - val_loss: 1.5197 - val_accuracy: 0.5530\n",
      "Epoch 16/20\n",
      "347/347 [==============================] - 87s 251ms/step - loss: 0.9674 - accuracy: 0.7066 - val_loss: 1.5426 - val_accuracy: 0.5640\n",
      "Epoch 17/20\n",
      "347/347 [==============================] - 95s 273ms/step - loss: 0.9373 - accuracy: 0.7142 - val_loss: 1.5627 - val_accuracy: 0.5690\n",
      "Epoch 18/20\n",
      "347/347 [==============================] - 90s 258ms/step - loss: 0.8865 - accuracy: 0.7319 - val_loss: 1.6010 - val_accuracy: 0.5614\n",
      "Epoch 19/20\n",
      "347/347 [==============================] - 90s 260ms/step - loss: 0.8693 - accuracy: 0.7380 - val_loss: 1.5903 - val_accuracy: 0.5631\n",
      "Epoch 20/20\n",
      "347/347 [==============================] - 91s 263ms/step - loss: 0.8543 - accuracy: 0.7402 - val_loss: 1.5648 - val_accuracy: 0.5791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbda46525b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=20, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "347/347 [==============================] - 84s 239ms/step - loss: 2.6382 - sparse_top_k_categorical_accuracy: 0.4709 - val_loss: 2.2655 - val_sparse_top_k_categorical_accuracy: 0.5522\n",
      "Epoch 2/10\n",
      "347/347 [==============================] - 82s 236ms/step - loss: 2.1419 - sparse_top_k_categorical_accuracy: 0.5983 - val_loss: 1.9373 - val_sparse_top_k_categorical_accuracy: 0.6742\n",
      "Epoch 3/10\n",
      "347/347 [==============================] - 83s 238ms/step - loss: 1.8688 - sparse_top_k_categorical_accuracy: 0.6774 - val_loss: 1.7730 - val_sparse_top_k_categorical_accuracy: 0.7290\n",
      "Epoch 4/10\n",
      "347/347 [==============================] - 86s 249ms/step - loss: 1.7214 - sparse_top_k_categorical_accuracy: 0.7070 - val_loss: 1.7133 - val_sparse_top_k_categorical_accuracy: 0.7340\n",
      "Epoch 5/10\n",
      "347/347 [==============================] - 85s 246ms/step - loss: 1.6095 - sparse_top_k_categorical_accuracy: 0.7384 - val_loss: 1.6436 - val_sparse_top_k_categorical_accuracy: 0.7593\n",
      "Epoch 6/10\n",
      "347/347 [==============================] - 84s 243ms/step - loss: 1.5377 - sparse_top_k_categorical_accuracy: 0.7647 - val_loss: 1.6057 - val_sparse_top_k_categorical_accuracy: 0.7761\n",
      "Epoch 7/10\n",
      "347/347 [==============================] - 86s 247ms/step - loss: 1.4170 - sparse_top_k_categorical_accuracy: 0.7972 - val_loss: 1.6052 - val_sparse_top_k_categorical_accuracy: 0.7769\n",
      "Epoch 8/10\n",
      "347/347 [==============================] - 86s 246ms/step - loss: 1.3565 - sparse_top_k_categorical_accuracy: 0.8185 - val_loss: 1.5662 - val_sparse_top_k_categorical_accuracy: 0.7811\n",
      "Epoch 9/10\n",
      "347/347 [==============================] - 83s 240ms/step - loss: 1.2829 - sparse_top_k_categorical_accuracy: 0.8322 - val_loss: 1.5930 - val_sparse_top_k_categorical_accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "347/347 [==============================] - 84s 243ms/step - loss: 1.2245 - sparse_top_k_categorical_accuracy: 0.8441 - val_loss: 1.5508 - val_sparse_top_k_categorical_accuracy: 0.7955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbd96291be0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=10, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "347/347 [==============================] - 85s 245ms/step - loss: 1.1835 - sparse_top_k_categorical_accuracy: 0.8495 - val_loss: 1.5756 - val_sparse_top_k_categorical_accuracy: 0.7946\n",
      "Epoch 2/10\n",
      "347/347 [==============================] - 84s 241ms/step - loss: 1.1413 - sparse_top_k_categorical_accuracy: 0.8643 - val_loss: 1.5232 - val_sparse_top_k_categorical_accuracy: 0.8047\n",
      "Epoch 3/10\n",
      "347/347 [==============================] - 83s 239ms/step - loss: 1.0969 - sparse_top_k_categorical_accuracy: 0.8690 - val_loss: 1.5720 - val_sparse_top_k_categorical_accuracy: 0.8030\n",
      "Epoch 4/10\n",
      "347/347 [==============================] - 83s 239ms/step - loss: 1.0588 - sparse_top_k_categorical_accuracy: 0.8820 - val_loss: 1.5467 - val_sparse_top_k_categorical_accuracy: 0.8039\n",
      "Epoch 5/10\n",
      "347/347 [==============================] - 83s 238ms/step - loss: 1.0064 - sparse_top_k_categorical_accuracy: 0.8813 - val_loss: 1.5706 - val_sparse_top_k_categorical_accuracy: 0.8072\n",
      "Epoch 6/10\n",
      "347/347 [==============================] - 83s 239ms/step - loss: 0.9832 - sparse_top_k_categorical_accuracy: 0.8899 - val_loss: 1.6010 - val_sparse_top_k_categorical_accuracy: 0.7946\n",
      "Epoch 7/10\n",
      "347/347 [==============================] - 83s 239ms/step - loss: 0.9565 - sparse_top_k_categorical_accuracy: 0.8968 - val_loss: 1.6472 - val_sparse_top_k_categorical_accuracy: 0.7980\n",
      "Epoch 8/10\n",
      "347/347 [==============================] - 84s 242ms/step - loss: 0.9258 - sparse_top_k_categorical_accuracy: 0.8975 - val_loss: 1.5817 - val_sparse_top_k_categorical_accuracy: 0.8005\n",
      "Epoch 9/10\n",
      "347/347 [==============================] - 83s 239ms/step - loss: 0.8905 - sparse_top_k_categorical_accuracy: 0.9029 - val_loss: 1.6780 - val_sparse_top_k_categorical_accuracy: 0.7904\n",
      "Epoch 10/10\n",
      "347/347 [==============================] - 83s 239ms/step - loss: 0.8668 - sparse_top_k_categorical_accuracy: 0.9029 - val_loss: 1.7153 - val_sparse_top_k_categorical_accuracy: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbda4730f10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=10, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import keras\n",
    "check = 'distilbert-base-uncased'\n",
    "token = AutoTokenizer.from_pretrained(check)\n",
    "input_tokens = token(list(xtrain), padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tokens = token(list(xtest), padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "train_data = tf.data.Dataset.from_tensor_slices((dict(input_tokens), ytrain))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((dict(eval_tokens), ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_transform', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_59', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(check, num_labels=20)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = .00018,decay=.0008)#, centered=True)\n",
    "model.compile(optimizer=optimizer,loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  15380     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,968,852\n",
      "Trainable params: 66,968,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "174/174 [==============================] - 880s 5s/step - loss: 2.0527 - accuracy: 0.4381 - val_loss: 2.0018 - val_accuracy: 0.3914\n",
      "Epoch 2/12\n",
      "174/174 [==============================] - 869s 5s/step - loss: 1.7381 - accuracy: 0.4958 - val_loss: 1.7089 - val_accuracy: 0.4840\n",
      "Epoch 3/12\n",
      "174/174 [==============================] - 868s 5s/step - loss: 1.5504 - accuracy: 0.5464 - val_loss: 1.5672 - val_accuracy: 0.5337\n",
      "Epoch 4/12\n",
      "174/174 [==============================] - 863s 5s/step - loss: 1.3677 - accuracy: 0.5958 - val_loss: 1.5004 - val_accuracy: 0.5471\n",
      "Epoch 5/12\n",
      "174/174 [==============================] - 874s 5s/step - loss: 1.2216 - accuracy: 0.6391 - val_loss: 1.4865 - val_accuracy: 0.5589\n",
      "Epoch 6/12\n",
      "174/174 [==============================] - 872s 5s/step - loss: 1.0546 - accuracy: 0.6752 - val_loss: 1.5201 - val_accuracy: 0.5387\n",
      "Epoch 7/12\n",
      "174/174 [==============================] - 876s 5s/step - loss: 0.9329 - accuracy: 0.7265 - val_loss: 1.6559 - val_accuracy: 0.5421\n",
      "Epoch 8/12\n",
      "174/174 [==============================] - 896s 5s/step - loss: 0.4609 - accuracy: 0.8661 - val_loss: 1.8686 - val_accuracy: 0.5261\n",
      "Epoch 11/12\n",
      " 67/174 [==========>...................] - ETA: 8:13 - loss: 0.3858 - accuracy: 0.8853"
     ]
    }
   ],
   "source": [
    "model.fit(train_data.shuffle(1000).batch(16), validation_data = test_data.shuffle(1000).batch(16), batch_size=16, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss=loss, metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "174/174 [==============================] - 807s 5s/step - loss: 1.9978 - sparse_top_k_categorical_accuracy: 0.6435 - val_loss: 1.6888 - val_sparse_top_k_categorical_accuracy: 0.7424\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 824s 5s/step - loss: 1.6002 - sparse_top_k_categorical_accuracy: 0.7593 - val_loss: 1.5215 - val_sparse_top_k_categorical_accuracy: 0.7921\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 836s 5s/step - loss: 1.3660 - sparse_top_k_categorical_accuracy: 0.8217 - val_loss: 1.4589 - val_sparse_top_k_categorical_accuracy: 0.8056\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 820s 5s/step - loss: 1.2087 - sparse_top_k_categorical_accuracy: 0.8575 - val_loss: 1.4136 - val_sparse_top_k_categorical_accuracy: 0.8148\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 826s 5s/step - loss: 1.0439 - sparse_top_k_categorical_accuracy: 0.8860 - val_loss: 1.4178 - val_sparse_top_k_categorical_accuracy: 0.8342\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 823s 5s/step - loss: 0.8741 - sparse_top_k_categorical_accuracy: 0.9152 - val_loss: 1.5636 - val_sparse_top_k_categorical_accuracy: 0.8140\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 819s 5s/step - loss: 0.7577 - sparse_top_k_categorical_accuracy: 0.9300 - val_loss: 1.5332 - val_sparse_top_k_categorical_accuracy: 0.8308\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 820s 5s/step - loss: 0.5959 - sparse_top_k_categorical_accuracy: 0.9578 - val_loss: 1.6801 - val_sparse_top_k_categorical_accuracy: 0.8114\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 830s 5s/step - loss: 0.4556 - sparse_top_k_categorical_accuracy: 0.9715 - val_loss: 1.8020 - val_sparse_top_k_categorical_accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 841s 5s/step - loss: 0.3144 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 1.9817 - val_sparse_top_k_categorical_accuracy: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75a6ddb220>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data.shuffle(1000).batch(16), validation_data = test_data.shuffle(1000).batch(16), batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
