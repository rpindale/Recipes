{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Apple Cranberry Pecan Salad</td>\n",
       "      <td>6 cups baby spinach 1 Granny Smith apple, thi...</td>\n",
       "      <td>To make the vinaigrette, whisk together olive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salad</td>\n",
       "      <td>Asian Pasta Salad</td>\n",
       "      <td>8 ounces elbows pasta 1 California Avocado, h...</td>\n",
       "      <td>To make the dressing, whisk together soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick-easy</td>\n",
       "      <td>Vegetable Kabobs</td>\n",
       "      <td>2 cups cremini mushrooms 1 cup cherry tomatoe...</td>\n",
       "      <td>Preheat oven to 400 degrees F. In a small bow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salad</td>\n",
       "      <td>Harvest Cobb Salad</td>\n",
       "      <td>4 slices bacon, diced 2 large eggs 6 cups cho...</td>\n",
       "      <td>To make the poppy seed dressing, whisk togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicken-recipes</td>\n",
       "      <td>Quick Chicken and Broccoli Stir Fry</td>\n",
       "      <td>1 pound boneless, skinless chicken breasts, c...</td>\n",
       "      <td>In a small bowl, whisk together soy sauce, oy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                title  \\\n",
       "0        appetizer          Apple Cranberry Pecan Salad   \n",
       "1            salad                    Asian Pasta Salad   \n",
       "2       quick-easy                     Vegetable Kabobs   \n",
       "3            salad                   Harvest Cobb Salad   \n",
       "4  chicken-recipes  Quick Chicken and Broccoli Stir Fry   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0   6 cups baby spinach 1 Granny Smith apple, thi...   \n",
       "1   8 ounces elbows pasta 1 California Avocado, h...   \n",
       "2   2 cups cremini mushrooms 1 cup cherry tomatoe...   \n",
       "3   4 slices bacon, diced 2 large eggs 6 cups cho...   \n",
       "4   1 pound boneless, skinless chicken breasts, c...   \n",
       "\n",
       "                                        instructions  \n",
       "0   To make the vinaigrette, whisk together olive...  \n",
       "1   To make the dressing, whisk together soy sauc...  \n",
       "2   Preheat oven to 400 degrees F. In a small bow...  \n",
       "3   To make the poppy seed dressing, whisk togeth...  \n",
       "4   In a small bowl, whisk together soy sauce, oy...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "colin = pd.read_csv('colin_webscrap.csv')\n",
    "colin.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(colin.shape)\n",
    "colin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicates\n",
    "colin.drop_duplicates('title').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Title</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Gnocchi, Mushroom and Kale Soup</td>\n",
       "      <td>Sauté the veggies. Heat oil in a large stockpo...</td>\n",
       "      <td>2 tablespoons olive oil 1 medium white onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Greek Salmon Salad Bowls</td>\n",
       "      <td>Cook the salmon. Season the salmon with a few ...</td>\n",
       "      <td>1 pound salmon filets fine sea salt and freshl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Pasta alla Boscaiola</td>\n",
       "      <td>Soften the mushrooms. In a medium saucepan, st...</td>\n",
       "      <td>3 cups vegetable broth 1 ounce dried porcini m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Lemony Lentil Soup</td>\n",
       "      <td>Stovetop Instructions:  Sauté the veggies. Hea...</td>\n",
       "      <td>1 tablespoon olive oil 1 medium white onion, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Guinness Beef Stew</td>\n",
       "      <td>Sear the beef. Generously season the beef with...</td>\n",
       "      <td>3 tablespoons olive oil, divided 3 pounds beef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cat                            Title  \\\n",
       "0  main-course  Gnocchi, Mushroom and Kale Soup   \n",
       "1  main-course         Greek Salmon Salad Bowls   \n",
       "2  main-course             Pasta alla Boscaiola   \n",
       "3  main-course               Lemony Lentil Soup   \n",
       "4  main-course               Guinness Beef Stew   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Sauté the veggies. Heat oil in a large stockpo...   \n",
       "1  Cook the salmon. Season the salmon with a few ...   \n",
       "2  Soften the mushrooms. In a medium saucepan, st...   \n",
       "3  Stovetop Instructions:  Sauté the veggies. Hea...   \n",
       "4  Sear the beef. Generously season the beef with...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  2 tablespoons olive oil 1 medium white onion, ...  \n",
       "1  1 pound salmon filets fine sea salt and freshl...  \n",
       "2  3 cups vegetable broth 1 ounce dried porcini m...  \n",
       "3  1 tablespoon olive oil 1 medium white onion, p...  \n",
       "4  3 tablespoons olive oil, divided 3 pounds beef...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = pd.read_csv('GSOScrapped.csv')\n",
    "print(ed.shape)\n",
    "ed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.drop_duplicates('Title').shape\n",
    "ed = ed.drop_duplicates('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'Title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = ed.rename(columns={'Title':'title'})\n",
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = colin.append(ed).reset_index().drop('index',axis=1)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Apple Cranberry Pecan Salad</td>\n",
       "      <td>6 cups baby spinach 1 Granny Smith apple, thi...</td>\n",
       "      <td>To make the vinaigrette, whisk together olive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salad</td>\n",
       "      <td>Asian Pasta Salad</td>\n",
       "      <td>8 ounces elbows pasta 1 California Avocado, h...</td>\n",
       "      <td>To make the dressing, whisk together soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick-easy</td>\n",
       "      <td>Vegetable Kabobs</td>\n",
       "      <td>2 cups cremini mushrooms 1 cup cherry tomatoe...</td>\n",
       "      <td>Preheat oven to 400 degrees F. In a small bow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salad</td>\n",
       "      <td>Harvest Cobb Salad</td>\n",
       "      <td>4 slices bacon, diced 2 large eggs 6 cups cho...</td>\n",
       "      <td>To make the poppy seed dressing, whisk togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicken-recipes</td>\n",
       "      <td>Quick Chicken and Broccoli Stir Fry</td>\n",
       "      <td>1 pound boneless, skinless chicken breasts, c...</td>\n",
       "      <td>In a small bowl, whisk together soy sauce, oy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                title  \\\n",
       "0        appetizer          Apple Cranberry Pecan Salad   \n",
       "1            salad                    Asian Pasta Salad   \n",
       "2       quick-easy                     Vegetable Kabobs   \n",
       "3            salad                   Harvest Cobb Salad   \n",
       "4  chicken-recipes  Quick Chicken and Broccoli Stir Fry   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0   6 cups baby spinach 1 Granny Smith apple, thi...   \n",
       "1   8 ounces elbows pasta 1 California Avocado, h...   \n",
       "2   2 cups cremini mushrooms 1 cup cherry tomatoe...   \n",
       "3   4 slices bacon, diced 2 large eggs 6 cups cho...   \n",
       "4   1 pound boneless, skinless chicken breasts, c...   \n",
       "\n",
       "                                        instructions  \n",
       "0   To make the vinaigrette, whisk together olive...  \n",
       "1   To make the dressing, whisk together soy sauc...  \n",
       "2   Preheat oven to 400 degrees F. In a small bow...  \n",
       "3   To make the poppy seed dressing, whisk togeth...  \n",
       "4   In a small bowl, whisk together soy sauce, oy...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( 'dip' in merged[merged.cat == 'game-day'].title):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow Cooker Corn and Jalapeno Dip\n",
      "Crab Rangoon Dip\n",
      "Beef Queso Dip\n",
      "Beef Enchilada Dip\n",
      "Hot Cheesy Corn Dip\n",
      "Cheesy Bacon Spinach Dip\n",
      "Bacon Corn Dip\n",
      "French Onion Dip\n"
     ]
    }
   ],
   "source": [
    "for x in merged[merged.cat == 'game-day'].title:\n",
    "    if('Dip' in x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Chicken Burrito Bowl Meal Prep</td>\n",
       "      <td>1 cup brown rice 1 tablespoon olive oil 1 1/2...</td>\n",
       "      <td>To make the chipotle cream sauce, whisk toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Ham, Egg and Cheese Breakfast Quesadillas</td>\n",
       "      <td>1 tablespoon olive oil 2 cloves garlic, mince...</td>\n",
       "      <td>Preheat oven to 400 degrees F. Line a baking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Shrimp Fried Rice Meal Prep</td>\n",
       "      <td>1 1/2 cups brown rice 1 pound green beans, tr...</td>\n",
       "      <td>In a large saucepan of 3 cups water, cook ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Korean Beef Bowl Meal Prep</td>\n",
       "      <td>1 cup brown rice 4 large eggs 2 tablespoons o...</td>\n",
       "      <td>In a large saucepan filled with 2 cups of wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Chicken Tikka Masala Meal Prep</td>\n",
       "      <td>1 cup basmati rice 2 tablespoons unsalted but...</td>\n",
       "      <td>In a large saucepan of 2 cups water, cook ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Chicken Shawarma Meal Prep</td>\n",
       "      <td>1 cup brown rice 1 1/2 pounds boneless, skinl...</td>\n",
       "      <td>In a large saucepan of 2 cups water, cook ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Quick Beef and Broccoli Meal Prep</td>\n",
       "      <td>1 cup brown rice 1/4 cup reduced sodium soy s...</td>\n",
       "      <td>In a large saucepan of 2 cups water, cook ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Taco Meal Prep Bowls</td>\n",
       "      <td>1 cup brown rice 2 tablespoons olive oil 2 po...</td>\n",
       "      <td>In a large saucepan of 2 cups water, cook ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Avocado and Egg Breakfast Meal Prep</td>\n",
       "      <td>1/2 cup brown rice 6 large eggs 2 tablespoons...</td>\n",
       "      <td>In a large saucepan of 1 cup water, cook rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Carne Asada Burrito Bowls</td>\n",
       "      <td>For the carne asada  1/2 cup chopped fresh cil...</td>\n",
       "      <td>For the carne asada  In a medium bowl, combine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Breakfast Meal Prep</td>\n",
       "      <td>12 ounces russet potatoes, diced* 3 tablespoo...</td>\n",
       "      <td>Preheat oven to 400 degrees F. Lightly oil a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Copycat Starbucks Cheese and Fruit Bistro Box</td>\n",
       "      <td>1 ounce aged cheddar cheese, sliced 1 ounce G...</td>\n",
       "      <td>Place cheeses, crackers, apple, almonds and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Turkey Taco Salad Meal Prep</td>\n",
       "      <td>1 tablespoon olive oil 1 1/2 pounds ground tu...</td>\n",
       "      <td>Heat olive oil in a large stockpot or Dutch o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Tuna Salad Meal Prep</td>\n",
       "      <td>2 (5-ounce) cans tuna in water, drained and f...</td>\n",
       "      <td>In a medium bowl, combine tuna, Greek yogurt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Copycat Starbucks PB&amp;J Bistro Box</td>\n",
       "      <td>6 slices whole wheat bread 1/4 cup peanut but...</td>\n",
       "      <td>Spread 2 tablespoons peanut butter over 1 sli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Shrimp Zucchini Noodles Meal Prep</td>\n",
       "      <td>2 tablespoons unsalted butter 2 tablespoons o...</td>\n",
       "      <td>Combine butter and olive oil in a large skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Turkey Spinach Pinwheels Meal Prep</td>\n",
       "      <td>1 slice cheddar cheese 2 ounces thinly sliced...</td>\n",
       "      <td>Place cheese, turkey and spinach in center of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Peanut Butter and Banana Roll Ups Snack Box</td>\n",
       "      <td>1 (8-inch) whole wheat tortilla 1 tablespoon ...</td>\n",
       "      <td>Spread tortilla with peanut butter. Place ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>DIY Pizza Lunchables</td>\n",
       "      <td>4 pita bites crackers 2 tablespoons reduced f...</td>\n",
       "      <td>Place crackers, cheese, pizza sauce, almonds,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>meal-prep</td>\n",
       "      <td>Deli Snack Box</td>\n",
       "      <td>2 ounces thinly sliced turkey breast 1 large ...</td>\n",
       "      <td>Place turkey, egg, tomatoes, cheese, crackers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cat                                          title  \\\n",
       "500   meal-prep                 Chicken Burrito Bowl Meal Prep   \n",
       "575   meal-prep      Ham, Egg and Cheese Breakfast Quesadillas   \n",
       "695   meal-prep                    Shrimp Fried Rice Meal Prep   \n",
       "707   meal-prep                     Korean Beef Bowl Meal Prep   \n",
       "731   meal-prep                 Chicken Tikka Masala Meal Prep   \n",
       "732   meal-prep                     Chicken Shawarma Meal Prep   \n",
       "738   meal-prep              Quick Beef and Broccoli Meal Prep   \n",
       "742   meal-prep                           Taco Meal Prep Bowls   \n",
       "746   meal-prep            Avocado and Egg Breakfast Meal Prep   \n",
       "861   meal-prep                      Carne Asada Burrito Bowls   \n",
       "930   meal-prep                            Breakfast Meal Prep   \n",
       "1217  meal-prep  Copycat Starbucks Cheese and Fruit Bistro Box   \n",
       "1218  meal-prep                    Turkey Taco Salad Meal Prep   \n",
       "1219  meal-prep                           Tuna Salad Meal Prep   \n",
       "1220  meal-prep              Copycat Starbucks PB&J Bistro Box   \n",
       "1221  meal-prep              Shrimp Zucchini Noodles Meal Prep   \n",
       "1222  meal-prep             Turkey Spinach Pinwheels Meal Prep   \n",
       "1223  meal-prep    Peanut Butter and Banana Roll Ups Snack Box   \n",
       "1224  meal-prep                           DIY Pizza Lunchables   \n",
       "1225  meal-prep                                 Deli Snack Box   \n",
       "\n",
       "                                            ingredients  \\\n",
       "500    1 cup brown rice 1 tablespoon olive oil 1 1/2...   \n",
       "575    1 tablespoon olive oil 2 cloves garlic, mince...   \n",
       "695    1 1/2 cups brown rice 1 pound green beans, tr...   \n",
       "707    1 cup brown rice 4 large eggs 2 tablespoons o...   \n",
       "731    1 cup basmati rice 2 tablespoons unsalted but...   \n",
       "732    1 cup brown rice 1 1/2 pounds boneless, skinl...   \n",
       "738    1 cup brown rice 1/4 cup reduced sodium soy s...   \n",
       "742    1 cup brown rice 2 tablespoons olive oil 2 po...   \n",
       "746    1/2 cup brown rice 6 large eggs 2 tablespoons...   \n",
       "861   For the carne asada  1/2 cup chopped fresh cil...   \n",
       "930    12 ounces russet potatoes, diced* 3 tablespoo...   \n",
       "1217   1 ounce aged cheddar cheese, sliced 1 ounce G...   \n",
       "1218   1 tablespoon olive oil 1 1/2 pounds ground tu...   \n",
       "1219   2 (5-ounce) cans tuna in water, drained and f...   \n",
       "1220   6 slices whole wheat bread 1/4 cup peanut but...   \n",
       "1221   2 tablespoons unsalted butter 2 tablespoons o...   \n",
       "1222   1 slice cheddar cheese 2 ounces thinly sliced...   \n",
       "1223   1 (8-inch) whole wheat tortilla 1 tablespoon ...   \n",
       "1224   4 pita bites crackers 2 tablespoons reduced f...   \n",
       "1225   2 ounces thinly sliced turkey breast 1 large ...   \n",
       "\n",
       "                                           instructions  \n",
       "500    To make the chipotle cream sauce, whisk toget...  \n",
       "575    Preheat oven to 400 degrees F. Line a baking ...  \n",
       "695    In a large saucepan of 3 cups water, cook ric...  \n",
       "707    In a large saucepan filled with 2 cups of wat...  \n",
       "731    In a large saucepan of 2 cups water, cook ric...  \n",
       "732    In a large saucepan of 2 cups water, cook ric...  \n",
       "738    In a large saucepan of 2 cups water, cook ric...  \n",
       "742    In a large saucepan of 2 cups water, cook ric...  \n",
       "746    In a large saucepan of 1 cup water, cook rice...  \n",
       "861   For the carne asada  In a medium bowl, combine...  \n",
       "930    Preheat oven to 400 degrees F. Lightly oil a ...  \n",
       "1217   Place cheeses, crackers, apple, almonds and c...  \n",
       "1218   Heat olive oil in a large stockpot or Dutch o...  \n",
       "1219   In a medium bowl, combine tuna, Greek yogurt,...  \n",
       "1220   Spread 2 tablespoons peanut butter over 1 sli...  \n",
       "1221   Combine butter and olive oil in a large skill...  \n",
       "1222   Place cheese, turkey and spinach in center of...  \n",
       "1223   Spread tortilla with peanut butter. Place ban...  \n",
       "1224   Place crackers, cheese, pizza sauce, almonds,...  \n",
       "1225   Place turkey, egg, tomatoes, cheese, crackers...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged.cat == 'meal-prep'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course            695\n",
       "dessert                343\n",
       "breakfast              196\n",
       "quick-easy             164\n",
       "appetizer              131\n",
       "appetizers             104\n",
       "chicken-recipes        100\n",
       "asian-inspired          87\n",
       "drinks                  81\n",
       "pasta                   79\n",
       "soup                    76\n",
       "salad                   70\n",
       "vegetarian              58\n",
       "side-dish               55\n",
       "slow-cooker             43\n",
       "one-pot                 39\n",
       "entree                  38\n",
       "summer                  36\n",
       "game-day                35\n",
       "healthy                 28\n",
       "christmas               26\n",
       "instant-pot-recipes     26\n",
       "drink                   26\n",
       "thanksgiving            25\n",
       "beverages               24\n",
       "dip                     21\n",
       "meal-prep               21\n",
       "baked-goods             21\n",
       "fall                    20\n",
       "pastas                  14\n",
       "snacks                  14\n",
       "salsas-sauces           14\n",
       "smoothies               13\n",
       "pizzas                  12\n",
       "sandwiches              12\n",
       "bread                    7\n",
       "spreads                  6\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course        745\n",
       "dessert            343\n",
       "appetizers         304\n",
       "quick-easy         197\n",
       "breakfast          196\n",
       "drinks             144\n",
       "vegetarian         128\n",
       "chicken-recipes    100\n",
       "pasta               93\n",
       "asian-inspired      87\n",
       "soup                76\n",
       "slow-cooker         69\n",
       "seasonal            56\n",
       "holiday             51\n",
       "sauces              41\n",
       "one-pot             39\n",
       "game-day            35\n",
       "healthy             28\n",
       "baked-goods         28\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged.cat == 'appetizer', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'pastas', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'bread', 'cat'] = 'baked-goods'\n",
    "merged.loc[merged.cat == 'snacks', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'beverages', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'entree','cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'drink', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'smoothies', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'spreads', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'salsas-sauces', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'dip', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'pizzas', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'sandwiches', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'fall', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'summer', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'side-dish', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'salad', 'cat'] = 'vegetarian'\n",
    "merged.loc[merged.cat == 'meal-prep', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'thanksgiving', 'cat'] = 'holiday'\n",
    "merged.loc[merged.cat == 'christmas', 'cat'] = 'holiday'\n",
    "merged.loc[merged.cat == 'instant-pot-recipes', 'cat'] = 'slow-cooker'\n",
    "\n",
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged.cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.cat = pd.Categorical(merged.cat)\n",
    "merged['y'] = merged.cat.cat.codes\n",
    "merged.y = [np.int64(x) for x in merged.y]\n",
    "merged.y = pd.Series(merged.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =merged.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1       18\n",
       "2       13\n",
       "3       18\n",
       "4        4\n",
       "        ..\n",
       "2755    14\n",
       "2756    14\n",
       "2757    14\n",
       "2758    14\n",
       "2759    14\n",
       "Name: y, Length: 2760, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'ingredients', 'instructions', 'y'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.hstack(merged['title'] + merged['ingredients']+ merged['instructions'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import one_hot , Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain, ttest, ingtrain, ingtest, insttrain, insttest, y1train, y1test = train_test_split(merged.title, merged.ingredients, \n",
    "                                                                                        merged.instructions, merged.cat, test_size=.3, \n",
    "                                                                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510, 1354, 1437, 4125, 1437, 195, 4126, 484, 242, 1354, 3, 174, 1788, 195, 114, 1, 647, 1882, 32, 10, 436, 5, 28, 35, 126, 17, 1, 18, 122, 24, 35, 867, 41, 3, 13, 11, 13, 28, 35, 126, 5, 140, 24, 80, 249, 12, 17, 1, 989, 100, 2, 1354, 1437, 195, 128, 33, 4, 1222, 32, 6, 743, 724, 410, 2, 1354, 25, 1138, 744, 552, 1, 54, 410, 136, 12, 1789, 552, 7, 127, 30, 106, 717, 345, 1692, 744, 552, 176, 104, 868, 3, 103, 280, 13, 58, 706, 4127, 6, 687, 12, 1354, 452, 2, 4128, 12, 6, 687, 12, 195, 1, 707, 60, 1081, 192, 337, 32, 6, 294, 491, 36, 81, 1355, 9, 2, 118, 195, 1, 1354, 393, 2, 126, 35, 207, 2, 82, 12, 136, 195, 1115, 9, 6, 297, 577, 905, 12, 17, 1, 18, 89, 15, 72, 2771, 10, 8, 2, 195, 104, 560, 1, 1045, 1, 2, 1354, 43, 230, 366, 449, 168, 9, 990, 890, 46, 74, 4, 100, 2, 24, 35, 867, 41, 79, 87, 69, 71, 8, 73, 1115, 9, 133, 17, 1, 18, 46, 74, 1, 40, 168]\n",
      "880\n"
     ]
    }
   ],
   "source": [
    "## To DO: tokenize using keras tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(xtrain)\n",
    "vocabsize = len(t.word_index) + 1\n",
    "encoded = t.texts_to_sequences(xtrain)\n",
    "tencoded = t.texts_to_sequences(ttrain)\n",
    "ingencoded = t.texts_to_sequences(str(ingtrain))\n",
    "instencoded = t.texts_to_sequences([str(x) for x in insttrain])\n",
    "encodedtest = t.texts_to_sequences(xtest)\n",
    "print(encoded[1])\n",
    "\n",
    "maxlength = max([len(x) for x in encoded])\n",
    "print(maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_glove():\n",
    "    embeddings_index = dict()\n",
    "    f = open('./glove.6B.100d.txt') # replace this with the path to your downloaded txt file\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    # create a weight matrix for words in training docs\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "[1221  238    9  698   39    1  876  132 4122   23  336 1044  853  238\n",
      "   16   28   51   22  267  353  239   17    1   48  349   57   18    3\n",
      "   16   11  386  820    5  877  151   85    9  130    1  124  821  267\n",
      "   13   84   24   96   13  125   63   39    5  125  698   39    3   13\n",
      "   11  292   53  876  132  150    3   13   11  290  609  441   16   28\n",
      "  292   53   50 4123    2  238   55    6  400  300   46  141   32   82\n",
      "   12    6   23   36   81    1 1025    9  162  182  374   88    1  129\n",
      "    2  666  765    4    6  743  724    1  292 1291 4124    2  666 1991\n",
      "  790   71 1397  192  121   32    2  190   36  300  285    2  666 1991\n",
      "   94    9    3   52   10  111   51   22    1   68   94    9    6  297\n",
      " 1691   12   57   18    1    6  249   12  239   17 1026    2  820  757\n",
      "    3   52   22    7    6  181   75   44   29   65   20   19  386    1\n",
      "  144    4   62   42   15    5    4   16   14   70  344    8  131  158\n",
      "  129    2  386    4    6   34   54  612 2274  337    2  181   75    4\n",
      "   88  269  118  592  181    2  442  757    2  118    3   52   22   44\n",
      "   29   65   20   19 3214  821   12    2  877    1  181   15   16   14\n",
      "   70  113   19    2   24    1   53  666  765    1  181   15   16    4\n",
      "   58  111   14    8  200   88   75   90   20   62    2  278 1157    2\n",
      "   24  666   45   63   39  698   39  876  132  150  609  441    1  166\n",
      "    7    6  263   34   10  106  107   62  293    7    2  987  181   75\n",
      "    1   31    8   94   73 1992    2  238  757   33    4  699 2114  156\n",
      "    6   86  231    4  473    2  278   45   94   25    2  190  666 1991\n",
      "  644    2  278   25    2 2275  134  904  134 1470  445    2  238 1880\n",
      "  337    7    2  386   45  221  176   60 1787    2  278   54   55    2\n",
      "  238  567   32    2  400  300 2276  112  320    3  103  932   89  988\n",
      "   15  211    4  364   14   10    8    2  666 1991  104  200   36  237\n",
      "  315 1881 2465   32    2  455   12   93  238   40  586   36   81   90\n",
      "    2   33    1   40    2 1221  238  168  731    9  133   50  166   46\n",
      "  106  521  289  409    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.initializers import Constant\n",
    "import math\n",
    "# to Do: add constants that you might need here\n",
    "n_classes=19\n",
    "embeddingdim = 100\n",
    "\n",
    "word_index=t.word_index\n",
    "\n",
    "embeddings_index = load_glove()\n",
    "embedding_matrix = np.random.random((len(word_index)+1, embeddingdim))\n",
    "for word, i in word_index.items():\n",
    "    embeddingvector = embeddings_index.get(word)\n",
    "    if embeddingvector is not None:\n",
    "        if len(embedding_matrix[i]) != len(embeddingvector):\n",
    "            print('could not be broadcast input array from shape ', str(len(embedding_matrix[i])),\n",
    "                 ' into shape ', str(len(embeddingvector)), ' Please make sure your embedding dim is equal to embedding vector file Glove')\n",
    "            exit(1)\n",
    "        \n",
    "        embedding_matrix[i] = embeddingvector\n",
    "        \n",
    "\n",
    "###To Do:  pad the train and test data \n",
    "padded = pad_sequences(encoded, maxlen=maxlength, padding='post')\n",
    "tpadded = pad_sequences(tencoded, maxlen=maxlength, padding='post')\n",
    "ingpadded = pad_sequences(ingencoded, maxlen=maxlength, padding='post')\n",
    "instpadded = pad_sequences(instencoded, maxlen=maxlength, padding='post')\n",
    "paddedtest = pad_sequences(encodedtest, maxlen=maxlength, padding='post')\n",
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 880, 100)     733700      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 880, 100)     0           ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 880, 64)      19264       ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 880, 32)      9632        ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 880, 16)      4816        ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_40 (MaxPooling1D  (None, 176, 64)     0           ['conv1d_41[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_42 (MaxPooling1D  (None, 176, 32)     0           ['conv1d_43[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_44 (MaxPooling1D  (None, 176, 16)     0           ['conv1d_45[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 176, 64)      0           ['max_pooling1d_40[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 176, 32)      0           ['max_pooling1d_42[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 176, 16)      0           ['max_pooling1d_44[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 174, 128)     24704       ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 174, 128)     12416       ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 174, 128)     6272        ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_41 (MaxPooling1D  (None, 58, 128)     0           ['conv1d_42[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_43 (MaxPooling1D  (None, 58, 128)     0           ['conv1d_44[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_45 (MaxPooling1D  (None, 58, 128)     0           ['conv1d_46[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 58, 384)      0           ['max_pooling1d_41[0][0]',       \n",
      "                                                                  'max_pooling1d_43[0][0]',       \n",
      "                                                                  'max_pooling1d_45[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 22272)        0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          2850944     ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 64)           8256        ['dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 64)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 32)           2080        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 32)           0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 19)           627         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,672,711\n",
      "Trainable params: 3,672,711\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                          input_length=maxlength, trainable=True)\n",
    "sequence_input = Input(shape=(maxlength,),dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "x = Dropout(.2)(embeddedsequences)\n",
    "x1 = Conv1D(64, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x1 = MaxPooling1D(5)(x1)\n",
    "x1 = Dropout(.2)(x1)\n",
    "x1 = Conv1D(128, 3, activation='softplus')(x1)\n",
    "x1 = MaxPooling1D(3)(x1)\n",
    "#x1 = Conv1D(256, 5, activation = 'softplus')(x1)\n",
    "#x1 = MaxPooling1D(10)(x1)\n",
    "\n",
    "x2 = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x2 = MaxPooling1D(5)(x2)\n",
    "x2 = Dropout(.2)(x2)\n",
    "x2 = Conv1D(128, 3, activation='softplus')(x2)\n",
    "x2 = MaxPooling1D(3)(x2)\n",
    "#x2 = Conv1D(256, 5, activation = 'softplus')(x2)\n",
    "#x2 = MaxPooling1D(10)(x2)\n",
    "\n",
    "x3 = Conv1D(16, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x3 = MaxPooling1D(5)(x3)\n",
    "x3 = Dropout(.2)(x3)\n",
    "x3 = Conv1D(128, 3, activation='softplus')(x3)\n",
    "x3 = MaxPooling1D(3)(x3)\n",
    "#x3 = Conv1D(256, 5, activation = 'softplus')(x3)\n",
    "#x3 = MaxPooling1D(10)(x3)\n",
    "\n",
    "x = Concatenate()([x1,x2,x3])\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(32, activation = 'softplus')(x)\n",
    "x = Dropout(.4)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=.003, decay=.0008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 880, 100)     733700      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 880, 100)     0           ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 880, 32)      9632        ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 880, 24)      9624        ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 880, 64)      32064       ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 880, 120)     0           ['conv1d_47[0][0]',              \n",
      "                                                                  'conv1d_48[0][0]',              \n",
      "                                                                  'conv1d_49[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_46 (MaxPooling1D  (None, 176, 120)    0           ['concatenate_6[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 176, 120)     0           ['max_pooling1d_46[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 174, 128)     46208       ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_47 (MaxPooling1D  (None, 21, 128)     0           ['conv1d_50[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 17, 256)      164096      ['max_pooling1d_47[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_48 (MaxPooling1D  (None, 1, 256)      0           ['conv1d_51[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 256)          0           ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          32896       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 64)           8256        ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 64)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 19)           1235        ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,037,711\n",
      "Trainable params: 1,037,711\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(8)(x)\n",
    "x = Conv1D(256, 5, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(10)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "#x = Dense(32, activation = 'softplus')(x)\n",
    "#x = Dropout(.2)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=.0003, decay=.00008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 4s 81ms/step - loss: 2.9222 - accuracy: 0.1858 - val_loss: 2.5904 - val_accuracy: 0.2802\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.6968 - accuracy: 0.2184 - val_loss: 2.5555 - val_accuracy: 0.2802\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.6309 - accuracy: 0.2288 - val_loss: 2.4865 - val_accuracy: 0.2802\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 2.5716 - accuracy: 0.2329 - val_loss: 2.4762 - val_accuracy: 0.2802\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.5450 - accuracy: 0.2583 - val_loss: 2.4102 - val_accuracy: 0.2802\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.4935 - accuracy: 0.2531 - val_loss: 2.3630 - val_accuracy: 0.2802\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.4322 - accuracy: 0.2567 - val_loss: 2.4158 - val_accuracy: 0.2947\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 2.4013 - accuracy: 0.2671 - val_loss: 2.3038 - val_accuracy: 0.2802\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.3359 - accuracy: 0.2945 - val_loss: 2.2490 - val_accuracy: 0.3092\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.3000 - accuracy: 0.2867 - val_loss: 2.2453 - val_accuracy: 0.3152\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.2236 - accuracy: 0.3116 - val_loss: 2.1097 - val_accuracy: 0.3080\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.1711 - accuracy: 0.3323 - val_loss: 2.1983 - val_accuracy: 0.2983\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.1040 - accuracy: 0.3535 - val_loss: 1.9723 - val_accuracy: 0.3937\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.0795 - accuracy: 0.3649 - val_loss: 1.9344 - val_accuracy: 0.4312\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.0025 - accuracy: 0.3923 - val_loss: 1.8970 - val_accuracy: 0.4384\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 2.0044 - accuracy: 0.4006 - val_loss: 1.8769 - val_accuracy: 0.4372\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.9642 - accuracy: 0.4079 - val_loss: 2.0110 - val_accuracy: 0.4215\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.9211 - accuracy: 0.4146 - val_loss: 1.8526 - val_accuracy: 0.4589\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.8950 - accuracy: 0.4265 - val_loss: 1.8198 - val_accuracy: 0.4336\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.8672 - accuracy: 0.4249 - val_loss: 1.8136 - val_accuracy: 0.4384\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.8643 - accuracy: 0.4224 - val_loss: 1.7839 - val_accuracy: 0.4686\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.8428 - accuracy: 0.4363 - val_loss: 1.8502 - val_accuracy: 0.4481\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.8117 - accuracy: 0.4275 - val_loss: 1.7687 - val_accuracy: 0.4541\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.7886 - accuracy: 0.4498 - val_loss: 1.7152 - val_accuracy: 0.4638\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.7737 - accuracy: 0.4596 - val_loss: 1.8115 - val_accuracy: 0.4505\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.7581 - accuracy: 0.4560 - val_loss: 1.6936 - val_accuracy: 0.4662\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.7654 - accuracy: 0.4436 - val_loss: 1.7104 - val_accuracy: 0.4626\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.7506 - accuracy: 0.4689 - val_loss: 1.9428 - val_accuracy: 0.4022\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.7028 - accuracy: 0.4705 - val_loss: 1.8228 - val_accuracy: 0.4457\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.6831 - accuracy: 0.4679 - val_loss: 1.7454 - val_accuracy: 0.4626\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.7024 - accuracy: 0.4581 - val_loss: 1.7253 - val_accuracy: 0.4553\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.6724 - accuracy: 0.4819 - val_loss: 1.7171 - val_accuracy: 0.4734\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.6284 - accuracy: 0.4772 - val_loss: 1.6445 - val_accuracy: 0.4867\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.6358 - accuracy: 0.4798 - val_loss: 1.9623 - val_accuracy: 0.4082\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.6475 - accuracy: 0.4845 - val_loss: 1.6281 - val_accuracy: 0.4746\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 1.6070 - accuracy: 0.4860 - val_loss: 1.5914 - val_accuracy: 0.4952\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.5907 - accuracy: 0.4917 - val_loss: 1.5809 - val_accuracy: 0.5048\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.5742 - accuracy: 0.5052 - val_loss: 1.6158 - val_accuracy: 0.4879\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.5818 - accuracy: 0.5016 - val_loss: 1.7780 - val_accuracy: 0.4734\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.5380 - accuracy: 0.5041 - val_loss: 1.8456 - val_accuracy: 0.4324\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.5350 - accuracy: 0.4969 - val_loss: 1.6204 - val_accuracy: 0.4988\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.5077 - accuracy: 0.5135 - val_loss: 1.5699 - val_accuracy: 0.5085\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.5046 - accuracy: 0.5186 - val_loss: 1.7272 - val_accuracy: 0.4662\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.5244 - accuracy: 0.5186 - val_loss: 1.5412 - val_accuracy: 0.4928\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.4797 - accuracy: 0.5217 - val_loss: 1.5188 - val_accuracy: 0.5205\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.4532 - accuracy: 0.5331 - val_loss: 1.6655 - val_accuracy: 0.4940\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.4568 - accuracy: 0.5269 - val_loss: 1.6183 - val_accuracy: 0.4976\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.4273 - accuracy: 0.5254 - val_loss: 1.5204 - val_accuracy: 0.5157\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.4230 - accuracy: 0.5414 - val_loss: 1.5264 - val_accuracy: 0.5217\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.4135 - accuracy: 0.5393 - val_loss: 1.5347 - val_accuracy: 0.5193\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.3941 - accuracy: 0.5414 - val_loss: 1.5627 - val_accuracy: 0.5145\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 1.3715 - accuracy: 0.5487 - val_loss: 1.5587 - val_accuracy: 0.5133\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.3933 - accuracy: 0.5450 - val_loss: 1.5132 - val_accuracy: 0.5169\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.3405 - accuracy: 0.5699 - val_loss: 1.4492 - val_accuracy: 0.5519\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.3680 - accuracy: 0.5502 - val_loss: 1.6550 - val_accuracy: 0.5048\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.3149 - accuracy: 0.5663 - val_loss: 1.4850 - val_accuracy: 0.5471\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.3036 - accuracy: 0.5756 - val_loss: 1.5068 - val_accuracy: 0.5459\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.2894 - accuracy: 0.5673 - val_loss: 1.5298 - val_accuracy: 0.5314\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2597 - accuracy: 0.5864 - val_loss: 1.5157 - val_accuracy: 0.5386\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2490 - accuracy: 0.5952 - val_loss: 1.4873 - val_accuracy: 0.5604\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.2587 - accuracy: 0.5932 - val_loss: 1.5201 - val_accuracy: 0.5290\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.2251 - accuracy: 0.6014 - val_loss: 1.5729 - val_accuracy: 0.5242\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.1974 - accuracy: 0.6051 - val_loss: 1.7417 - val_accuracy: 0.4915\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2087 - accuracy: 0.5978 - val_loss: 1.4918 - val_accuracy: 0.5374\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2017 - accuracy: 0.5927 - val_loss: 1.7676 - val_accuracy: 0.4988\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.1902 - accuracy: 0.6082 - val_loss: 1.5060 - val_accuracy: 0.5411\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.1707 - accuracy: 0.5983 - val_loss: 1.5540 - val_accuracy: 0.5278\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.1856 - accuracy: 0.6030 - val_loss: 1.5014 - val_accuracy: 0.5386\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.1622 - accuracy: 0.6175 - val_loss: 1.5228 - val_accuracy: 0.5471\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.1329 - accuracy: 0.6366 - val_loss: 1.4684 - val_accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0931 - accuracy: 0.6299 - val_loss: 1.4832 - val_accuracy: 0.5483\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.0923 - accuracy: 0.6408 - val_loss: 1.4461 - val_accuracy: 0.5676\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0975 - accuracy: 0.6444 - val_loss: 1.6667 - val_accuracy: 0.5097\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.0989 - accuracy: 0.6392 - val_loss: 1.4600 - val_accuracy: 0.5713\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0698 - accuracy: 0.6403 - val_loss: 1.4993 - val_accuracy: 0.5399\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0368 - accuracy: 0.6460 - val_loss: 1.5931 - val_accuracy: 0.5399\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.0321 - accuracy: 0.6563 - val_loss: 1.4839 - val_accuracy: 0.5700\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.0330 - accuracy: 0.6573 - val_loss: 1.5540 - val_accuracy: 0.5411\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.0191 - accuracy: 0.6553 - val_loss: 1.7085 - val_accuracy: 0.5278\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.0031 - accuracy: 0.6718 - val_loss: 1.6122 - val_accuracy: 0.5157\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.9608 - accuracy: 0.6744 - val_loss: 1.5011 - val_accuracy: 0.5604\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9974 - accuracy: 0.6542 - val_loss: 1.4616 - val_accuracy: 0.5664\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9711 - accuracy: 0.6672 - val_loss: 1.4851 - val_accuracy: 0.5592\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9597 - accuracy: 0.6812 - val_loss: 1.6515 - val_accuracy: 0.5012\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.9649 - accuracy: 0.6853 - val_loss: 1.6524 - val_accuracy: 0.5290\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9415 - accuracy: 0.6863 - val_loss: 1.5455 - val_accuracy: 0.5640\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.9347 - accuracy: 0.6915 - val_loss: 1.5832 - val_accuracy: 0.5568\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.9559 - accuracy: 0.6682 - val_loss: 1.7735 - val_accuracy: 0.5459\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9276 - accuracy: 0.6931 - val_loss: 1.6377 - val_accuracy: 0.5664\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.9144 - accuracy: 0.7024 - val_loss: 1.5451 - val_accuracy: 0.5725\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.8861 - accuracy: 0.7013 - val_loss: 1.5385 - val_accuracy: 0.5568\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.8891 - accuracy: 0.7127 - val_loss: 1.5317 - val_accuracy: 0.5628\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8650 - accuracy: 0.7086 - val_loss: 1.4990 - val_accuracy: 0.5700\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8542 - accuracy: 0.7246 - val_loss: 1.5195 - val_accuracy: 0.5483\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8404 - accuracy: 0.7277 - val_loss: 1.5015 - val_accuracy: 0.5737\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.8268 - accuracy: 0.7246 - val_loss: 1.8011 - val_accuracy: 0.4891\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.8528 - accuracy: 0.7029 - val_loss: 1.5954 - val_accuracy: 0.5592\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.7974 - accuracy: 0.7360 - val_loss: 1.6785 - val_accuracy: 0.5350\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8210 - accuracy: 0.7257 - val_loss: 1.5686 - val_accuracy: 0.5664\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.8051 - accuracy: 0.7277 - val_loss: 1.7368 - val_accuracy: 0.5435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2ae7a6f40>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.8344 - accuracy: 0.7298 - val_loss: 1.7000 - val_accuracy: 0.5338\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.8321 - accuracy: 0.7246 - val_loss: 1.6812 - val_accuracy: 0.5109\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7752 - accuracy: 0.7386 - val_loss: 1.5505 - val_accuracy: 0.5845\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7763 - accuracy: 0.7448 - val_loss: 1.6949 - val_accuracy: 0.5483\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7692 - accuracy: 0.7433 - val_loss: 1.6405 - val_accuracy: 0.5628\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7337 - accuracy: 0.7562 - val_loss: 1.5994 - val_accuracy: 0.5531\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7443 - accuracy: 0.7500 - val_loss: 1.5639 - val_accuracy: 0.5628\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7183 - accuracy: 0.7619 - val_loss: 1.6930 - val_accuracy: 0.5326\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6960 - accuracy: 0.7733 - val_loss: 1.6621 - val_accuracy: 0.5471\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6635 - accuracy: 0.7738 - val_loss: 1.6573 - val_accuracy: 0.5604\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6652 - accuracy: 0.7754 - val_loss: 1.7681 - val_accuracy: 0.5773\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6695 - accuracy: 0.7723 - val_loss: 1.6626 - val_accuracy: 0.5700\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6823 - accuracy: 0.7666 - val_loss: 1.7230 - val_accuracy: 0.5737\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6428 - accuracy: 0.7867 - val_loss: 1.7677 - val_accuracy: 0.5543\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.6092 - accuracy: 0.8023 - val_loss: 1.7571 - val_accuracy: 0.5604\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.6069 - accuracy: 0.7945 - val_loss: 1.8707 - val_accuracy: 0.5471\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5748 - accuracy: 0.8012 - val_loss: 1.8201 - val_accuracy: 0.5640\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5795 - accuracy: 0.8023 - val_loss: 1.8575 - val_accuracy: 0.5531\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5394 - accuracy: 0.8126 - val_loss: 1.8769 - val_accuracy: 0.5725\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5463 - accuracy: 0.8188 - val_loss: 1.8264 - val_accuracy: 0.5664\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5257 - accuracy: 0.8240 - val_loss: 1.8461 - val_accuracy: 0.5616\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5592 - accuracy: 0.8173 - val_loss: 1.8229 - val_accuracy: 0.5519\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5516 - accuracy: 0.8168 - val_loss: 1.8489 - val_accuracy: 0.5688\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4972 - accuracy: 0.8323 - val_loss: 1.9127 - val_accuracy: 0.5435\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5241 - accuracy: 0.8328 - val_loss: 1.8880 - val_accuracy: 0.5616\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5001 - accuracy: 0.8344 - val_loss: 1.8723 - val_accuracy: 0.5737\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4913 - accuracy: 0.8333 - val_loss: 1.9116 - val_accuracy: 0.5797\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4878 - accuracy: 0.8354 - val_loss: 1.9895 - val_accuracy: 0.5362\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4762 - accuracy: 0.8483 - val_loss: 1.8567 - val_accuracy: 0.5604\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.4629 - accuracy: 0.8494 - val_loss: 1.9160 - val_accuracy: 0.5459\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4294 - accuracy: 0.8582 - val_loss: 2.1348 - val_accuracy: 0.5290\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4287 - accuracy: 0.8566 - val_loss: 2.2891 - val_accuracy: 0.5386\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4559 - accuracy: 0.8463 - val_loss: 2.0919 - val_accuracy: 0.5640\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4115 - accuracy: 0.8649 - val_loss: 2.1222 - val_accuracy: 0.5447\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4254 - accuracy: 0.8561 - val_loss: 2.0461 - val_accuracy: 0.5519\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4032 - accuracy: 0.8701 - val_loss: 2.1206 - val_accuracy: 0.5531\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4100 - accuracy: 0.8597 - val_loss: 2.0970 - val_accuracy: 0.5749\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3831 - accuracy: 0.8742 - val_loss: 2.2270 - val_accuracy: 0.5580\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3677 - accuracy: 0.8722 - val_loss: 2.3200 - val_accuracy: 0.5616\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3649 - accuracy: 0.8804 - val_loss: 2.1318 - val_accuracy: 0.5568\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3743 - accuracy: 0.8804 - val_loss: 2.2667 - val_accuracy: 0.5519\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3682 - accuracy: 0.8830 - val_loss: 2.3790 - val_accuracy: 0.5254\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3382 - accuracy: 0.8913 - val_loss: 2.1369 - val_accuracy: 0.5604\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3354 - accuracy: 0.8960 - val_loss: 2.1730 - val_accuracy: 0.5725\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3458 - accuracy: 0.8841 - val_loss: 2.3391 - val_accuracy: 0.5640\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3527 - accuracy: 0.8846 - val_loss: 2.1676 - val_accuracy: 0.5616\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 2.2158 - val_accuracy: 0.5652\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3340 - accuracy: 0.8887 - val_loss: 2.4837 - val_accuracy: 0.5411\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3326 - accuracy: 0.8934 - val_loss: 2.3919 - val_accuracy: 0.5266\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3141 - accuracy: 0.8970 - val_loss: 2.4366 - val_accuracy: 0.5676\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3164 - accuracy: 0.8954 - val_loss: 2.5164 - val_accuracy: 0.5628\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3087 - accuracy: 0.9032 - val_loss: 2.3958 - val_accuracy: 0.5713\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3034 - accuracy: 0.9042 - val_loss: 2.3130 - val_accuracy: 0.5640\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3028 - accuracy: 0.9053 - val_loss: 2.3583 - val_accuracy: 0.5568\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2900 - accuracy: 0.9073 - val_loss: 2.4301 - val_accuracy: 0.5652\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2966 - accuracy: 0.9073 - val_loss: 2.4691 - val_accuracy: 0.5640\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2925 - accuracy: 0.9058 - val_loss: 2.4759 - val_accuracy: 0.5580\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2813 - accuracy: 0.9125 - val_loss: 2.3099 - val_accuracy: 0.5725\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2492 - accuracy: 0.9198 - val_loss: 2.5422 - val_accuracy: 0.5616\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2836 - accuracy: 0.9068 - val_loss: 2.5740 - val_accuracy: 0.5543\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2695 - accuracy: 0.9156 - val_loss: 2.5470 - val_accuracy: 0.5640\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2864 - accuracy: 0.9110 - val_loss: 2.4118 - val_accuracy: 0.5568\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2580 - accuracy: 0.9151 - val_loss: 2.5301 - val_accuracy: 0.5507\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2889 - accuracy: 0.9068 - val_loss: 2.4856 - val_accuracy: 0.5459\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2358 - accuracy: 0.9203 - val_loss: 2.6055 - val_accuracy: 0.5399\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2406 - accuracy: 0.9270 - val_loss: 2.5767 - val_accuracy: 0.5531\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2440 - accuracy: 0.9234 - val_loss: 2.6720 - val_accuracy: 0.5229\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2641 - accuracy: 0.9130 - val_loss: 2.5234 - val_accuracy: 0.5700\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2411 - accuracy: 0.9239 - val_loss: 2.5553 - val_accuracy: 0.5556\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2229 - accuracy: 0.9296 - val_loss: 2.8188 - val_accuracy: 0.5362\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2460 - accuracy: 0.9193 - val_loss: 2.5636 - val_accuracy: 0.5543\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2153 - accuracy: 0.9369 - val_loss: 2.6629 - val_accuracy: 0.5604\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2356 - accuracy: 0.9281 - val_loss: 2.6128 - val_accuracy: 0.5688\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2298 - accuracy: 0.9286 - val_loss: 2.7357 - val_accuracy: 0.5399\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2254 - accuracy: 0.9327 - val_loss: 2.5903 - val_accuracy: 0.5483\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2225 - accuracy: 0.9281 - val_loss: 2.6758 - val_accuracy: 0.5556\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2071 - accuracy: 0.9384 - val_loss: 2.7835 - val_accuracy: 0.5628\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.2386 - accuracy: 0.9234 - val_loss: 2.5736 - val_accuracy: 0.5471\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2356 - accuracy: 0.9229 - val_loss: 2.6060 - val_accuracy: 0.5543\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2136 - accuracy: 0.9343 - val_loss: 2.7526 - val_accuracy: 0.5483\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2088 - accuracy: 0.9332 - val_loss: 2.9039 - val_accuracy: 0.5447\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2218 - accuracy: 0.9348 - val_loss: 2.6253 - val_accuracy: 0.5568\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1933 - accuracy: 0.9415 - val_loss: 2.8037 - val_accuracy: 0.5399\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1938 - accuracy: 0.9457 - val_loss: 2.7095 - val_accuracy: 0.5374\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1794 - accuracy: 0.9384 - val_loss: 3.0129 - val_accuracy: 0.5350\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2080 - accuracy: 0.9317 - val_loss: 2.9309 - val_accuracy: 0.5435\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1752 - accuracy: 0.9462 - val_loss: 3.1121 - val_accuracy: 0.5483\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1960 - accuracy: 0.9363 - val_loss: 3.2041 - val_accuracy: 0.5302\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1921 - accuracy: 0.9441 - val_loss: 2.6933 - val_accuracy: 0.5568\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1832 - accuracy: 0.9436 - val_loss: 2.7708 - val_accuracy: 0.5640\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1998 - accuracy: 0.9389 - val_loss: 2.7818 - val_accuracy: 0.5556\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1806 - accuracy: 0.9410 - val_loss: 3.1756 - val_accuracy: 0.5157\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2294 - accuracy: 0.9332 - val_loss: 3.0955 - val_accuracy: 0.5435\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1700 - accuracy: 0.9508 - val_loss: 2.9247 - val_accuracy: 0.5507\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1851 - accuracy: 0.9462 - val_loss: 2.8565 - val_accuracy: 0.5399\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1726 - accuracy: 0.9462 - val_loss: 2.8646 - val_accuracy: 0.5592\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1726 - accuracy: 0.9482 - val_loss: 2.9335 - val_accuracy: 0.5483\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1733 - accuracy: 0.9493 - val_loss: 2.8635 - val_accuracy: 0.5604\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1799 - accuracy: 0.9436 - val_loss: 2.8477 - val_accuracy: 0.5459\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1922 - accuracy: 0.9410 - val_loss: 3.1516 - val_accuracy: 0.5254\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1782 - accuracy: 0.9508 - val_loss: 2.9707 - val_accuracy: 0.5700\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1725 - accuracy: 0.9467 - val_loss: 3.0551 - val_accuracy: 0.5435\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1487 - accuracy: 0.9565 - val_loss: 3.1147 - val_accuracy: 0.5519\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1566 - accuracy: 0.9508 - val_loss: 3.0883 - val_accuracy: 0.5616\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1654 - accuracy: 0.9503 - val_loss: 2.9570 - val_accuracy: 0.5471\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1590 - accuracy: 0.9513 - val_loss: 3.1268 - val_accuracy: 0.5543\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1765 - accuracy: 0.9472 - val_loss: 3.0911 - val_accuracy: 0.5447\n",
      "Epoch 108/200\n",
      "49/61 [=======================>......] - ETA: 0s - loss: 0.1669 - accuracy: 0.9483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cb67e54f027f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=200, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 880, 100)     733700      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 880, 100)     0           ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 880, 32)      9632        ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 880, 24)      9624        ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 880, 64)      32064       ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 880, 120)     0           ['conv1d_52[0][0]',              \n",
      "                                                                  'conv1d_53[0][0]',              \n",
      "                                                                  'conv1d_54[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_49 (MaxPooling1D  (None, 176, 120)    0           ['concatenate_7[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 176, 120)     0           ['max_pooling1d_49[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 174, 128)     46208       ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_50 (MaxPooling1D  (None, 34, 128)     0           ['conv1d_55[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 30, 256)      164096      ['max_pooling1d_50[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_51 (MaxPooling1D  (None, 6, 256)      0           ['conv1d_56[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1536)         0           ['max_pooling1d_51[0][0]']       \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 128)          196736      ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 128)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 64)           8256        ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 64)           0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           2080        ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 32)           0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 19)           627         ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,203,023\n",
      "Trainable params: 1,203,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "x = Dropout(.4)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=.0003, decay=.00008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 5s 113ms/step - loss: 2.8861 - accuracy: 0.1372 - val_loss: 2.8414 - val_accuracy: 0.2705\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.7813 - accuracy: 0.1698 - val_loss: 2.7391 - val_accuracy: 0.2935\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.7435 - accuracy: 0.1962 - val_loss: 2.6966 - val_accuracy: 0.2862\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.6838 - accuracy: 0.2086 - val_loss: 2.6847 - val_accuracy: 0.3019\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.6588 - accuracy: 0.2267 - val_loss: 2.6552 - val_accuracy: 0.3031\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.5905 - accuracy: 0.2241 - val_loss: 2.5774 - val_accuracy: 0.3056\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.5783 - accuracy: 0.2433 - val_loss: 2.6359 - val_accuracy: 0.3031\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.5855 - accuracy: 0.2350 - val_loss: 2.6490 - val_accuracy: 0.3007\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.5557 - accuracy: 0.2547 - val_loss: 2.5974 - val_accuracy: 0.3080\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.5328 - accuracy: 0.2474 - val_loss: 2.5703 - val_accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4958 - accuracy: 0.2593 - val_loss: 2.6696 - val_accuracy: 0.2923\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.4786 - accuracy: 0.2629 - val_loss: 2.5173 - val_accuracy: 0.3104\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4641 - accuracy: 0.2671 - val_loss: 2.5879 - val_accuracy: 0.3092\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4288 - accuracy: 0.2847 - val_loss: 2.4172 - val_accuracy: 0.3213\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.4224 - accuracy: 0.2759 - val_loss: 2.6320 - val_accuracy: 0.3056\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4142 - accuracy: 0.2733 - val_loss: 2.6044 - val_accuracy: 0.3128\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.3851 - accuracy: 0.2878 - val_loss: 2.5480 - val_accuracy: 0.3152\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.3780 - accuracy: 0.2826 - val_loss: 2.5274 - val_accuracy: 0.3345\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.3502 - accuracy: 0.2883 - val_loss: 2.5622 - val_accuracy: 0.3611\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.3318 - accuracy: 0.3002 - val_loss: 2.3440 - val_accuracy: 0.3249\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.2937 - accuracy: 0.3194 - val_loss: 2.4831 - val_accuracy: 0.3599\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.2563 - accuracy: 0.3256 - val_loss: 2.2549 - val_accuracy: 0.3780\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.2147 - accuracy: 0.3364 - val_loss: 2.3244 - val_accuracy: 0.4046\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.1704 - accuracy: 0.3613 - val_loss: 2.1982 - val_accuracy: 0.3611\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.1139 - accuracy: 0.3846 - val_loss: 2.1691 - val_accuracy: 0.4348\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.1089 - accuracy: 0.3841 - val_loss: 2.0710 - val_accuracy: 0.4360\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.0701 - accuracy: 0.4042 - val_loss: 1.9678 - val_accuracy: 0.4348\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.0812 - accuracy: 0.4073 - val_loss: 2.0774 - val_accuracy: 0.4324\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.0019 - accuracy: 0.4042 - val_loss: 2.1909 - val_accuracy: 0.4227\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.0089 - accuracy: 0.4032 - val_loss: 1.9518 - val_accuracy: 0.4553\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9738 - accuracy: 0.4161 - val_loss: 2.0418 - val_accuracy: 0.4360\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9823 - accuracy: 0.4187 - val_loss: 1.9178 - val_accuracy: 0.4432\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9183 - accuracy: 0.4306 - val_loss: 1.9730 - val_accuracy: 0.4469\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9306 - accuracy: 0.4203 - val_loss: 2.0924 - val_accuracy: 0.4143\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.9257 - accuracy: 0.4286 - val_loss: 1.8768 - val_accuracy: 0.4517\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9058 - accuracy: 0.4343 - val_loss: 1.9270 - val_accuracy: 0.4420\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.9272 - accuracy: 0.4244 - val_loss: 1.8690 - val_accuracy: 0.4432\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.8843 - accuracy: 0.4343 - val_loss: 2.1538 - val_accuracy: 0.3647\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.8751 - accuracy: 0.4343 - val_loss: 1.8161 - val_accuracy: 0.4662\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.8696 - accuracy: 0.4332 - val_loss: 2.0487 - val_accuracy: 0.4118\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.8392 - accuracy: 0.4513 - val_loss: 1.9274 - val_accuracy: 0.4384\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.8227 - accuracy: 0.4534 - val_loss: 1.8324 - val_accuracy: 0.4601\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.8035 - accuracy: 0.4576 - val_loss: 1.8228 - val_accuracy: 0.4553\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 3s 108ms/step - loss: 1.7906 - accuracy: 0.4570 - val_loss: 1.8620 - val_accuracy: 0.4553\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.7686 - accuracy: 0.4689 - val_loss: 1.8172 - val_accuracy: 0.4662\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7810 - accuracy: 0.4638 - val_loss: 1.7665 - val_accuracy: 0.4734\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 3s 109ms/step - loss: 1.7533 - accuracy: 0.4638 - val_loss: 1.7826 - val_accuracy: 0.4710\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7564 - accuracy: 0.4612 - val_loss: 1.8147 - val_accuracy: 0.4541\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.7398 - accuracy: 0.4658 - val_loss: 1.7743 - val_accuracy: 0.4722\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7018 - accuracy: 0.4746 - val_loss: 1.9958 - val_accuracy: 0.4070\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7199 - accuracy: 0.4669 - val_loss: 1.8051 - val_accuracy: 0.4505\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.6844 - accuracy: 0.4803 - val_loss: 1.7470 - val_accuracy: 0.4686\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.6850 - accuracy: 0.4902 - val_loss: 1.9132 - val_accuracy: 0.4505\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7062 - accuracy: 0.4933 - val_loss: 1.8077 - val_accuracy: 0.4734\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6832 - accuracy: 0.4808 - val_loss: 1.7211 - val_accuracy: 0.4867\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.6318 - accuracy: 0.4855 - val_loss: 1.6945 - val_accuracy: 0.4855\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.6112 - accuracy: 0.4912 - val_loss: 1.7454 - val_accuracy: 0.4903\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6356 - accuracy: 0.4979 - val_loss: 1.7414 - val_accuracy: 0.4843\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.6088 - accuracy: 0.5093 - val_loss: 1.9024 - val_accuracy: 0.4710\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6263 - accuracy: 0.4953 - val_loss: 1.7104 - val_accuracy: 0.4867\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.5872 - accuracy: 0.4990 - val_loss: 1.8437 - val_accuracy: 0.4903\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 1.5903 - accuracy: 0.5140 - val_loss: 1.8010 - val_accuracy: 0.4734\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.5554 - accuracy: 0.5098 - val_loss: 1.7542 - val_accuracy: 0.4771\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.5564 - accuracy: 0.5098 - val_loss: 1.7008 - val_accuracy: 0.4928\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.5449 - accuracy: 0.5295 - val_loss: 1.7116 - val_accuracy: 0.4903\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 1.5328 - accuracy: 0.5336 - val_loss: 1.7193 - val_accuracy: 0.4976\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.5640 - accuracy: 0.5207 - val_loss: 1.7871 - val_accuracy: 0.4674\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.5119 - accuracy: 0.5259 - val_loss: 1.7909 - val_accuracy: 0.4601\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4950 - accuracy: 0.5305 - val_loss: 1.7466 - val_accuracy: 0.5181\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.5127 - accuracy: 0.5295 - val_loss: 1.7308 - val_accuracy: 0.5133\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.4852 - accuracy: 0.5383 - val_loss: 1.8060 - val_accuracy: 0.4928\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.4547 - accuracy: 0.5476 - val_loss: 1.7213 - val_accuracy: 0.4988\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.4612 - accuracy: 0.5481 - val_loss: 1.7221 - val_accuracy: 0.4879\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4276 - accuracy: 0.5528 - val_loss: 1.7502 - val_accuracy: 0.4952\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.4349 - accuracy: 0.5450 - val_loss: 1.9402 - val_accuracy: 0.4408\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4636 - accuracy: 0.5321 - val_loss: 1.7491 - val_accuracy: 0.5145\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.4394 - accuracy: 0.5383 - val_loss: 1.7698 - val_accuracy: 0.4771\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4339 - accuracy: 0.5569 - val_loss: 1.7234 - val_accuracy: 0.5145\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3815 - accuracy: 0.5533 - val_loss: 1.8676 - val_accuracy: 0.4722\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3974 - accuracy: 0.5559 - val_loss: 1.7777 - val_accuracy: 0.4819\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3820 - accuracy: 0.5564 - val_loss: 1.8286 - val_accuracy: 0.4879\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3891 - accuracy: 0.5606 - val_loss: 1.7829 - val_accuracy: 0.4891\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3521 - accuracy: 0.5631 - val_loss: 1.8666 - val_accuracy: 0.4444\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.3729 - accuracy: 0.5580 - val_loss: 1.8108 - val_accuracy: 0.4638\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 1.3771 - accuracy: 0.5476 - val_loss: 1.8383 - val_accuracy: 0.4855\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3699 - accuracy: 0.5621 - val_loss: 2.0245 - val_accuracy: 0.4746\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3054 - accuracy: 0.5802 - val_loss: 1.7982 - val_accuracy: 0.4928\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3088 - accuracy: 0.5771 - val_loss: 1.7773 - val_accuracy: 0.5133\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.3272 - accuracy: 0.5719 - val_loss: 1.7869 - val_accuracy: 0.5157\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.3065 - accuracy: 0.5823 - val_loss: 1.8656 - val_accuracy: 0.4928\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.3325 - accuracy: 0.5704 - val_loss: 1.8879 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.2893 - accuracy: 0.5761 - val_loss: 1.8474 - val_accuracy: 0.4903\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2831 - accuracy: 0.5839 - val_loss: 1.8044 - val_accuracy: 0.5133\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3047 - accuracy: 0.5833 - val_loss: 1.7492 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.2885 - accuracy: 0.5761 - val_loss: 1.8039 - val_accuracy: 0.4964\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.2596 - accuracy: 0.5813 - val_loss: 1.8194 - val_accuracy: 0.4903\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2678 - accuracy: 0.5828 - val_loss: 1.8426 - val_accuracy: 0.5072\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2283 - accuracy: 0.6020 - val_loss: 1.8291 - val_accuracy: 0.4819\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.2206 - accuracy: 0.5989 - val_loss: 1.8002 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2405 - accuracy: 0.5818 - val_loss: 2.2062 - val_accuracy: 0.4626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4298425100>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2784 - accuracy: 0.5844 - val_loss: 1.7574 - val_accuracy: 0.4964\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2457 - accuracy: 0.5942 - val_loss: 1.8897 - val_accuracy: 0.5072\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2404 - accuracy: 0.5937 - val_loss: 1.8630 - val_accuracy: 0.5109\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 1.2265 - accuracy: 0.6035 - val_loss: 1.7694 - val_accuracy: 0.5060\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2094 - accuracy: 0.5989 - val_loss: 1.8367 - val_accuracy: 0.5133\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1796 - accuracy: 0.6035 - val_loss: 2.0629 - val_accuracy: 0.3998\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2013 - accuracy: 0.6071 - val_loss: 1.8257 - val_accuracy: 0.5109\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1526 - accuracy: 0.6185 - val_loss: 1.8691 - val_accuracy: 0.5254\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 1.1574 - accuracy: 0.6123 - val_loss: 1.8108 - val_accuracy: 0.5036\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1529 - accuracy: 0.6263 - val_loss: 1.8755 - val_accuracy: 0.5109\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1092 - accuracy: 0.6310 - val_loss: 1.8763 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1256 - accuracy: 0.6284 - val_loss: 2.0322 - val_accuracy: 0.5145\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1215 - accuracy: 0.6413 - val_loss: 1.9290 - val_accuracy: 0.5205\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0654 - accuracy: 0.6372 - val_loss: 1.9509 - val_accuracy: 0.5072\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0581 - accuracy: 0.6449 - val_loss: 1.9835 - val_accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0589 - accuracy: 0.6527 - val_loss: 1.9572 - val_accuracy: 0.5181\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0569 - accuracy: 0.6563 - val_loss: 1.9781 - val_accuracy: 0.5254\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0661 - accuracy: 0.6449 - val_loss: 1.9489 - val_accuracy: 0.5133\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0308 - accuracy: 0.6429 - val_loss: 1.9786 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0227 - accuracy: 0.6630 - val_loss: 1.8873 - val_accuracy: 0.5278\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 1.0157 - accuracy: 0.6511 - val_loss: 2.0042 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.9873 - accuracy: 0.6713 - val_loss: 2.1186 - val_accuracy: 0.5350\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.9612 - accuracy: 0.6770 - val_loss: 1.9654 - val_accuracy: 0.4915\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9762 - accuracy: 0.6755 - val_loss: 2.0648 - val_accuracy: 0.5290\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9915 - accuracy: 0.6713 - val_loss: 2.3275 - val_accuracy: 0.4891\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9297 - accuracy: 0.6817 - val_loss: 2.1610 - val_accuracy: 0.5072\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.9424 - accuracy: 0.6744 - val_loss: 2.1035 - val_accuracy: 0.5181\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9515 - accuracy: 0.6724 - val_loss: 2.0163 - val_accuracy: 0.5109\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9469 - accuracy: 0.6749 - val_loss: 2.0647 - val_accuracy: 0.5374\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9365 - accuracy: 0.6869 - val_loss: 2.2604 - val_accuracy: 0.5048\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9597 - accuracy: 0.6848 - val_loss: 2.1316 - val_accuracy: 0.4879\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9028 - accuracy: 0.6832 - val_loss: 2.1520 - val_accuracy: 0.5217\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8621 - accuracy: 0.6962 - val_loss: 2.2660 - val_accuracy: 0.5314\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8855 - accuracy: 0.6920 - val_loss: 2.0611 - val_accuracy: 0.5121\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8844 - accuracy: 0.6915 - val_loss: 2.2029 - val_accuracy: 0.5085\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8578 - accuracy: 0.6977 - val_loss: 2.1734 - val_accuracy: 0.5229\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8387 - accuracy: 0.7008 - val_loss: 2.2852 - val_accuracy: 0.5254\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8444 - accuracy: 0.7091 - val_loss: 2.2293 - val_accuracy: 0.5193\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8455 - accuracy: 0.7008 - val_loss: 2.2512 - val_accuracy: 0.5036\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8886 - accuracy: 0.7029 - val_loss: 2.2100 - val_accuracy: 0.5205\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8362 - accuracy: 0.7122 - val_loss: 2.1289 - val_accuracy: 0.5097\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8160 - accuracy: 0.7122 - val_loss: 2.3446 - val_accuracy: 0.5254\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8296 - accuracy: 0.7091 - val_loss: 2.1915 - val_accuracy: 0.5338\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8256 - accuracy: 0.7060 - val_loss: 2.2858 - val_accuracy: 0.5350\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8116 - accuracy: 0.7164 - val_loss: 2.1918 - val_accuracy: 0.5266\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7862 - accuracy: 0.7195 - val_loss: 2.3047 - val_accuracy: 0.5399\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7909 - accuracy: 0.7236 - val_loss: 2.3242 - val_accuracy: 0.5145\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7761 - accuracy: 0.7350 - val_loss: 2.2756 - val_accuracy: 0.5024\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7540 - accuracy: 0.7396 - val_loss: 2.4233 - val_accuracy: 0.5338\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7312 - accuracy: 0.7376 - val_loss: 2.3827 - val_accuracy: 0.5326\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7493 - accuracy: 0.7402 - val_loss: 2.2171 - val_accuracy: 0.5242\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7452 - accuracy: 0.7448 - val_loss: 2.5775 - val_accuracy: 0.5085\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7500 - accuracy: 0.7417 - val_loss: 2.2388 - val_accuracy: 0.5386\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7109 - accuracy: 0.7443 - val_loss: 2.4954 - val_accuracy: 0.5145\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7347 - accuracy: 0.7407 - val_loss: 2.5598 - val_accuracy: 0.5338\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7297 - accuracy: 0.7459 - val_loss: 2.5323 - val_accuracy: 0.5435\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6978 - accuracy: 0.7609 - val_loss: 2.6251 - val_accuracy: 0.5205\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6960 - accuracy: 0.7531 - val_loss: 2.5936 - val_accuracy: 0.5435\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.6847 - accuracy: 0.7614 - val_loss: 2.4615 - val_accuracy: 0.5338\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6648 - accuracy: 0.7697 - val_loss: 2.4331 - val_accuracy: 0.5133\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6939 - accuracy: 0.7541 - val_loss: 2.5501 - val_accuracy: 0.5326\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7023 - accuracy: 0.7583 - val_loss: 2.6862 - val_accuracy: 0.5205\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6686 - accuracy: 0.7697 - val_loss: 2.4433 - val_accuracy: 0.5229\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6924 - accuracy: 0.7557 - val_loss: 2.4473 - val_accuracy: 0.5326\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6847 - accuracy: 0.7635 - val_loss: 2.3938 - val_accuracy: 0.5447\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6777 - accuracy: 0.7697 - val_loss: 2.3531 - val_accuracy: 0.5193\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6504 - accuracy: 0.7785 - val_loss: 2.6729 - val_accuracy: 0.5217\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6452 - accuracy: 0.7852 - val_loss: 2.6209 - val_accuracy: 0.5072\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6348 - accuracy: 0.7852 - val_loss: 2.5896 - val_accuracy: 0.5302\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6170 - accuracy: 0.7888 - val_loss: 2.5461 - val_accuracy: 0.5157\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6082 - accuracy: 0.7873 - val_loss: 2.7019 - val_accuracy: 0.5411\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6353 - accuracy: 0.7940 - val_loss: 2.5372 - val_accuracy: 0.5254\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6040 - accuracy: 0.7945 - val_loss: 2.5384 - val_accuracy: 0.5193\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5934 - accuracy: 0.7992 - val_loss: 2.6678 - val_accuracy: 0.5290\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6143 - accuracy: 0.7867 - val_loss: 2.6392 - val_accuracy: 0.5229\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6195 - accuracy: 0.7873 - val_loss: 2.8649 - val_accuracy: 0.5471\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.6145 - accuracy: 0.7914 - val_loss: 2.7866 - val_accuracy: 0.5169\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6032 - accuracy: 0.7935 - val_loss: 2.7970 - val_accuracy: 0.5254\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5726 - accuracy: 0.7966 - val_loss: 2.6996 - val_accuracy: 0.5266\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5559 - accuracy: 0.8069 - val_loss: 2.8125 - val_accuracy: 0.5242\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5538 - accuracy: 0.8100 - val_loss: 2.7374 - val_accuracy: 0.5193\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5673 - accuracy: 0.8111 - val_loss: 2.8036 - val_accuracy: 0.5326\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5464 - accuracy: 0.8126 - val_loss: 2.9280 - val_accuracy: 0.5447\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5694 - accuracy: 0.8033 - val_loss: 3.0114 - val_accuracy: 0.5338\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5332 - accuracy: 0.8225 - val_loss: 2.6997 - val_accuracy: 0.5290\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5260 - accuracy: 0.8225 - val_loss: 3.0751 - val_accuracy: 0.5242\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5481 - accuracy: 0.8142 - val_loss: 2.9539 - val_accuracy: 0.5133\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5501 - accuracy: 0.8178 - val_loss: 2.7995 - val_accuracy: 0.5181\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5386 - accuracy: 0.8131 - val_loss: 2.5509 - val_accuracy: 0.5121\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5267 - accuracy: 0.8219 - val_loss: 2.7742 - val_accuracy: 0.5302\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5257 - accuracy: 0.8307 - val_loss: 2.9228 - val_accuracy: 0.5302\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5350 - accuracy: 0.8137 - val_loss: 2.8183 - val_accuracy: 0.5205\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5475 - accuracy: 0.8204 - val_loss: 2.7037 - val_accuracy: 0.5290\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5125 - accuracy: 0.8328 - val_loss: 3.0115 - val_accuracy: 0.5386\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.5120 - accuracy: 0.8183 - val_loss: 2.8394 - val_accuracy: 0.5085\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5065 - accuracy: 0.8292 - val_loss: 2.8374 - val_accuracy: 0.5229\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.4772 - accuracy: 0.8271 - val_loss: 3.1375 - val_accuracy: 0.5181\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5131 - accuracy: 0.8328 - val_loss: 3.0833 - val_accuracy: 0.5205\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5097 - accuracy: 0.8282 - val_loss: 2.8459 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5044 - accuracy: 0.8318 - val_loss: 2.8745 - val_accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41887d32b0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 880)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 880, 100)          733700    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 880, 100)          0         \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 32)                12864     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 19)                627       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 747,191\n",
      "Trainable params: 747,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(32, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.2)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(19, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.007, decay=.0008, centered=True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 19s 286ms/step - loss: 2.6704 - accuracy: 0.2003 - val_loss: 2.5229 - val_accuracy: 0.2802\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 18s 291ms/step - loss: 2.4670 - accuracy: 0.2598 - val_loss: 2.2877 - val_accuracy: 0.3140\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 17s 280ms/step - loss: 2.2426 - accuracy: 0.3080 - val_loss: 2.1624 - val_accuracy: 0.3551\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 17s 270ms/step - loss: 2.0604 - accuracy: 0.3872 - val_loss: 1.9177 - val_accuracy: 0.4239\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 1.8741 - accuracy: 0.4369 - val_loss: 1.7877 - val_accuracy: 0.4529\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 17s 278ms/step - loss: 1.7288 - accuracy: 0.4912 - val_loss: 1.6795 - val_accuracy: 0.4783\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 16s 256ms/step - loss: 1.6110 - accuracy: 0.5238 - val_loss: 1.6563 - val_accuracy: 0.5012\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 16s 266ms/step - loss: 1.4986 - accuracy: 0.5466 - val_loss: 1.7533 - val_accuracy: 0.4626\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 17s 272ms/step - loss: 1.4153 - accuracy: 0.5600 - val_loss: 1.5592 - val_accuracy: 0.5350\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 17s 279ms/step - loss: 1.3042 - accuracy: 0.5885 - val_loss: 1.5323 - val_accuracy: 0.5399\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 16s 265ms/step - loss: 1.2069 - accuracy: 0.6356 - val_loss: 1.5824 - val_accuracy: 0.5447\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 17s 275ms/step - loss: 1.1765 - accuracy: 0.6289 - val_loss: 1.5473 - val_accuracy: 0.5435\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 16s 264ms/step - loss: 1.0725 - accuracy: 0.6760 - val_loss: 1.5503 - val_accuracy: 0.5700\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 17s 279ms/step - loss: 1.0177 - accuracy: 0.6951 - val_loss: 1.6116 - val_accuracy: 0.5507\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 17s 279ms/step - loss: 0.9571 - accuracy: 0.7127 - val_loss: 1.6172 - val_accuracy: 0.5374\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 17s 285ms/step - loss: 0.9101 - accuracy: 0.7127 - val_loss: 1.6364 - val_accuracy: 0.5266\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 16s 260ms/step - loss: 0.8684 - accuracy: 0.7365 - val_loss: 1.6052 - val_accuracy: 0.5543\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 16s 265ms/step - loss: 0.8378 - accuracy: 0.7360 - val_loss: 1.7357 - val_accuracy: 0.5531\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 17s 274ms/step - loss: 0.7975 - accuracy: 0.7588 - val_loss: 1.7691 - val_accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 16s 255ms/step - loss: 0.7544 - accuracy: 0.7692 - val_loss: 1.7157 - val_accuracy: 0.5543\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 17s 282ms/step - loss: 0.6989 - accuracy: 0.7935 - val_loss: 1.8324 - val_accuracy: 0.5664\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 16s 258ms/step - loss: 0.6902 - accuracy: 0.7852 - val_loss: 1.7571 - val_accuracy: 0.5543\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 16s 269ms/step - loss: 0.6696 - accuracy: 0.7924 - val_loss: 1.7747 - val_accuracy: 0.5580\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 17s 279ms/step - loss: 0.6568 - accuracy: 0.7955 - val_loss: 1.8490 - val_accuracy: 0.5447\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 17s 276ms/step - loss: 0.6039 - accuracy: 0.8116 - val_loss: 1.8067 - val_accuracy: 0.5640\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 17s 280ms/step - loss: 0.5871 - accuracy: 0.8245 - val_loss: 1.8466 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 16s 269ms/step - loss: 0.5803 - accuracy: 0.8240 - val_loss: 1.8114 - val_accuracy: 0.5676\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 17s 280ms/step - loss: 0.5385 - accuracy: 0.8364 - val_loss: 1.8508 - val_accuracy: 0.5580\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 17s 275ms/step - loss: 0.5311 - accuracy: 0.8395 - val_loss: 1.8800 - val_accuracy: 0.5483\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 16s 258ms/step - loss: 0.5244 - accuracy: 0.8380 - val_loss: 1.8453 - val_accuracy: 0.5568\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 16s 264ms/step - loss: 0.4873 - accuracy: 0.8577 - val_loss: 1.8949 - val_accuracy: 0.5737\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 16s 270ms/step - loss: 0.4853 - accuracy: 0.8571 - val_loss: 1.8266 - val_accuracy: 0.5688\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 17s 282ms/step - loss: 0.4765 - accuracy: 0.8551 - val_loss: 1.8866 - val_accuracy: 0.5688\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 18s 288ms/step - loss: 0.4458 - accuracy: 0.8696 - val_loss: 2.0540 - val_accuracy: 0.5314\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 17s 275ms/step - loss: 0.4630 - accuracy: 0.8639 - val_loss: 1.9883 - val_accuracy: 0.5495\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 16s 265ms/step - loss: 0.4452 - accuracy: 0.8649 - val_loss: 1.9490 - val_accuracy: 0.5676\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 16s 267ms/step - loss: 0.4157 - accuracy: 0.8778 - val_loss: 1.9411 - val_accuracy: 0.5785\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 16s 265ms/step - loss: 0.3987 - accuracy: 0.8892 - val_loss: 2.0257 - val_accuracy: 0.5592\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 16s 268ms/step - loss: 0.3964 - accuracy: 0.8835 - val_loss: 2.0235 - val_accuracy: 0.5821\n",
      "Epoch 40/100\n",
      "13/61 [=====>........................] - ETA: 11s - loss: 0.3810 - accuracy: 0.8798"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5ea1866fd44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 880)]             0         \n",
      "                                                                 \n",
      " embedding_47 (Embedding)    (None, 880, 100)          733700    \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 880, 100)          0         \n",
      "                                                                 \n",
      " conv1d_155 (Conv1D)         (None, 880, 64)           32064     \n",
      "                                                                 \n",
      " max_pooling1d_76 (MaxPoolin  (None, 176, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " gru_38 (GRU)                (None, 32)                9408      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 25)                825       \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 19)                494       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 776,491\n",
      "Trainable params: 776,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "conv1 = Conv1D(filters=64,\n",
    "               kernel_size=5,\n",
    "               strides=1,\n",
    "               activation='softplus',\n",
    "               padding='same')(y)\n",
    "x = MaxPooling1D(5)(conv1)\n",
    "#x = GRU(128, return_sequences=True)(x)\n",
    "#lstm1 = GRU(64, return_sequences=True)(x)\n",
    "lstm2 = GRU(32)(x)\n",
    "x = Flatten()(lstm2)\n",
    "x = Dropout(.3)(x)\n",
    "x = Dense(25, activation = 'softplus')(lstm2)\n",
    "x = Dropout(.2)(x)\n",
    "output_layer = Dense(19, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.01, decay=.008, centered=True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 8s 93ms/step - loss: 2.5949 - accuracy: 0.2464 - val_loss: 2.4962 - val_accuracy: 0.2802\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 2.5004 - accuracy: 0.2681 - val_loss: 2.3404 - val_accuracy: 0.2802\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 2.2940 - accuracy: 0.2966 - val_loss: 2.1310 - val_accuracy: 0.3309\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 2.1026 - accuracy: 0.3701 - val_loss: 1.9592 - val_accuracy: 0.4384\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.9492 - accuracy: 0.4027 - val_loss: 1.9536 - val_accuracy: 0.3708\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.8361 - accuracy: 0.4322 - val_loss: 1.8164 - val_accuracy: 0.4529\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.7831 - accuracy: 0.4420 - val_loss: 1.8469 - val_accuracy: 0.4215\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.7078 - accuracy: 0.4664 - val_loss: 1.7478 - val_accuracy: 0.4505\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.6347 - accuracy: 0.4886 - val_loss: 1.7235 - val_accuracy: 0.4758\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.5844 - accuracy: 0.5052 - val_loss: 1.7156 - val_accuracy: 0.4807\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.5071 - accuracy: 0.5295 - val_loss: 1.7362 - val_accuracy: 0.4758\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.4821 - accuracy: 0.5274 - val_loss: 1.6873 - val_accuracy: 0.4722\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.4226 - accuracy: 0.5326 - val_loss: 1.7354 - val_accuracy: 0.4589\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.3964 - accuracy: 0.5352 - val_loss: 1.7519 - val_accuracy: 0.4529\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.3743 - accuracy: 0.5657 - val_loss: 1.7511 - val_accuracy: 0.4722\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.3208 - accuracy: 0.5637 - val_loss: 1.7030 - val_accuracy: 0.4746\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.2886 - accuracy: 0.5782 - val_loss: 1.6838 - val_accuracy: 0.4807\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.2685 - accuracy: 0.5864 - val_loss: 1.7062 - val_accuracy: 0.4783\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.2313 - accuracy: 0.5973 - val_loss: 1.7116 - val_accuracy: 0.4662\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1791 - accuracy: 0.6035 - val_loss: 1.7134 - val_accuracy: 0.5024\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1885 - accuracy: 0.6051 - val_loss: 1.7311 - val_accuracy: 0.5085\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.1474 - accuracy: 0.6123 - val_loss: 1.7464 - val_accuracy: 0.4976\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1278 - accuracy: 0.6232 - val_loss: 1.7445 - val_accuracy: 0.5229\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1091 - accuracy: 0.6304 - val_loss: 1.7956 - val_accuracy: 0.5145\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0858 - accuracy: 0.6351 - val_loss: 1.7629 - val_accuracy: 0.5169\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0636 - accuracy: 0.6403 - val_loss: 1.7847 - val_accuracy: 0.5254\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0553 - accuracy: 0.6403 - val_loss: 1.7724 - val_accuracy: 0.5060\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0354 - accuracy: 0.6589 - val_loss: 1.7901 - val_accuracy: 0.5133\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.0193 - accuracy: 0.6599 - val_loss: 1.7862 - val_accuracy: 0.5266\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0058 - accuracy: 0.6729 - val_loss: 1.8010 - val_accuracy: 0.5145\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9834 - accuracy: 0.6687 - val_loss: 1.8142 - val_accuracy: 0.5205\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9701 - accuracy: 0.6713 - val_loss: 1.8145 - val_accuracy: 0.5229\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9591 - accuracy: 0.6801 - val_loss: 1.8069 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.9454 - accuracy: 0.6894 - val_loss: 1.8313 - val_accuracy: 0.5217\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9426 - accuracy: 0.6749 - val_loss: 1.8662 - val_accuracy: 0.5169\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.9400 - accuracy: 0.6801 - val_loss: 1.8860 - val_accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.9148 - accuracy: 0.6946 - val_loss: 1.8532 - val_accuracy: 0.5048\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.8936 - accuracy: 0.6967 - val_loss: 1.8755 - val_accuracy: 0.5072\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8978 - accuracy: 0.7008 - val_loss: 1.9088 - val_accuracy: 0.5133\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 5s 89ms/step - loss: 0.8908 - accuracy: 0.7029 - val_loss: 1.9784 - val_accuracy: 0.5193\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8467 - accuracy: 0.7200 - val_loss: 1.9003 - val_accuracy: 0.5097\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8613 - accuracy: 0.7112 - val_loss: 1.9439 - val_accuracy: 0.4903\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8401 - accuracy: 0.7164 - val_loss: 1.9203 - val_accuracy: 0.5036\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8448 - accuracy: 0.7179 - val_loss: 1.9173 - val_accuracy: 0.5024\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8306 - accuracy: 0.7262 - val_loss: 1.9547 - val_accuracy: 0.5121\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8071 - accuracy: 0.7329 - val_loss: 2.0185 - val_accuracy: 0.5302\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8097 - accuracy: 0.7236 - val_loss: 1.9943 - val_accuracy: 0.5217\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7805 - accuracy: 0.7371 - val_loss: 2.0075 - val_accuracy: 0.5133\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8069 - accuracy: 0.7319 - val_loss: 2.0982 - val_accuracy: 0.5193\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.7958 - accuracy: 0.7350 - val_loss: 1.9832 - val_accuracy: 0.5072\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7935 - accuracy: 0.7334 - val_loss: 2.0065 - val_accuracy: 0.5121\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7680 - accuracy: 0.7360 - val_loss: 2.0158 - val_accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7710 - accuracy: 0.7324 - val_loss: 2.0036 - val_accuracy: 0.5024\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7831 - accuracy: 0.7350 - val_loss: 2.0191 - val_accuracy: 0.4976\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7551 - accuracy: 0.7495 - val_loss: 2.0443 - val_accuracy: 0.5181\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7369 - accuracy: 0.7547 - val_loss: 2.0775 - val_accuracy: 0.5097\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7296 - accuracy: 0.7598 - val_loss: 2.0721 - val_accuracy: 0.5109\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7191 - accuracy: 0.7629 - val_loss: 2.1017 - val_accuracy: 0.4988\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7053 - accuracy: 0.7598 - val_loss: 2.0827 - val_accuracy: 0.5205\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7327 - accuracy: 0.7598 - val_loss: 2.0984 - val_accuracy: 0.5229\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7039 - accuracy: 0.7635 - val_loss: 2.0736 - val_accuracy: 0.5060\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7002 - accuracy: 0.7697 - val_loss: 2.1503 - val_accuracy: 0.5133\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6867 - accuracy: 0.7686 - val_loss: 2.1141 - val_accuracy: 0.5157\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6891 - accuracy: 0.7738 - val_loss: 2.1361 - val_accuracy: 0.5254\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6914 - accuracy: 0.7676 - val_loss: 2.1893 - val_accuracy: 0.5048\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6994 - accuracy: 0.7754 - val_loss: 2.1630 - val_accuracy: 0.5205\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7125 - accuracy: 0.7598 - val_loss: 2.1377 - val_accuracy: 0.5157\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6687 - accuracy: 0.7764 - val_loss: 2.1403 - val_accuracy: 0.5109\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6619 - accuracy: 0.7836 - val_loss: 2.1675 - val_accuracy: 0.5121\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6720 - accuracy: 0.7774 - val_loss: 2.1554 - val_accuracy: 0.5157\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6654 - accuracy: 0.7790 - val_loss: 2.1775 - val_accuracy: 0.5193\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6320 - accuracy: 0.7955 - val_loss: 2.1686 - val_accuracy: 0.5109\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6333 - accuracy: 0.7842 - val_loss: 2.2219 - val_accuracy: 0.5314\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6330 - accuracy: 0.7847 - val_loss: 2.2013 - val_accuracy: 0.5314\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6367 - accuracy: 0.7867 - val_loss: 2.2452 - val_accuracy: 0.5181\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6336 - accuracy: 0.7800 - val_loss: 2.2365 - val_accuracy: 0.5205\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6215 - accuracy: 0.7945 - val_loss: 2.2594 - val_accuracy: 0.5157\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6347 - accuracy: 0.7919 - val_loss: 2.2492 - val_accuracy: 0.5169\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6486 - accuracy: 0.7748 - val_loss: 2.2870 - val_accuracy: 0.5217\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6334 - accuracy: 0.7930 - val_loss: 2.2525 - val_accuracy: 0.5242\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6281 - accuracy: 0.7873 - val_loss: 2.3356 - val_accuracy: 0.5048\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6212 - accuracy: 0.8043 - val_loss: 2.2567 - val_accuracy: 0.5133\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6082 - accuracy: 0.8038 - val_loss: 2.3658 - val_accuracy: 0.5157\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6066 - accuracy: 0.8059 - val_loss: 2.2928 - val_accuracy: 0.5181\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6284 - accuracy: 0.7842 - val_loss: 2.3505 - val_accuracy: 0.5109\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6245 - accuracy: 0.7981 - val_loss: 2.2692 - val_accuracy: 0.5121\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6036 - accuracy: 0.8028 - val_loss: 2.3103 - val_accuracy: 0.5205\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5886 - accuracy: 0.7940 - val_loss: 2.3923 - val_accuracy: 0.5109\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5747 - accuracy: 0.8121 - val_loss: 2.3057 - val_accuracy: 0.5133\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5574 - accuracy: 0.8188 - val_loss: 2.3466 - val_accuracy: 0.5290\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5684 - accuracy: 0.8137 - val_loss: 2.3323 - val_accuracy: 0.5205\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5689 - accuracy: 0.8085 - val_loss: 2.3653 - val_accuracy: 0.5145\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.5557 - accuracy: 0.8116 - val_loss: 2.4121 - val_accuracy: 0.5205\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5772 - accuracy: 0.8121 - val_loss: 2.4116 - val_accuracy: 0.5169\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5738 - accuracy: 0.8116 - val_loss: 2.3635 - val_accuracy: 0.5217\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5631 - accuracy: 0.8157 - val_loss: 2.3268 - val_accuracy: 0.5157\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.5838 - accuracy: 0.8090 - val_loss: 2.3874 - val_accuracy: 0.5181\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5628 - accuracy: 0.8173 - val_loss: 2.4396 - val_accuracy: 0.5254\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.5888 - accuracy: 0.8054 - val_loss: 2.3745 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.5668 - accuracy: 0.8204 - val_loss: 2.4050 - val_accuracy: 0.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f42b1003a30>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
