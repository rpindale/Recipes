{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Apple Cranberry Pecan Salad</td>\n",
       "      <td>6 cups baby spinach 1 Granny Smith apple, thi...</td>\n",
       "      <td>To make the vinaigrette, whisk together olive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salad</td>\n",
       "      <td>Asian Pasta Salad</td>\n",
       "      <td>8 ounces elbows pasta 1 California Avocado, h...</td>\n",
       "      <td>To make the dressing, whisk together soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick-easy</td>\n",
       "      <td>Vegetable Kabobs</td>\n",
       "      <td>2 cups cremini mushrooms 1 cup cherry tomatoe...</td>\n",
       "      <td>Preheat oven to 400 degrees F. In a small bow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salad</td>\n",
       "      <td>Harvest Cobb Salad</td>\n",
       "      <td>4 slices bacon, diced 2 large eggs 6 cups cho...</td>\n",
       "      <td>To make the poppy seed dressing, whisk togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicken-recipes</td>\n",
       "      <td>Quick Chicken and Broccoli Stir Fry</td>\n",
       "      <td>1 pound boneless, skinless chicken breasts, c...</td>\n",
       "      <td>In a small bowl, whisk together soy sauce, oy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                title  \\\n",
       "0        appetizer          Apple Cranberry Pecan Salad   \n",
       "1            salad                    Asian Pasta Salad   \n",
       "2       quick-easy                     Vegetable Kabobs   \n",
       "3            salad                   Harvest Cobb Salad   \n",
       "4  chicken-recipes  Quick Chicken and Broccoli Stir Fry   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0   6 cups baby spinach 1 Granny Smith apple, thi...   \n",
       "1   8 ounces elbows pasta 1 California Avocado, h...   \n",
       "2   2 cups cremini mushrooms 1 cup cherry tomatoe...   \n",
       "3   4 slices bacon, diced 2 large eggs 6 cups cho...   \n",
       "4   1 pound boneless, skinless chicken breasts, c...   \n",
       "\n",
       "                                        instructions  \n",
       "0   To make the vinaigrette, whisk together olive...  \n",
       "1   To make the dressing, whisk together soy sauc...  \n",
       "2   Preheat oven to 400 degrees F. In a small bow...  \n",
       "3   To make the poppy seed dressing, whisk togeth...  \n",
       "4   In a small bowl, whisk together soy sauce, oy...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "colin = pd.read_csv('colin_webscrap.csv')\n",
    "colin.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(colin.shape)\n",
    "colin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4479, 4)\n",
      "(1608, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>side</td>\n",
       "      <td>Moroccan Couscous Recipe (with Roasted Veggies)</td>\n",
       "      <td>1  large red bell pepper, (cored and diced) 2 ...</td>\n",
       "      <td>Preheat oven to 475 degrees. Spray a 18 by 13-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>main-dish</td>\n",
       "      <td>Honey Garlic Chicken (Oven Baked)</td>\n",
       "      <td>1 1/2 lbs bonless skinless chicken breasts (, ...</td>\n",
       "      <td>Preheat oven to 400 degrees. Line a rimmed 18 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>main-dish</td>\n",
       "      <td>Best Turkey Chili Recipe</td>\n",
       "      <td>2 Tbsp olive oil 20 oz 93% lean ground turkey ...</td>\n",
       "      <td>Heat 1 Tbsp olive oil in a large pot over medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>bars</td>\n",
       "      <td>Lemon Cream Pie Bars</td>\n",
       "      <td>1 1/2 cups finely crushed graham cracker crumb...</td>\n",
       "      <td>Preheat oven to 350 degrees. Butter an 8 by 8-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>muffins</td>\n",
       "      <td>How to Make Homemade Donuts in 15 Minutes</td>\n",
       "      <td>1 1/4 cups (176g) all-purpose flour ((scoop an...</td>\n",
       "      <td>Pour about 1/2-inch oil into a large saute pan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                            title  \\\n",
       "4001       side  Moroccan Couscous Recipe (with Roasted Veggies)   \n",
       "3029  main-dish                Honey Garlic Chicken (Oven Baked)   \n",
       "2732  main-dish                         Best Turkey Chili Recipe   \n",
       "584        bars                             Lemon Cream Pie Bars   \n",
       "3361    muffins        How to Make Homemade Donuts in 15 Minutes   \n",
       "\n",
       "                                            ingredients  \\\n",
       "4001  1  large red bell pepper, (cored and diced) 2 ...   \n",
       "3029  1 1/2 lbs bonless skinless chicken breasts (, ...   \n",
       "2732  2 Tbsp olive oil 20 oz 93% lean ground turkey ...   \n",
       "584   1 1/2 cups finely crushed graham cracker crumb...   \n",
       "3361  1 1/4 cups (176g) all-purpose flour ((scoop an...   \n",
       "\n",
       "                                           instructions  \n",
       "4001  Preheat oven to 475 degrees. Spray a 18 by 13-...  \n",
       "3029  Preheat oven to 400 degrees. Line a rimmed 18 ...  \n",
       "2732  Heat 1 Tbsp olive oil in a large pot over medi...  \n",
       "584   Preheat oven to 350 degrees. Butter an 8 by 8-...  \n",
       "3361  Pour about 1/2-inch oil into a large saute pan...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan = pd.read_csv('cooking_classy_text_data.csv')\n",
    "ryan.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(ryan.shape)\n",
    "ryan.isna().sum()\n",
    "ryan = ryan.sample(frac=1, random_state=42)\n",
    "#ryan.head()\n",
    "print(ryan.drop_duplicates('title').shape)\n",
    "ryan = ryan.drop_duplicates('title')\n",
    "ryan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ryan = ryan.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicates\n",
    "colin.drop_duplicates('title').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Title</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Gnocchi, Mushroom and Kale Soup</td>\n",
       "      <td>Sauté the veggies. Heat oil in a large stockpo...</td>\n",
       "      <td>2 tablespoons olive oil 1 medium white onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Greek Salmon Salad Bowls</td>\n",
       "      <td>Cook the salmon. Season the salmon with a few ...</td>\n",
       "      <td>1 pound salmon filets fine sea salt and freshl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Pasta alla Boscaiola</td>\n",
       "      <td>Soften the mushrooms. In a medium saucepan, st...</td>\n",
       "      <td>3 cups vegetable broth 1 ounce dried porcini m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Lemony Lentil Soup</td>\n",
       "      <td>Stovetop Instructions:  Sauté the veggies. Hea...</td>\n",
       "      <td>1 tablespoon olive oil 1 medium white onion, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Guinness Beef Stew</td>\n",
       "      <td>Sear the beef. Generously season the beef with...</td>\n",
       "      <td>3 tablespoons olive oil, divided 3 pounds beef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cat                            Title  \\\n",
       "0  main-course  Gnocchi, Mushroom and Kale Soup   \n",
       "1  main-course         Greek Salmon Salad Bowls   \n",
       "2  main-course             Pasta alla Boscaiola   \n",
       "3  main-course               Lemony Lentil Soup   \n",
       "4  main-course               Guinness Beef Stew   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Sauté the veggies. Heat oil in a large stockpo...   \n",
       "1  Cook the salmon. Season the salmon with a few ...   \n",
       "2  Soften the mushrooms. In a medium saucepan, st...   \n",
       "3  Stovetop Instructions:  Sauté the veggies. Hea...   \n",
       "4  Sear the beef. Generously season the beef with...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  2 tablespoons olive oil 1 medium white onion, ...  \n",
       "1  1 pound salmon filets fine sea salt and freshl...  \n",
       "2  3 cups vegetable broth 1 ounce dried porcini m...  \n",
       "3  1 tablespoon olive oil 1 medium white onion, p...  \n",
       "4  3 tablespoons olive oil, divided 3 pounds beef...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = pd.read_csv('GSOScrapped.csv')\n",
    "print(ed.shape)\n",
    "ed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.drop_duplicates('Title').shape\n",
    "ed = ed.drop_duplicates('Title')\n",
    "ed = ed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1362, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'Title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = ed.rename(columns={'Title':'title'})\n",
    "ryan = ryan.rename(columns={'category':'cat'})\n",
    "print(ryan.columns)\n",
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4052, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = colin.append(ed).reset_index().drop('index',axis=1)\n",
    "merged = merged.append(ryan).reset_index().drop('index', axis=1)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>healthy</td>\n",
       "      <td>Mango Salsa {with Avocado!}</td>\n",
       "      <td>2 cups peeled and diced mangoes, ((about 2 sma...</td>\n",
       "      <td>In a medium mixing bowl toss together all ingr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>drinks</td>\n",
       "      <td>Sparkling Limeade with Honey Recipe</td>\n",
       "      <td>1 liter club soda or sparkling water (, chille...</td>\n",
       "      <td>In a pitcher whisk together 1/2 cup water and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>treats</td>\n",
       "      <td>Cookies and Cream Muddy Buddies</td>\n",
       "      <td>6 cups Corn Chex Cereal 1/2 cup very finely cr...</td>\n",
       "      <td>Measure 6 cups Corn Chex Cereal into a large m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>drinks</td>\n",
       "      <td>Brazilian Limeade</td>\n",
       "      <td>4 cups cold water, (divided) 3/4 cup fresh lim...</td>\n",
       "      <td>To a blender jar add 3 cups water, lime juice,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>3-Ingredient Queso Cheese Dip</td>\n",
       "      <td>1 cup half and half 1 Tbsp Argo Corn Starch 8 ...</td>\n",
       "      <td>In a medium saucepan whisk together half and h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cat                                title  \\\n",
       "4047    healthy          Mango Salsa {with Avocado!}   \n",
       "4048     drinks  Sparkling Limeade with Honey Recipe   \n",
       "4049     treats      Cookies and Cream Muddy Buddies   \n",
       "4050     drinks                    Brazilian Limeade   \n",
       "4051  appetizer        3-Ingredient Queso Cheese Dip   \n",
       "\n",
       "                                            ingredients  \\\n",
       "4047  2 cups peeled and diced mangoes, ((about 2 sma...   \n",
       "4048  1 liter club soda or sparkling water (, chille...   \n",
       "4049  6 cups Corn Chex Cereal 1/2 cup very finely cr...   \n",
       "4050  4 cups cold water, (divided) 3/4 cup fresh lim...   \n",
       "4051  1 cup half and half 1 Tbsp Argo Corn Starch 8 ...   \n",
       "\n",
       "                                           instructions  \n",
       "4047  In a medium mixing bowl toss together all ingr...  \n",
       "4048  In a pitcher whisk together 1/2 cup water and ...  \n",
       "4049  Measure 6 cups Corn Chex Cereal into a large m...  \n",
       "4050  To a blender jar add 3 cups water, lime juice,...  \n",
       "4051  In a medium saucepan whisk together half and h...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course           618\n",
       "dessert               498\n",
       "breakfast             259\n",
       "main-dish             194\n",
       "appetizer             194\n",
       "                     ... \n",
       "pizzas                  8\n",
       "holidays/spring         7\n",
       "spreads                 6\n",
       "tarts-and-pastries      5\n",
       "instant-pot             3\n",
       "Name: cat, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course        896\n",
       "dessert            713\n",
       "appetizers         363\n",
       "breakfast          259\n",
       "quick-easy         207\n",
       "holidays           199\n",
       "chicken-recipes    179\n",
       "drinks             156\n",
       "healthy            151\n",
       "pasta              136\n",
       "vegetarian         124\n",
       "asian              109\n",
       "soup               105\n",
       "seasonal            92\n",
       "slow-cooker         76\n",
       "baked-goods         54\n",
       "one-pot             39\n",
       "sauces              37\n",
       "game-day            35\n",
       "seafood             29\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged.cat == 'ice-cream', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'poultry', 'cat'] = 'chicken-recipes'\n",
    "merged.loc[merged.cat == 'instant-pot', 'cat'] = 'slow-cooker'\n",
    "merged.loc[merged.cat == 'italian', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'treats', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'bars', 'cat'] = 'dessert'\n",
    "merged = merged.drop(merged[merged.cat == 'mexican'].index)\n",
    "merged = merged.drop(merged[merged.cat == 'side'].index)\n",
    "merged.loc[merged.cat == 'appetizer', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'pastas', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'bread', 'cat'] = 'baked-goods'\n",
    "merged.loc[merged.cat == 'snacks', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'beverages', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'entree','cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'drink', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'smoothies', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'spreads', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'salsas-sauces', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'dip', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'pizzas', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'sandwiches', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'sandwich', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'fall', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'summer', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'side-dish', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'salad', 'cat'] = 'vegetarian'\n",
    "merged.loc[merged.cat == 'meal-prep', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'thanksgiving', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'christmas', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'instant-pot-recipes', 'cat'] = 'slow-cooker'\n",
    "merged.loc[merged.cat == 'fall-faves', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'cookies', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'holidays/christmas', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'cake', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'meat', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'asian-inspired', 'cat'] = 'asian'\n",
    "merged.loc[merged.cat == 'main-dish', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'tarts-and-pastries'] = 'dessert'\n",
    "merged.loc[merged.cat == 'holidays/spring'] ='holidays'\n",
    "merged.loc[merged.cat == 'holidays/valentines'] ='holidays'\n",
    "merged.loc[merged.cat == 'holidays/halloween'] ='holidays'\n",
    "merged.loc[merged.cat == 'muffins'] ='baked-goods'\n",
    "merged.loc[merged.cat == 'pie-cheesecake'] ='dessert'\n",
    "merged.loc[merged.cat == 'holidays/thanksgiving'] ='holidays'\n",
    "\n",
    "\n",
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course        0.226320\n",
       "dessert            0.180096\n",
       "appetizers         0.091690\n",
       "breakfast          0.065421\n",
       "quick-easy         0.052286\n",
       "holidays           0.050265\n",
       "chicken-recipes    0.045213\n",
       "drinks             0.039404\n",
       "healthy            0.038141\n",
       "pasta              0.034352\n",
       "vegetarian         0.031321\n",
       "asian              0.027532\n",
       "soup               0.026522\n",
       "seasonal           0.023238\n",
       "slow-cooker        0.019197\n",
       "baked-goods        0.013640\n",
       "one-pot            0.009851\n",
       "sauces             0.009346\n",
       "game-day           0.008841\n",
       "seafood            0.007325\n",
       "Name: cat, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.cat.value_counts()/len(merged.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged.cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.cat = pd.Categorical(merged.cat)\n",
    "merged['y'] = merged.cat.cat.codes\n",
    "merged.y = [np.int64(x) for x in merged.y]\n",
    "merged.y = pd.Series(merged.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =merged.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3959,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.hstack(merged['title'] + merged['ingredients']+ merged['instructions'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 7061)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import one_hot , Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "ttrain, ttest, ingtrain, ingtest, insttrain, insttest, y1train, y1test = train_test_split(merged.title, merged.ingredients, \n",
    "                                                                                        merged.instructions, merged.cat, test_size=.3, \n",
    "                                                                                        random_state = 420)\n",
    "count = CountVectorizer()\n",
    "xtraincounts = count.fit_transform(xtrain)\n",
    "xtraincounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(xtraincounts, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36423833726430066"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testvector = count.transform(xtest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030101367351615615"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraincounts = count.fit_transform(ttrain)\n",
    "clf = MultinomialNB().fit(xtraincounts, ytrain)\n",
    "testvector = count.transform(ttest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03468213915648437"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraincounts = count.fit_transform(ingtrain)\n",
    "clf = MultinomialNB().fit(xtraincounts, ytrain)\n",
    "testvector = count.transform(ingtest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03532390832786299"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraincounts = count.fit_transform(insttrain)\n",
    "clf = MultinomialNB().fit(xtraincounts, ytrain)\n",
    "testvector = count.transform(insttest)\n",
    "predict = clf.predict(testvector)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeitup = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33354576217581466"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeitup.fit(xtrain, ytrain)\n",
    "predicted=pipeitup.predict(xtest)\n",
    "metrics.f1_score(ytest, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "param_grid ={'clf__n_estimators' :[100,200,600,800,1000],\n",
    "             'clf__min_samples_split' : [2,4,6,8],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            }\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(pipeitup, param_grid, cv=5)\n",
    "gs = gs.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__min_samples_split': 2,\n",
       " 'clf__n_estimators': 1000,\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37581515764068074"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = gs.predict(xtest)\n",
    "metrics.f1_score(ytest, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "textclf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l1',\n",
    "                         alpha=1e-3, random_state=420,\n",
    "                         max_iter=5, tol=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33354576217581466"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textclf.fit(xtrain, ytrain)\n",
    "predict = textclf.predict(xtest)\n",
    "metrics.f1_score(ytest, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4224085760409363"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeitupagain = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC(C=4, random_state=420))\n",
    "])\n",
    "\n",
    "pipeitupagain.fit(xtrain,ytrain)\n",
    "predict = pipeitupagain.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4390843800812082"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeitupagain = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC(random_state=420, tol=1e-5))\n",
    "])\n",
    "\n",
    "pipeitupagain.fit(xtrain,ytrain)\n",
    "predict = pipeitupagain.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting LInear SVC and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4189517394295968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "c1 = LinearSVC(random_state=420, tol=1e-5)\n",
    "c2 = SVC(C=4, random_state=420)\n",
    "vote = VotingClassifier(estimators=[('1',c1), ('2',c2)],\n",
    "                       voting = 'hard')\n",
    "pipeitupagain = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', vote)\n",
    "])\n",
    "\n",
    "pipeitupagain.fit(xtrain,ytrain)\n",
    "predict = pipeitupagain.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42893254932183844"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = BaggingClassifier(base_estimator=LinearSVC(random_state=420, tol=1e-5),\n",
    "                       n_estimators=100, random_state=420)\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', bag)\n",
    "])\n",
    "pipe.fit(xtrain, ytrain)\n",
    "predict = pipe.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4279478859111562"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', xgboost.XGBClassifier(objective='multi:softprob',\n",
    "                                max_depth=3, n_estimators=700))\n",
    "])\n",
    "pipe.fit(xtrain, ytrain)\n",
    "predict = pipe.predict(xtest)\n",
    "metrics.f1_score(ytest, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2843, 152, 559, 316, 1, 449, 1204, 54, 53, 23, 240, 2, 262, 578, 316, 2477, 152, 69, 143, 1, 62, 5, 30, 251, 143, 1, 62, 102, 108, 35, 143, 1, 95, 71, 38, 25, 241, 5, 147, 181, 569, 5180, 5181, 12, 1345, 1625, 5, 719, 46, 342, 5, 719, 46, 187, 12, 366, 149, 317, 2478, 387, 2, 1133, 4067, 12, 2844, 449, 556, 48, 8, 1626, 953, 672, 311, 17, 1, 61, 457, 63, 21, 61, 208, 126, 2140, 2, 2638, 7, 6, 27, 350, 39, 30, 72, 20, 56, 18, 316, 1, 295, 16, 57, 15, 89, 1, 860, 146, 9, 239, 5182, 6, 861, 265, 4, 105, 3, 316, 4, 6, 322, 278, 1, 59, 85, 56, 651, 333, 106, 604, 18, 3, 106, 23, 4, 3, 350, 56, 18, 69, 1, 632, 1, 295, 16, 360, 15, 89, 146, 9, 3, 69, 55, 451, 1, 633, 56, 40, 7, 3, 35, 1, 295, 16, 2, 5, 98, 15, 89, 394, 9, 401, 18, 7, 3, 25, 241, 152, 247, 1068, 1, 121, 316, 1, 40, 9, 79, 56, 306, 159, 9, 3, 269, 400, 6, 173, 40, 2479, 449, 140, 1, 49, 16, 57, 15, 12, 9, 3, 449, 215, 270, 6, 617, 47, 1, 75, 8, 6, 318, 750, 990, 13, 17, 1, 21, 122, 182, 44, 134, 217, 8, 801, 13, 126, 41, 56, 12, 105, 4, 6, 522, 250, 739, 1, 335, 16, 141, 4, 14, 509, 12, 538, 16, 141, 4, 14, 807]\n",
      "787\n"
     ]
    }
   ],
   "source": [
    "## To DO: tokenize using keras tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(xtrain)\n",
    "vocabsize = len(t.word_index) + 1\n",
    "encoded = t.texts_to_sequences(xtrain)\n",
    "tencoded = t.texts_to_sequences(ttrain)\n",
    "ingencoded = t.texts_to_sequences(str(ingtrain))\n",
    "instencoded = t.texts_to_sequences([str(x) for x in insttrain])\n",
    "encodedtest = t.texts_to_sequences(xtest)\n",
    "print(encoded[1])\n",
    "\n",
    "maxlength = max([len(x) for x in encoded])\n",
    "print(maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_glove():\n",
    "    embeddings_index = dict()\n",
    "    f = open('./glove.6B.100d.txt') # replace this with the path to your downloaded txt file\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    # create a weight matrix for words in training docs\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "[  76  559  331 3130   38  354   87  240    5   38  212   45    5   14\n",
      "   10  177   32    5   26  230  233  375    2   76  559    5    2    5\n",
      "   26  275    2   11   10  287 4065    6   83  111   28   65   60    2\n",
      "   11   10   87    8    3  275    9  189   59   85    7    6   30  243\n",
      "   92  106    2   14   11   10   87    3   45   32  233  375   76  559\n",
      "  264    1   76  559 4066  237   31  117    4    6  195   39   30   72\n",
      "   20   89  394    4 1445   32  192   58  400    6  195   65  275   31\n",
      "  192   98    1  235  444   87   31    7  243  481  110  275   31   22\n",
      "  243  214   20  180  235   89  376  283   31    4 1284    1   49   19\n",
      "    2    5   15  268    9  215  415    1   58 1564    3  594   13    6\n",
      "  612  265   77   67   20    1   65    7  287   45  110   22    6   20\n",
      "  848   28  140   31    8 1371  164  686 1285 1098    3  428   13    3\n",
      "   31    4  930    6  589   67 1372    1  335    9  494  133  445 1016\n",
      "  145  524  576 2047   16  169   15   33   89 3131  273 2048   58    7\n",
      "    3  331   45 1393 2637  104  344    6 1446 5179 2840  203   58 2841\n",
      "    3  331   45    6 1394 1660    1 2841    3  331   45 1393    6  744\n",
      " 1079  541   31    7   64  331   45 1393  308    4 1991  391  105   31\n",
      "    4   64  397  250    1  538    9  586   42  154  621   55  122  472\n",
      "  122  959  119   58  338  100  225 1447  577   15  273  207   16 2842\n",
      " 1305   58  406  236  703  451    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.initializers import Constant\n",
    "import math\n",
    "# to Do: add constants that you might need here\n",
    "n_classes=20\n",
    "embeddingdim = 100\n",
    "\n",
    "word_index=t.word_index\n",
    "\n",
    "embeddings_index = load_glove()\n",
    "embedding_matrix = np.random.random((len(word_index)+1, embeddingdim))\n",
    "for word, i in word_index.items():\n",
    "    embeddingvector = embeddings_index.get(word)\n",
    "    if embeddingvector is not None:\n",
    "        if len(embedding_matrix[i]) != len(embeddingvector):\n",
    "            print('could not be broadcast input array from shape ', str(len(embedding_matrix[i])),\n",
    "                 ' into shape ', str(len(embeddingvector)), ' Please make sure your embedding dim is equal to embedding vector file Glove')\n",
    "            exit(1)\n",
    "        \n",
    "        embedding_matrix[i] = embeddingvector\n",
    "        \n",
    "\n",
    "###To Do:  pad the train and test data \n",
    "padded = pad_sequences(encoded, maxlen=maxlength, padding='post')\n",
    "tpadded = pad_sequences(tencoded, maxlen=maxlength, padding='post')\n",
    "ingpadded = pad_sequences(ingencoded, maxlen=maxlength, padding='post')\n",
    "instpadded = pad_sequences(instencoded, maxlen=maxlength, padding='post')\n",
    "paddedtest = pad_sequences(encodedtest, maxlen=maxlength, padding='post')\n",
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 787)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 787, 100)     920500      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 787, 100)     0           ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 787, 64)      19264       ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 787, 32)      9632        ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 787, 16)      4816        ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_18 (MaxPooling1D  (None, 157, 64)     0           ['conv1d_26[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_20 (MaxPooling1D  (None, 157, 32)     0           ['conv1d_28[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_22 (MaxPooling1D  (None, 157, 16)     0           ['conv1d_30[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 157, 64)      0           ['max_pooling1d_18[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 157, 32)      0           ['max_pooling1d_20[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 157, 16)      0           ['max_pooling1d_22[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 155, 128)     24704       ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 155, 128)     12416       ['dropout_51[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 155, 128)     6272        ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_19 (MaxPooling1D  (None, 51, 128)     0           ['conv1d_27[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_21 (MaxPooling1D  (None, 51, 128)     0           ['conv1d_29[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_23 (MaxPooling1D  (None, 51, 128)     0           ['conv1d_31[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 51, 384)      0           ['max_pooling1d_19[0][0]',       \n",
      "                                                                  'max_pooling1d_21[0][0]',       \n",
      "                                                                  'max_pooling1d_23[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 19584)        0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 128)          2506880     ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 128)          0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 64)           8256        ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 64)           0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 32)           2080        ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 32)           0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 19)           627         ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,515,447\n",
      "Trainable params: 3,515,447\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                          input_length=maxlength, trainable=True)\n",
    "sequence_input = Input(shape=(maxlength,),dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "x = Dropout(.2)(embeddedsequences)\n",
    "x1 = Conv1D(64, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x1 = MaxPooling1D(5)(x1)\n",
    "x1 = Dropout(.2)(x1)\n",
    "x1 = Conv1D(128, 3, activation='softplus')(x1)\n",
    "x1 = MaxPooling1D(3)(x1)\n",
    "#x1 = Conv1D(256, 5, activation = 'softplus')(x1)\n",
    "#x1 = MaxPooling1D(10)(x1)\n",
    "\n",
    "x2 = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x2 = MaxPooling1D(5)(x2)\n",
    "x2 = Dropout(.2)(x2)\n",
    "x2 = Conv1D(128, 3, activation='softplus')(x2)\n",
    "x2 = MaxPooling1D(3)(x2)\n",
    "#x2 = Conv1D(256, 5, activation = 'softplus')(x2)\n",
    "#x2 = MaxPooling1D(10)(x2)\n",
    "\n",
    "x3 = Conv1D(16, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x3 = MaxPooling1D(5)(x3)\n",
    "x3 = Dropout(.2)(x3)\n",
    "x3 = Conv1D(128, 3, activation='softplus')(x3)\n",
    "x3 = MaxPooling1D(3)(x3)\n",
    "#x3 = Conv1D(256, 5, activation = 'softplus')(x3)\n",
    "#x3 = MaxPooling1D(10)(x3)\n",
    "\n",
    "x = Concatenate()([x1,x2,x3])\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(32, activation = 'softplus')(x)\n",
    "x = Dropout(.4)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=.003, decay=.0008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 787)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 787, 100)     920500      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 787, 100)     0           ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 787, 32)      9632        ['dropout_56[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 787, 24)      9624        ['dropout_56[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 787, 64)      32064       ['dropout_56[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 787, 120)     0           ['conv1d_32[0][0]',              \n",
      "                                                                  'conv1d_33[0][0]',              \n",
      "                                                                  'conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_24 (MaxPooling1D  (None, 157, 120)    0           ['concatenate_6[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 157, 120)     0           ['max_pooling1d_24[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 155, 128)     46208       ['dropout_57[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_25 (MaxPooling1D  (None, 19, 128)     0           ['conv1d_35[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 15, 256)      164096      ['max_pooling1d_25[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_26 (MaxPooling1D  (None, 1, 256)      0           ['conv1d_36[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 256)          0           ['max_pooling1d_26[0][0]']       \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          32896       ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 128)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 64)           8256        ['dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 64)           0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 20)           1300        ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,224,576\n",
      "Trainable params: 1,224,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(8)(x)\n",
    "x = Conv1D(256, 5, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(10)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "#x = Dense(32, activation = 'softplus')(x)\n",
    "#x = Dropout(.2)(x)\n",
    "preds = Dense(20, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=.0003, decay=.00008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 6s 98ms/step - loss: 3.0757 - accuracy: 0.1288 - val_loss: 2.6745 - val_accuracy: 0.2197\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.7022 - accuracy: 0.2057 - val_loss: 2.6180 - val_accuracy: 0.2231\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.6394 - accuracy: 0.2014 - val_loss: 2.5394 - val_accuracy: 0.2239\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.5592 - accuracy: 0.2465 - val_loss: 2.4718 - val_accuracy: 0.2197\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.4659 - accuracy: 0.2883 - val_loss: 2.2676 - val_accuracy: 0.3763\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.3020 - accuracy: 0.3681 - val_loss: 2.1717 - val_accuracy: 0.3872\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.2280 - accuracy: 0.3829 - val_loss: 2.0974 - val_accuracy: 0.3981\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 2.1426 - accuracy: 0.4053 - val_loss: 2.1054 - val_accuracy: 0.3906\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.1204 - accuracy: 0.4053 - val_loss: 2.0601 - val_accuracy: 0.4226\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.0620 - accuracy: 0.4161 - val_loss: 1.9613 - val_accuracy: 0.4141\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.0143 - accuracy: 0.4240 - val_loss: 1.9279 - val_accuracy: 0.4259\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.0069 - accuracy: 0.4186 - val_loss: 1.9408 - val_accuracy: 0.4200\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.9633 - accuracy: 0.4406 - val_loss: 1.9160 - val_accuracy: 0.4293\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.9314 - accuracy: 0.4403 - val_loss: 1.9048 - val_accuracy: 0.4537\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8982 - accuracy: 0.4489 - val_loss: 1.8667 - val_accuracy: 0.4419\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8682 - accuracy: 0.4540 - val_loss: 1.9459 - val_accuracy: 0.4411\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8500 - accuracy: 0.4464 - val_loss: 1.8395 - val_accuracy: 0.4554\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8100 - accuracy: 0.4612 - val_loss: 1.8523 - val_accuracy: 0.4596\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8002 - accuracy: 0.4738 - val_loss: 1.7917 - val_accuracy: 0.4680\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.7669 - accuracy: 0.4720 - val_loss: 1.7743 - val_accuracy: 0.4588\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.7455 - accuracy: 0.4836 - val_loss: 2.0131 - val_accuracy: 0.4369\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.7459 - accuracy: 0.4811 - val_loss: 1.9356 - val_accuracy: 0.4537\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.7240 - accuracy: 0.4951 - val_loss: 1.8131 - val_accuracy: 0.4604\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.7015 - accuracy: 0.4901 - val_loss: 1.7929 - val_accuracy: 0.4613\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6952 - accuracy: 0.4865 - val_loss: 1.7479 - val_accuracy: 0.4865\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6776 - accuracy: 0.5009 - val_loss: 1.6877 - val_accuracy: 0.4933\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6363 - accuracy: 0.5045 - val_loss: 1.7494 - val_accuracy: 0.4848\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6388 - accuracy: 0.5092 - val_loss: 1.6854 - val_accuracy: 0.5042\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6237 - accuracy: 0.5088 - val_loss: 1.7465 - val_accuracy: 0.4848\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6106 - accuracy: 0.5070 - val_loss: 1.6930 - val_accuracy: 0.4882\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5779 - accuracy: 0.5125 - val_loss: 1.7080 - val_accuracy: 0.4722\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5688 - accuracy: 0.5251 - val_loss: 1.7180 - val_accuracy: 0.4739\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5637 - accuracy: 0.5240 - val_loss: 1.6866 - val_accuracy: 0.4916\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5533 - accuracy: 0.5226 - val_loss: 1.6855 - val_accuracy: 0.4823\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.5348 - accuracy: 0.5327 - val_loss: 1.6329 - val_accuracy: 0.5109\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5106 - accuracy: 0.5420 - val_loss: 1.6212 - val_accuracy: 0.5008\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5180 - accuracy: 0.5355 - val_loss: 1.6603 - val_accuracy: 0.4992\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4946 - accuracy: 0.5330 - val_loss: 1.6464 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 1.4895 - accuracy: 0.5330 - val_loss: 1.6912 - val_accuracy: 0.4806\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4577 - accuracy: 0.5485 - val_loss: 1.6295 - val_accuracy: 0.5059\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4560 - accuracy: 0.5449 - val_loss: 1.6720 - val_accuracy: 0.4705\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4441 - accuracy: 0.5540 - val_loss: 1.5992 - val_accuracy: 0.5168\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4221 - accuracy: 0.5525 - val_loss: 1.6540 - val_accuracy: 0.4983\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4056 - accuracy: 0.5601 - val_loss: 1.8182 - val_accuracy: 0.4503\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.4089 - accuracy: 0.5648 - val_loss: 1.5855 - val_accuracy: 0.5194\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3872 - accuracy: 0.5687 - val_loss: 1.6061 - val_accuracy: 0.5034\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3787 - accuracy: 0.5706 - val_loss: 1.6265 - val_accuracy: 0.5101\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3768 - accuracy: 0.5590 - val_loss: 1.6417 - val_accuracy: 0.5152\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3527 - accuracy: 0.5706 - val_loss: 1.6191 - val_accuracy: 0.4882\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3430 - accuracy: 0.5763 - val_loss: 1.6778 - val_accuracy: 0.5076\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3047 - accuracy: 0.5868 - val_loss: 1.6205 - val_accuracy: 0.5084\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.3375 - accuracy: 0.5785 - val_loss: 1.6342 - val_accuracy: 0.5253\n",
      "Epoch 53/100\n",
      "22/44 [==============>...............] - ETA: 1s - loss: 1.2839 - accuracy: 0.5916"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-ad7f7effb416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = [keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "\n",
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.8344 - accuracy: 0.7298 - val_loss: 1.7000 - val_accuracy: 0.5338\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.8321 - accuracy: 0.7246 - val_loss: 1.6812 - val_accuracy: 0.5109\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7752 - accuracy: 0.7386 - val_loss: 1.5505 - val_accuracy: 0.5845\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7763 - accuracy: 0.7448 - val_loss: 1.6949 - val_accuracy: 0.5483\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7692 - accuracy: 0.7433 - val_loss: 1.6405 - val_accuracy: 0.5628\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7337 - accuracy: 0.7562 - val_loss: 1.5994 - val_accuracy: 0.5531\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7443 - accuracy: 0.7500 - val_loss: 1.5639 - val_accuracy: 0.5628\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7183 - accuracy: 0.7619 - val_loss: 1.6930 - val_accuracy: 0.5326\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6960 - accuracy: 0.7733 - val_loss: 1.6621 - val_accuracy: 0.5471\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6635 - accuracy: 0.7738 - val_loss: 1.6573 - val_accuracy: 0.5604\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6652 - accuracy: 0.7754 - val_loss: 1.7681 - val_accuracy: 0.5773\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6695 - accuracy: 0.7723 - val_loss: 1.6626 - val_accuracy: 0.5700\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6823 - accuracy: 0.7666 - val_loss: 1.7230 - val_accuracy: 0.5737\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6428 - accuracy: 0.7867 - val_loss: 1.7677 - val_accuracy: 0.5543\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.6092 - accuracy: 0.8023 - val_loss: 1.7571 - val_accuracy: 0.5604\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.6069 - accuracy: 0.7945 - val_loss: 1.8707 - val_accuracy: 0.5471\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5748 - accuracy: 0.8012 - val_loss: 1.8201 - val_accuracy: 0.5640\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5795 - accuracy: 0.8023 - val_loss: 1.8575 - val_accuracy: 0.5531\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5394 - accuracy: 0.8126 - val_loss: 1.8769 - val_accuracy: 0.5725\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5463 - accuracy: 0.8188 - val_loss: 1.8264 - val_accuracy: 0.5664\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5257 - accuracy: 0.8240 - val_loss: 1.8461 - val_accuracy: 0.5616\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5592 - accuracy: 0.8173 - val_loss: 1.8229 - val_accuracy: 0.5519\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5516 - accuracy: 0.8168 - val_loss: 1.8489 - val_accuracy: 0.5688\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4972 - accuracy: 0.8323 - val_loss: 1.9127 - val_accuracy: 0.5435\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5241 - accuracy: 0.8328 - val_loss: 1.8880 - val_accuracy: 0.5616\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5001 - accuracy: 0.8344 - val_loss: 1.8723 - val_accuracy: 0.5737\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4913 - accuracy: 0.8333 - val_loss: 1.9116 - val_accuracy: 0.5797\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4878 - accuracy: 0.8354 - val_loss: 1.9895 - val_accuracy: 0.5362\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4762 - accuracy: 0.8483 - val_loss: 1.8567 - val_accuracy: 0.5604\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.4629 - accuracy: 0.8494 - val_loss: 1.9160 - val_accuracy: 0.5459\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4294 - accuracy: 0.8582 - val_loss: 2.1348 - val_accuracy: 0.5290\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4287 - accuracy: 0.8566 - val_loss: 2.2891 - val_accuracy: 0.5386\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4559 - accuracy: 0.8463 - val_loss: 2.0919 - val_accuracy: 0.5640\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4115 - accuracy: 0.8649 - val_loss: 2.1222 - val_accuracy: 0.5447\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4254 - accuracy: 0.8561 - val_loss: 2.0461 - val_accuracy: 0.5519\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4032 - accuracy: 0.8701 - val_loss: 2.1206 - val_accuracy: 0.5531\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4100 - accuracy: 0.8597 - val_loss: 2.0970 - val_accuracy: 0.5749\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3831 - accuracy: 0.8742 - val_loss: 2.2270 - val_accuracy: 0.5580\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3677 - accuracy: 0.8722 - val_loss: 2.3200 - val_accuracy: 0.5616\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3649 - accuracy: 0.8804 - val_loss: 2.1318 - val_accuracy: 0.5568\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3743 - accuracy: 0.8804 - val_loss: 2.2667 - val_accuracy: 0.5519\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3682 - accuracy: 0.8830 - val_loss: 2.3790 - val_accuracy: 0.5254\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3382 - accuracy: 0.8913 - val_loss: 2.1369 - val_accuracy: 0.5604\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3354 - accuracy: 0.8960 - val_loss: 2.1730 - val_accuracy: 0.5725\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3458 - accuracy: 0.8841 - val_loss: 2.3391 - val_accuracy: 0.5640\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3527 - accuracy: 0.8846 - val_loss: 2.1676 - val_accuracy: 0.5616\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 2.2158 - val_accuracy: 0.5652\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3340 - accuracy: 0.8887 - val_loss: 2.4837 - val_accuracy: 0.5411\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3326 - accuracy: 0.8934 - val_loss: 2.3919 - val_accuracy: 0.5266\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3141 - accuracy: 0.8970 - val_loss: 2.4366 - val_accuracy: 0.5676\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3164 - accuracy: 0.8954 - val_loss: 2.5164 - val_accuracy: 0.5628\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3087 - accuracy: 0.9032 - val_loss: 2.3958 - val_accuracy: 0.5713\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3034 - accuracy: 0.9042 - val_loss: 2.3130 - val_accuracy: 0.5640\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3028 - accuracy: 0.9053 - val_loss: 2.3583 - val_accuracy: 0.5568\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2900 - accuracy: 0.9073 - val_loss: 2.4301 - val_accuracy: 0.5652\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2966 - accuracy: 0.9073 - val_loss: 2.4691 - val_accuracy: 0.5640\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2925 - accuracy: 0.9058 - val_loss: 2.4759 - val_accuracy: 0.5580\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2813 - accuracy: 0.9125 - val_loss: 2.3099 - val_accuracy: 0.5725\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2492 - accuracy: 0.9198 - val_loss: 2.5422 - val_accuracy: 0.5616\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2836 - accuracy: 0.9068 - val_loss: 2.5740 - val_accuracy: 0.5543\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2695 - accuracy: 0.9156 - val_loss: 2.5470 - val_accuracy: 0.5640\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2864 - accuracy: 0.9110 - val_loss: 2.4118 - val_accuracy: 0.5568\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2580 - accuracy: 0.9151 - val_loss: 2.5301 - val_accuracy: 0.5507\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2889 - accuracy: 0.9068 - val_loss: 2.4856 - val_accuracy: 0.5459\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2358 - accuracy: 0.9203 - val_loss: 2.6055 - val_accuracy: 0.5399\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2406 - accuracy: 0.9270 - val_loss: 2.5767 - val_accuracy: 0.5531\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2440 - accuracy: 0.9234 - val_loss: 2.6720 - val_accuracy: 0.5229\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2641 - accuracy: 0.9130 - val_loss: 2.5234 - val_accuracy: 0.5700\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2411 - accuracy: 0.9239 - val_loss: 2.5553 - val_accuracy: 0.5556\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2229 - accuracy: 0.9296 - val_loss: 2.8188 - val_accuracy: 0.5362\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2460 - accuracy: 0.9193 - val_loss: 2.5636 - val_accuracy: 0.5543\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2153 - accuracy: 0.9369 - val_loss: 2.6629 - val_accuracy: 0.5604\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2356 - accuracy: 0.9281 - val_loss: 2.6128 - val_accuracy: 0.5688\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2298 - accuracy: 0.9286 - val_loss: 2.7357 - val_accuracy: 0.5399\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2254 - accuracy: 0.9327 - val_loss: 2.5903 - val_accuracy: 0.5483\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2225 - accuracy: 0.9281 - val_loss: 2.6758 - val_accuracy: 0.5556\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2071 - accuracy: 0.9384 - val_loss: 2.7835 - val_accuracy: 0.5628\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.2386 - accuracy: 0.9234 - val_loss: 2.5736 - val_accuracy: 0.5471\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2356 - accuracy: 0.9229 - val_loss: 2.6060 - val_accuracy: 0.5543\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2136 - accuracy: 0.9343 - val_loss: 2.7526 - val_accuracy: 0.5483\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2088 - accuracy: 0.9332 - val_loss: 2.9039 - val_accuracy: 0.5447\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2218 - accuracy: 0.9348 - val_loss: 2.6253 - val_accuracy: 0.5568\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1933 - accuracy: 0.9415 - val_loss: 2.8037 - val_accuracy: 0.5399\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1938 - accuracy: 0.9457 - val_loss: 2.7095 - val_accuracy: 0.5374\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1794 - accuracy: 0.9384 - val_loss: 3.0129 - val_accuracy: 0.5350\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2080 - accuracy: 0.9317 - val_loss: 2.9309 - val_accuracy: 0.5435\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1752 - accuracy: 0.9462 - val_loss: 3.1121 - val_accuracy: 0.5483\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1960 - accuracy: 0.9363 - val_loss: 3.2041 - val_accuracy: 0.5302\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1921 - accuracy: 0.9441 - val_loss: 2.6933 - val_accuracy: 0.5568\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1832 - accuracy: 0.9436 - val_loss: 2.7708 - val_accuracy: 0.5640\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1998 - accuracy: 0.9389 - val_loss: 2.7818 - val_accuracy: 0.5556\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1806 - accuracy: 0.9410 - val_loss: 3.1756 - val_accuracy: 0.5157\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2294 - accuracy: 0.9332 - val_loss: 3.0955 - val_accuracy: 0.5435\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1700 - accuracy: 0.9508 - val_loss: 2.9247 - val_accuracy: 0.5507\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1851 - accuracy: 0.9462 - val_loss: 2.8565 - val_accuracy: 0.5399\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1726 - accuracy: 0.9462 - val_loss: 2.8646 - val_accuracy: 0.5592\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1726 - accuracy: 0.9482 - val_loss: 2.9335 - val_accuracy: 0.5483\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1733 - accuracy: 0.9493 - val_loss: 2.8635 - val_accuracy: 0.5604\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1799 - accuracy: 0.9436 - val_loss: 2.8477 - val_accuracy: 0.5459\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1922 - accuracy: 0.9410 - val_loss: 3.1516 - val_accuracy: 0.5254\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1782 - accuracy: 0.9508 - val_loss: 2.9707 - val_accuracy: 0.5700\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1725 - accuracy: 0.9467 - val_loss: 3.0551 - val_accuracy: 0.5435\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1487 - accuracy: 0.9565 - val_loss: 3.1147 - val_accuracy: 0.5519\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1566 - accuracy: 0.9508 - val_loss: 3.0883 - val_accuracy: 0.5616\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1654 - accuracy: 0.9503 - val_loss: 2.9570 - val_accuracy: 0.5471\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1590 - accuracy: 0.9513 - val_loss: 3.1268 - val_accuracy: 0.5543\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1765 - accuracy: 0.9472 - val_loss: 3.0911 - val_accuracy: 0.5447\n",
      "Epoch 108/200\n",
      "49/61 [=======================>......] - ETA: 0s - loss: 0.1669 - accuracy: 0.9483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cb67e54f027f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=200, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 787)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 787, 100)     920500      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 787, 100)     0           ['embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 787, 32)      9632        ['dropout_60[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 787, 24)      9624        ['dropout_60[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 787, 64)      32064       ['dropout_60[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 787, 120)     0           ['conv1d_37[0][0]',              \n",
      "                                                                  'conv1d_38[0][0]',              \n",
      "                                                                  'conv1d_39[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_27 (MaxPooling1D  (None, 157, 120)    0           ['concatenate_7[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 157, 120)     0           ['max_pooling1d_27[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 155, 128)     46208       ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_28 (MaxPooling1D  (None, 31, 128)     0           ['conv1d_40[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 27, 256)      164096      ['max_pooling1d_28[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_29 (MaxPooling1D  (None, 5, 256)      0           ['conv1d_41[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 1280)         0           ['max_pooling1d_29[0][0]']       \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          163968      ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 128)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 64)           8256        ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 64)           0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 32)           2080        ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 32)           0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 20)           660         ['dropout_64[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,357,088\n",
      "Trainable params: 1,357,088\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "x = Dropout(.4)(x)\n",
    "preds = Dense(20, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=.0003, decay=.0008, centered=True)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 6s 98ms/step - loss: 2.8372 - accuracy: 0.1599 - val_loss: 2.7258 - val_accuracy: 0.2197\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.7098 - accuracy: 0.1963 - val_loss: 2.6732 - val_accuracy: 0.2189\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.6580 - accuracy: 0.1945 - val_loss: 2.6585 - val_accuracy: 0.2340\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.6112 - accuracy: 0.2198 - val_loss: 2.6401 - val_accuracy: 0.2416\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.5655 - accuracy: 0.2263 - val_loss: 2.6137 - val_accuracy: 0.2542\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.5112 - accuracy: 0.2660 - val_loss: 2.5228 - val_accuracy: 0.3510\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.4700 - accuracy: 0.2883 - val_loss: 2.5628 - val_accuracy: 0.3367\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.3981 - accuracy: 0.3280 - val_loss: 2.3651 - val_accuracy: 0.3678\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.3402 - accuracy: 0.3677 - val_loss: 2.3960 - val_accuracy: 0.3392\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.3164 - accuracy: 0.3677 - val_loss: 2.2680 - val_accuracy: 0.3771\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.2638 - accuracy: 0.3883 - val_loss: 2.2338 - val_accuracy: 0.3906\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.2181 - accuracy: 0.3901 - val_loss: 2.2522 - val_accuracy: 0.3754\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.1821 - accuracy: 0.4064 - val_loss: 2.1866 - val_accuracy: 0.4015\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.1858 - accuracy: 0.4013 - val_loss: 2.1825 - val_accuracy: 0.3872\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.1578 - accuracy: 0.4002 - val_loss: 2.1393 - val_accuracy: 0.3855\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.1302 - accuracy: 0.4042 - val_loss: 2.1561 - val_accuracy: 0.3847\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.1271 - accuracy: 0.4064 - val_loss: 2.0700 - val_accuracy: 0.3998\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.0797 - accuracy: 0.4136 - val_loss: 2.0644 - val_accuracy: 0.4040\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.0765 - accuracy: 0.4147 - val_loss: 2.0803 - val_accuracy: 0.4141\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.0769 - accuracy: 0.4157 - val_loss: 2.2028 - val_accuracy: 0.4141\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 2.0534 - accuracy: 0.4183 - val_loss: 2.0534 - val_accuracy: 0.4226\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.0094 - accuracy: 0.4157 - val_loss: 2.0624 - val_accuracy: 0.4209\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.0044 - accuracy: 0.4262 - val_loss: 2.2372 - val_accuracy: 0.3754\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 2.0101 - accuracy: 0.4233 - val_loss: 2.0982 - val_accuracy: 0.4192\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 2.0004 - accuracy: 0.4262 - val_loss: 2.0039 - val_accuracy: 0.4116\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.9613 - accuracy: 0.4331 - val_loss: 2.0492 - val_accuracy: 0.4226\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9633 - accuracy: 0.4298 - val_loss: 2.0012 - val_accuracy: 0.4360\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9567 - accuracy: 0.4298 - val_loss: 1.9655 - val_accuracy: 0.4310\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9555 - accuracy: 0.4334 - val_loss: 2.1120 - val_accuracy: 0.4032\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9638 - accuracy: 0.4406 - val_loss: 2.0674 - val_accuracy: 0.4175\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.9309 - accuracy: 0.4428 - val_loss: 2.0545 - val_accuracy: 0.4293\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9262 - accuracy: 0.4468 - val_loss: 1.9548 - val_accuracy: 0.4352\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9015 - accuracy: 0.4457 - val_loss: 1.9905 - val_accuracy: 0.4276\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.9056 - accuracy: 0.4450 - val_loss: 1.9532 - val_accuracy: 0.4478\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9152 - accuracy: 0.4435 - val_loss: 1.9837 - val_accuracy: 0.4310\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.9013 - accuracy: 0.4565 - val_loss: 1.9538 - val_accuracy: 0.4520\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8462 - accuracy: 0.4482 - val_loss: 1.9633 - val_accuracy: 0.4428\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.8493 - accuracy: 0.4457 - val_loss: 1.9419 - val_accuracy: 0.4562\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8588 - accuracy: 0.4572 - val_loss: 1.9242 - val_accuracy: 0.4579\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8477 - accuracy: 0.4580 - val_loss: 1.9473 - val_accuracy: 0.4360\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.8501 - accuracy: 0.4562 - val_loss: 1.9887 - val_accuracy: 0.4327\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8426 - accuracy: 0.4540 - val_loss: 1.9320 - val_accuracy: 0.4529\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8382 - accuracy: 0.4540 - val_loss: 1.8912 - val_accuracy: 0.4672\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.8242 - accuracy: 0.4634 - val_loss: 1.9052 - val_accuracy: 0.4545\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.8408 - accuracy: 0.4507 - val_loss: 1.8895 - val_accuracy: 0.4672\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8233 - accuracy: 0.4630 - val_loss: 1.9100 - val_accuracy: 0.4503\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.8084 - accuracy: 0.4713 - val_loss: 1.8761 - val_accuracy: 0.4613\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8093 - accuracy: 0.4634 - val_loss: 1.9140 - val_accuracy: 0.4537\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7869 - accuracy: 0.4713 - val_loss: 1.8820 - val_accuracy: 0.4705\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.8098 - accuracy: 0.4767 - val_loss: 1.8922 - val_accuracy: 0.4588\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 1.7866 - accuracy: 0.4807 - val_loss: 1.8698 - val_accuracy: 0.4689\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7927 - accuracy: 0.4699 - val_loss: 1.8764 - val_accuracy: 0.4630\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7738 - accuracy: 0.4756 - val_loss: 1.8508 - val_accuracy: 0.4705\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.7705 - accuracy: 0.4800 - val_loss: 1.9193 - val_accuracy: 0.4369\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7825 - accuracy: 0.4742 - val_loss: 1.8631 - val_accuracy: 0.4689\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7750 - accuracy: 0.4713 - val_loss: 1.8801 - val_accuracy: 0.4386\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7637 - accuracy: 0.4778 - val_loss: 1.9114 - val_accuracy: 0.4377\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 1.7647 - accuracy: 0.4836 - val_loss: 1.8688 - val_accuracy: 0.4689\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 1.7624 - accuracy: 0.4839 - val_loss: 1.8855 - val_accuracy: 0.4630\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.7345 - accuracy: 0.4879 - val_loss: 1.8533 - val_accuracy: 0.4705\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.7256 - accuracy: 0.4930 - val_loss: 1.8454 - val_accuracy: 0.4747\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.7157 - accuracy: 0.4850 - val_loss: 1.9059 - val_accuracy: 0.4360\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7085 - accuracy: 0.4825 - val_loss: 1.8501 - val_accuracy: 0.4806\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.7325 - accuracy: 0.4868 - val_loss: 1.8420 - val_accuracy: 0.4714\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7090 - accuracy: 0.4904 - val_loss: 1.8796 - val_accuracy: 0.4638\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7143 - accuracy: 0.4901 - val_loss: 1.8246 - val_accuracy: 0.4705\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6992 - accuracy: 0.4926 - val_loss: 1.8291 - val_accuracy: 0.4764\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7018 - accuracy: 0.4973 - val_loss: 1.8711 - val_accuracy: 0.4680\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7047 - accuracy: 0.4897 - val_loss: 1.8463 - val_accuracy: 0.4621\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6905 - accuracy: 0.5005 - val_loss: 1.8529 - val_accuracy: 0.4714\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.7015 - accuracy: 0.4995 - val_loss: 1.8241 - val_accuracy: 0.4705\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6874 - accuracy: 0.4915 - val_loss: 1.8076 - val_accuracy: 0.4722\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6934 - accuracy: 0.4955 - val_loss: 1.8215 - val_accuracy: 0.4646\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6822 - accuracy: 0.4966 - val_loss: 1.8483 - val_accuracy: 0.4588\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6495 - accuracy: 0.5049 - val_loss: 1.8136 - val_accuracy: 0.4823\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6674 - accuracy: 0.5052 - val_loss: 1.8153 - val_accuracy: 0.4899\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6733 - accuracy: 0.4977 - val_loss: 1.8299 - val_accuracy: 0.4537\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6629 - accuracy: 0.5013 - val_loss: 1.8006 - val_accuracy: 0.4747\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6632 - accuracy: 0.4969 - val_loss: 1.8099 - val_accuracy: 0.4697\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6536 - accuracy: 0.5023 - val_loss: 1.8152 - val_accuracy: 0.4655\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6666 - accuracy: 0.5002 - val_loss: 1.8022 - val_accuracy: 0.4747\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6553 - accuracy: 0.5056 - val_loss: 1.8006 - val_accuracy: 0.4739\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6446 - accuracy: 0.5078 - val_loss: 1.7872 - val_accuracy: 0.4672\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6448 - accuracy: 0.4980 - val_loss: 1.8097 - val_accuracy: 0.4907\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6445 - accuracy: 0.5045 - val_loss: 1.7952 - val_accuracy: 0.4815\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6457 - accuracy: 0.5085 - val_loss: 1.7867 - val_accuracy: 0.4840\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6270 - accuracy: 0.5081 - val_loss: 1.8135 - val_accuracy: 0.4562\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6210 - accuracy: 0.5117 - val_loss: 1.7835 - val_accuracy: 0.4840\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6240 - accuracy: 0.5078 - val_loss: 1.7832 - val_accuracy: 0.4798\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6118 - accuracy: 0.5009 - val_loss: 1.7886 - val_accuracy: 0.4739\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6011 - accuracy: 0.5182 - val_loss: 1.8012 - val_accuracy: 0.4562\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6017 - accuracy: 0.5258 - val_loss: 1.7802 - val_accuracy: 0.4798\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6021 - accuracy: 0.5110 - val_loss: 1.7852 - val_accuracy: 0.4806\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.6029 - accuracy: 0.5179 - val_loss: 1.7995 - val_accuracy: 0.4815\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.6007 - accuracy: 0.5171 - val_loss: 1.7844 - val_accuracy: 0.4705\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.5941 - accuracy: 0.5085 - val_loss: 1.8541 - val_accuracy: 0.4562\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.5878 - accuracy: 0.5164 - val_loss: 1.7640 - val_accuracy: 0.4722\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5686 - accuracy: 0.5164 - val_loss: 1.7736 - val_accuracy: 0.4781\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.5722 - accuracy: 0.5146 - val_loss: 1.7661 - val_accuracy: 0.4899\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.5814 - accuracy: 0.5226 - val_loss: 1.7732 - val_accuracy: 0.4756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16fbc07e80>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 6s 53ms/step - loss: 2.8927 - sparse_top_k_categorical_accuracy: 0.2945 - val_loss: 2.8627 - val_sparse_top_k_categorical_accuracy: 0.4983\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.7056 - sparse_top_k_categorical_accuracy: 0.4266 - val_loss: 2.7438 - val_sparse_top_k_categorical_accuracy: 0.4832\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.6193 - sparse_top_k_categorical_accuracy: 0.4590 - val_loss: 2.6106 - val_sparse_top_k_categorical_accuracy: 0.5025\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.5536 - sparse_top_k_categorical_accuracy: 0.4832 - val_loss: 2.5077 - val_sparse_top_k_categorical_accuracy: 0.5042\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.4346 - sparse_top_k_categorical_accuracy: 0.5088 - val_loss: 2.4530 - val_sparse_top_k_categorical_accuracy: 0.5059\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.3592 - sparse_top_k_categorical_accuracy: 0.5305 - val_loss: 2.4022 - val_sparse_top_k_categorical_accuracy: 0.5589\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.3082 - sparse_top_k_categorical_accuracy: 0.5370 - val_loss: 2.3523 - val_sparse_top_k_categorical_accuracy: 0.5261\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.2697 - sparse_top_k_categorical_accuracy: 0.5431 - val_loss: 2.2582 - val_sparse_top_k_categorical_accuracy: 0.5572\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.1984 - sparse_top_k_categorical_accuracy: 0.5594 - val_loss: 2.2424 - val_sparse_top_k_categorical_accuracy: 0.5909\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.1715 - sparse_top_k_categorical_accuracy: 0.5651 - val_loss: 2.2507 - val_sparse_top_k_categorical_accuracy: 0.6069\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 2.1552 - sparse_top_k_categorical_accuracy: 0.5835 - val_loss: 2.2132 - val_sparse_top_k_categorical_accuracy: 0.6221\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.1368 - sparse_top_k_categorical_accuracy: 0.5807 - val_loss: 2.1616 - val_sparse_top_k_categorical_accuracy: 0.6246\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 5s 52ms/step - loss: 2.1028 - sparse_top_k_categorical_accuracy: 0.6005 - val_loss: 2.1195 - val_sparse_top_k_categorical_accuracy: 0.6162\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.0832 - sparse_top_k_categorical_accuracy: 0.6019 - val_loss: 2.1941 - val_sparse_top_k_categorical_accuracy: 0.6406\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.0720 - sparse_top_k_categorical_accuracy: 0.5994 - val_loss: 2.2098 - val_sparse_top_k_categorical_accuracy: 0.6204\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.0509 - sparse_top_k_categorical_accuracy: 0.6092 - val_loss: 2.1752 - val_sparse_top_k_categorical_accuracy: 0.6456\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.0364 - sparse_top_k_categorical_accuracy: 0.6160 - val_loss: 2.1562 - val_sparse_top_k_categorical_accuracy: 0.6069\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.0115 - sparse_top_k_categorical_accuracy: 0.6113 - val_loss: 2.0505 - val_sparse_top_k_categorical_accuracy: 0.6355\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 2.0256 - sparse_top_k_categorical_accuracy: 0.6229 - val_loss: 2.1551 - val_sparse_top_k_categorical_accuracy: 0.6372\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9976 - sparse_top_k_categorical_accuracy: 0.6135 - val_loss: 2.0661 - val_sparse_top_k_categorical_accuracy: 0.6532\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9692 - sparse_top_k_categorical_accuracy: 0.6207 - val_loss: 2.0534 - val_sparse_top_k_categorical_accuracy: 0.6574\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9598 - sparse_top_k_categorical_accuracy: 0.6254 - val_loss: 2.1198 - val_sparse_top_k_categorical_accuracy: 0.6271\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9666 - sparse_top_k_categorical_accuracy: 0.6261 - val_loss: 2.0806 - val_sparse_top_k_categorical_accuracy: 0.6608\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9513 - sparse_top_k_categorical_accuracy: 0.6272 - val_loss: 2.0638 - val_sparse_top_k_categorical_accuracy: 0.6549\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9400 - sparse_top_k_categorical_accuracy: 0.6442 - val_loss: 2.0307 - val_sparse_top_k_categorical_accuracy: 0.6599\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.9291 - sparse_top_k_categorical_accuracy: 0.6467 - val_loss: 2.0253 - val_sparse_top_k_categorical_accuracy: 0.6582\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9223 - sparse_top_k_categorical_accuracy: 0.6384 - val_loss: 2.0318 - val_sparse_top_k_categorical_accuracy: 0.6566\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8934 - sparse_top_k_categorical_accuracy: 0.6435 - val_loss: 2.0304 - val_sparse_top_k_categorical_accuracy: 0.6608\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.9261 - sparse_top_k_categorical_accuracy: 0.6380 - val_loss: 2.0833 - val_sparse_top_k_categorical_accuracy: 0.6524\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.9038 - sparse_top_k_categorical_accuracy: 0.6453 - val_loss: 2.0380 - val_sparse_top_k_categorical_accuracy: 0.6700\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8944 - sparse_top_k_categorical_accuracy: 0.6499 - val_loss: 2.0098 - val_sparse_top_k_categorical_accuracy: 0.6540\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8799 - sparse_top_k_categorical_accuracy: 0.6463 - val_loss: 2.0173 - val_sparse_top_k_categorical_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8973 - sparse_top_k_categorical_accuracy: 0.6435 - val_loss: 1.9861 - val_sparse_top_k_categorical_accuracy: 0.6894\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8559 - sparse_top_k_categorical_accuracy: 0.6629 - val_loss: 1.9740 - val_sparse_top_k_categorical_accuracy: 0.6684\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8663 - sparse_top_k_categorical_accuracy: 0.6662 - val_loss: 1.9751 - val_sparse_top_k_categorical_accuracy: 0.6843\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8700 - sparse_top_k_categorical_accuracy: 0.6539 - val_loss: 2.0113 - val_sparse_top_k_categorical_accuracy: 0.6810\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8612 - sparse_top_k_categorical_accuracy: 0.6561 - val_loss: 1.9484 - val_sparse_top_k_categorical_accuracy: 0.6835\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8551 - sparse_top_k_categorical_accuracy: 0.6601 - val_loss: 1.9477 - val_sparse_top_k_categorical_accuracy: 0.6793\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8155 - sparse_top_k_categorical_accuracy: 0.6665 - val_loss: 1.9514 - val_sparse_top_k_categorical_accuracy: 0.6835\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8141 - sparse_top_k_categorical_accuracy: 0.6720 - val_loss: 1.9723 - val_sparse_top_k_categorical_accuracy: 0.6785\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.8120 - sparse_top_k_categorical_accuracy: 0.6658 - val_loss: 2.0130 - val_sparse_top_k_categorical_accuracy: 0.6751\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.8064 - sparse_top_k_categorical_accuracy: 0.6651 - val_loss: 1.9514 - val_sparse_top_k_categorical_accuracy: 0.6894\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7985 - sparse_top_k_categorical_accuracy: 0.6810 - val_loss: 1.9411 - val_sparse_top_k_categorical_accuracy: 0.7003\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7961 - sparse_top_k_categorical_accuracy: 0.6763 - val_loss: 1.9193 - val_sparse_top_k_categorical_accuracy: 0.6827\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7989 - sparse_top_k_categorical_accuracy: 0.6712 - val_loss: 1.9331 - val_sparse_top_k_categorical_accuracy: 0.6827\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.8048 - sparse_top_k_categorical_accuracy: 0.6687 - val_loss: 1.9322 - val_sparse_top_k_categorical_accuracy: 0.6768\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7918 - sparse_top_k_categorical_accuracy: 0.6709 - val_loss: 1.9366 - val_sparse_top_k_categorical_accuracy: 0.6995\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7866 - sparse_top_k_categorical_accuracy: 0.6720 - val_loss: 1.9093 - val_sparse_top_k_categorical_accuracy: 0.6902\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7563 - sparse_top_k_categorical_accuracy: 0.6799 - val_loss: 1.9494 - val_sparse_top_k_categorical_accuracy: 0.6801\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7708 - sparse_top_k_categorical_accuracy: 0.6875 - val_loss: 1.9094 - val_sparse_top_k_categorical_accuracy: 0.6995\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7689 - sparse_top_k_categorical_accuracy: 0.6734 - val_loss: 1.8842 - val_sparse_top_k_categorical_accuracy: 0.7037\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7486 - sparse_top_k_categorical_accuracy: 0.6821 - val_loss: 1.9171 - val_sparse_top_k_categorical_accuracy: 0.6700\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7597 - sparse_top_k_categorical_accuracy: 0.6925 - val_loss: 1.9071 - val_sparse_top_k_categorical_accuracy: 0.7037\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7437 - sparse_top_k_categorical_accuracy: 0.6900 - val_loss: 1.8819 - val_sparse_top_k_categorical_accuracy: 0.6894\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.7349 - sparse_top_k_categorical_accuracy: 0.6875 - val_loss: 1.9045 - val_sparse_top_k_categorical_accuracy: 0.7029\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7360 - sparse_top_k_categorical_accuracy: 0.6904 - val_loss: 1.8772 - val_sparse_top_k_categorical_accuracy: 0.7012\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7209 - sparse_top_k_categorical_accuracy: 0.6918 - val_loss: 1.9071 - val_sparse_top_k_categorical_accuracy: 0.7037\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7256 - sparse_top_k_categorical_accuracy: 0.7012 - val_loss: 1.8500 - val_sparse_top_k_categorical_accuracy: 0.7088\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7341 - sparse_top_k_categorical_accuracy: 0.6947 - val_loss: 1.8980 - val_sparse_top_k_categorical_accuracy: 0.7003\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7147 - sparse_top_k_categorical_accuracy: 0.6943 - val_loss: 1.8634 - val_sparse_top_k_categorical_accuracy: 0.6995\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7388 - sparse_top_k_categorical_accuracy: 0.6922 - val_loss: 1.8928 - val_sparse_top_k_categorical_accuracy: 0.6978\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6917 - sparse_top_k_categorical_accuracy: 0.6889 - val_loss: 1.8686 - val_sparse_top_k_categorical_accuracy: 0.6995\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7073 - sparse_top_k_categorical_accuracy: 0.6994 - val_loss: 1.8544 - val_sparse_top_k_categorical_accuracy: 0.7029\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7037 - sparse_top_k_categorical_accuracy: 0.7030 - val_loss: 1.8809 - val_sparse_top_k_categorical_accuracy: 0.6944\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6951 - sparse_top_k_categorical_accuracy: 0.7052 - val_loss: 1.8814 - val_sparse_top_k_categorical_accuracy: 0.7088\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7135 - sparse_top_k_categorical_accuracy: 0.7001 - val_loss: 1.8589 - val_sparse_top_k_categorical_accuracy: 0.7062\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.7142 - sparse_top_k_categorical_accuracy: 0.6972 - val_loss: 1.8656 - val_sparse_top_k_categorical_accuracy: 0.7020\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6940 - sparse_top_k_categorical_accuracy: 0.7041 - val_loss: 1.8385 - val_sparse_top_k_categorical_accuracy: 0.7062\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6963 - sparse_top_k_categorical_accuracy: 0.7030 - val_loss: 1.8482 - val_sparse_top_k_categorical_accuracy: 0.6978\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.6687 - sparse_top_k_categorical_accuracy: 0.7055 - val_loss: 1.8734 - val_sparse_top_k_categorical_accuracy: 0.6961\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6762 - sparse_top_k_categorical_accuracy: 0.7044 - val_loss: 1.8615 - val_sparse_top_k_categorical_accuracy: 0.7012\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6712 - sparse_top_k_categorical_accuracy: 0.7055 - val_loss: 1.8480 - val_sparse_top_k_categorical_accuracy: 0.6953\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6760 - sparse_top_k_categorical_accuracy: 0.7070 - val_loss: 1.8444 - val_sparse_top_k_categorical_accuracy: 0.7012\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6603 - sparse_top_k_categorical_accuracy: 0.7099 - val_loss: 1.8496 - val_sparse_top_k_categorical_accuracy: 0.7003\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6846 - sparse_top_k_categorical_accuracy: 0.7037 - val_loss: 1.8380 - val_sparse_top_k_categorical_accuracy: 0.7079\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6641 - sparse_top_k_categorical_accuracy: 0.7001 - val_loss: 1.8674 - val_sparse_top_k_categorical_accuracy: 0.6961\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6358 - sparse_top_k_categorical_accuracy: 0.7070 - val_loss: 1.8490 - val_sparse_top_k_categorical_accuracy: 0.7020\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6766 - sparse_top_k_categorical_accuracy: 0.6994 - val_loss: 1.8303 - val_sparse_top_k_categorical_accuracy: 0.7020\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6543 - sparse_top_k_categorical_accuracy: 0.7016 - val_loss: 1.8435 - val_sparse_top_k_categorical_accuracy: 0.6953\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6497 - sparse_top_k_categorical_accuracy: 0.7066 - val_loss: 1.8476 - val_sparse_top_k_categorical_accuracy: 0.7003\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6453 - sparse_top_k_categorical_accuracy: 0.7066 - val_loss: 1.8224 - val_sparse_top_k_categorical_accuracy: 0.7079\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6493 - sparse_top_k_categorical_accuracy: 0.7135 - val_loss: 1.8265 - val_sparse_top_k_categorical_accuracy: 0.7088\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6556 - sparse_top_k_categorical_accuracy: 0.7077 - val_loss: 1.8252 - val_sparse_top_k_categorical_accuracy: 0.7062\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6428 - sparse_top_k_categorical_accuracy: 0.7149 - val_loss: 1.8080 - val_sparse_top_k_categorical_accuracy: 0.7121\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6124 - sparse_top_k_categorical_accuracy: 0.7210 - val_loss: 1.8130 - val_sparse_top_k_categorical_accuracy: 0.7104\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6330 - sparse_top_k_categorical_accuracy: 0.7243 - val_loss: 1.8271 - val_sparse_top_k_categorical_accuracy: 0.7037\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6227 - sparse_top_k_categorical_accuracy: 0.7163 - val_loss: 1.8106 - val_sparse_top_k_categorical_accuracy: 0.7113\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6133 - sparse_top_k_categorical_accuracy: 0.7127 - val_loss: 1.8137 - val_sparse_top_k_categorical_accuracy: 0.7113\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6269 - sparse_top_k_categorical_accuracy: 0.7124 - val_loss: 1.8219 - val_sparse_top_k_categorical_accuracy: 0.6944\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6122 - sparse_top_k_categorical_accuracy: 0.7156 - val_loss: 1.8043 - val_sparse_top_k_categorical_accuracy: 0.7130\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6188 - sparse_top_k_categorical_accuracy: 0.7232 - val_loss: 1.8184 - val_sparse_top_k_categorical_accuracy: 0.7088\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6506 - sparse_top_k_categorical_accuracy: 0.7142 - val_loss: 1.8244 - val_sparse_top_k_categorical_accuracy: 0.7054\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.5746 - sparse_top_k_categorical_accuracy: 0.7254 - val_loss: 1.7988 - val_sparse_top_k_categorical_accuracy: 0.7130\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.6157 - sparse_top_k_categorical_accuracy: 0.7124 - val_loss: 1.7992 - val_sparse_top_k_categorical_accuracy: 0.7079\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6015 - sparse_top_k_categorical_accuracy: 0.7218 - val_loss: 1.8152 - val_sparse_top_k_categorical_accuracy: 0.6995\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.6203 - sparse_top_k_categorical_accuracy: 0.7127 - val_loss: 1.8360 - val_sparse_top_k_categorical_accuracy: 0.7003\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 4s 50ms/step - loss: 1.5968 - sparse_top_k_categorical_accuracy: 0.7228 - val_loss: 1.8174 - val_sparse_top_k_categorical_accuracy: 0.7121\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 4s 52ms/step - loss: 1.6076 - sparse_top_k_categorical_accuracy: 0.7174 - val_loss: 1.7883 - val_sparse_top_k_categorical_accuracy: 0.7121\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.6030 - sparse_top_k_categorical_accuracy: 0.7283 - val_loss: 1.8134 - val_sparse_top_k_categorical_accuracy: 0.7029\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 1.5904 - sparse_top_k_categorical_accuracy: 0.7192 - val_loss: 1.8049 - val_sparse_top_k_categorical_accuracy: 0.7062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f168a5ad6a0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = [keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2784 - accuracy: 0.5844 - val_loss: 1.7574 - val_accuracy: 0.4964\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2457 - accuracy: 0.5942 - val_loss: 1.8897 - val_accuracy: 0.5072\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2404 - accuracy: 0.5937 - val_loss: 1.8630 - val_accuracy: 0.5109\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 1.2265 - accuracy: 0.6035 - val_loss: 1.7694 - val_accuracy: 0.5060\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2094 - accuracy: 0.5989 - val_loss: 1.8367 - val_accuracy: 0.5133\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1796 - accuracy: 0.6035 - val_loss: 2.0629 - val_accuracy: 0.3998\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2013 - accuracy: 0.6071 - val_loss: 1.8257 - val_accuracy: 0.5109\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1526 - accuracy: 0.6185 - val_loss: 1.8691 - val_accuracy: 0.5254\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 1.1574 - accuracy: 0.6123 - val_loss: 1.8108 - val_accuracy: 0.5036\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1529 - accuracy: 0.6263 - val_loss: 1.8755 - val_accuracy: 0.5109\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1092 - accuracy: 0.6310 - val_loss: 1.8763 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1256 - accuracy: 0.6284 - val_loss: 2.0322 - val_accuracy: 0.5145\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1215 - accuracy: 0.6413 - val_loss: 1.9290 - val_accuracy: 0.5205\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0654 - accuracy: 0.6372 - val_loss: 1.9509 - val_accuracy: 0.5072\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0581 - accuracy: 0.6449 - val_loss: 1.9835 - val_accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0589 - accuracy: 0.6527 - val_loss: 1.9572 - val_accuracy: 0.5181\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0569 - accuracy: 0.6563 - val_loss: 1.9781 - val_accuracy: 0.5254\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0661 - accuracy: 0.6449 - val_loss: 1.9489 - val_accuracy: 0.5133\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0308 - accuracy: 0.6429 - val_loss: 1.9786 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0227 - accuracy: 0.6630 - val_loss: 1.8873 - val_accuracy: 0.5278\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 1.0157 - accuracy: 0.6511 - val_loss: 2.0042 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.9873 - accuracy: 0.6713 - val_loss: 2.1186 - val_accuracy: 0.5350\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.9612 - accuracy: 0.6770 - val_loss: 1.9654 - val_accuracy: 0.4915\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9762 - accuracy: 0.6755 - val_loss: 2.0648 - val_accuracy: 0.5290\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9915 - accuracy: 0.6713 - val_loss: 2.3275 - val_accuracy: 0.4891\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9297 - accuracy: 0.6817 - val_loss: 2.1610 - val_accuracy: 0.5072\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.9424 - accuracy: 0.6744 - val_loss: 2.1035 - val_accuracy: 0.5181\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9515 - accuracy: 0.6724 - val_loss: 2.0163 - val_accuracy: 0.5109\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9469 - accuracy: 0.6749 - val_loss: 2.0647 - val_accuracy: 0.5374\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9365 - accuracy: 0.6869 - val_loss: 2.2604 - val_accuracy: 0.5048\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9597 - accuracy: 0.6848 - val_loss: 2.1316 - val_accuracy: 0.4879\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9028 - accuracy: 0.6832 - val_loss: 2.1520 - val_accuracy: 0.5217\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8621 - accuracy: 0.6962 - val_loss: 2.2660 - val_accuracy: 0.5314\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8855 - accuracy: 0.6920 - val_loss: 2.0611 - val_accuracy: 0.5121\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8844 - accuracy: 0.6915 - val_loss: 2.2029 - val_accuracy: 0.5085\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8578 - accuracy: 0.6977 - val_loss: 2.1734 - val_accuracy: 0.5229\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8387 - accuracy: 0.7008 - val_loss: 2.2852 - val_accuracy: 0.5254\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8444 - accuracy: 0.7091 - val_loss: 2.2293 - val_accuracy: 0.5193\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8455 - accuracy: 0.7008 - val_loss: 2.2512 - val_accuracy: 0.5036\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8886 - accuracy: 0.7029 - val_loss: 2.2100 - val_accuracy: 0.5205\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8362 - accuracy: 0.7122 - val_loss: 2.1289 - val_accuracy: 0.5097\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8160 - accuracy: 0.7122 - val_loss: 2.3446 - val_accuracy: 0.5254\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8296 - accuracy: 0.7091 - val_loss: 2.1915 - val_accuracy: 0.5338\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8256 - accuracy: 0.7060 - val_loss: 2.2858 - val_accuracy: 0.5350\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8116 - accuracy: 0.7164 - val_loss: 2.1918 - val_accuracy: 0.5266\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7862 - accuracy: 0.7195 - val_loss: 2.3047 - val_accuracy: 0.5399\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7909 - accuracy: 0.7236 - val_loss: 2.3242 - val_accuracy: 0.5145\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7761 - accuracy: 0.7350 - val_loss: 2.2756 - val_accuracy: 0.5024\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7540 - accuracy: 0.7396 - val_loss: 2.4233 - val_accuracy: 0.5338\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7312 - accuracy: 0.7376 - val_loss: 2.3827 - val_accuracy: 0.5326\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7493 - accuracy: 0.7402 - val_loss: 2.2171 - val_accuracy: 0.5242\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7452 - accuracy: 0.7448 - val_loss: 2.5775 - val_accuracy: 0.5085\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7500 - accuracy: 0.7417 - val_loss: 2.2388 - val_accuracy: 0.5386\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7109 - accuracy: 0.7443 - val_loss: 2.4954 - val_accuracy: 0.5145\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7347 - accuracy: 0.7407 - val_loss: 2.5598 - val_accuracy: 0.5338\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7297 - accuracy: 0.7459 - val_loss: 2.5323 - val_accuracy: 0.5435\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6978 - accuracy: 0.7609 - val_loss: 2.6251 - val_accuracy: 0.5205\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6960 - accuracy: 0.7531 - val_loss: 2.5936 - val_accuracy: 0.5435\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.6847 - accuracy: 0.7614 - val_loss: 2.4615 - val_accuracy: 0.5338\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6648 - accuracy: 0.7697 - val_loss: 2.4331 - val_accuracy: 0.5133\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6939 - accuracy: 0.7541 - val_loss: 2.5501 - val_accuracy: 0.5326\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7023 - accuracy: 0.7583 - val_loss: 2.6862 - val_accuracy: 0.5205\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6686 - accuracy: 0.7697 - val_loss: 2.4433 - val_accuracy: 0.5229\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6924 - accuracy: 0.7557 - val_loss: 2.4473 - val_accuracy: 0.5326\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6847 - accuracy: 0.7635 - val_loss: 2.3938 - val_accuracy: 0.5447\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6777 - accuracy: 0.7697 - val_loss: 2.3531 - val_accuracy: 0.5193\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6504 - accuracy: 0.7785 - val_loss: 2.6729 - val_accuracy: 0.5217\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6452 - accuracy: 0.7852 - val_loss: 2.6209 - val_accuracy: 0.5072\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6348 - accuracy: 0.7852 - val_loss: 2.5896 - val_accuracy: 0.5302\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6170 - accuracy: 0.7888 - val_loss: 2.5461 - val_accuracy: 0.5157\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6082 - accuracy: 0.7873 - val_loss: 2.7019 - val_accuracy: 0.5411\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6353 - accuracy: 0.7940 - val_loss: 2.5372 - val_accuracy: 0.5254\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6040 - accuracy: 0.7945 - val_loss: 2.5384 - val_accuracy: 0.5193\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5934 - accuracy: 0.7992 - val_loss: 2.6678 - val_accuracy: 0.5290\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6143 - accuracy: 0.7867 - val_loss: 2.6392 - val_accuracy: 0.5229\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6195 - accuracy: 0.7873 - val_loss: 2.8649 - val_accuracy: 0.5471\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.6145 - accuracy: 0.7914 - val_loss: 2.7866 - val_accuracy: 0.5169\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6032 - accuracy: 0.7935 - val_loss: 2.7970 - val_accuracy: 0.5254\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5726 - accuracy: 0.7966 - val_loss: 2.6996 - val_accuracy: 0.5266\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5559 - accuracy: 0.8069 - val_loss: 2.8125 - val_accuracy: 0.5242\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5538 - accuracy: 0.8100 - val_loss: 2.7374 - val_accuracy: 0.5193\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5673 - accuracy: 0.8111 - val_loss: 2.8036 - val_accuracy: 0.5326\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5464 - accuracy: 0.8126 - val_loss: 2.9280 - val_accuracy: 0.5447\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5694 - accuracy: 0.8033 - val_loss: 3.0114 - val_accuracy: 0.5338\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5332 - accuracy: 0.8225 - val_loss: 2.6997 - val_accuracy: 0.5290\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5260 - accuracy: 0.8225 - val_loss: 3.0751 - val_accuracy: 0.5242\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5481 - accuracy: 0.8142 - val_loss: 2.9539 - val_accuracy: 0.5133\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5501 - accuracy: 0.8178 - val_loss: 2.7995 - val_accuracy: 0.5181\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5386 - accuracy: 0.8131 - val_loss: 2.5509 - val_accuracy: 0.5121\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5267 - accuracy: 0.8219 - val_loss: 2.7742 - val_accuracy: 0.5302\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5257 - accuracy: 0.8307 - val_loss: 2.9228 - val_accuracy: 0.5302\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5350 - accuracy: 0.8137 - val_loss: 2.8183 - val_accuracy: 0.5205\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5475 - accuracy: 0.8204 - val_loss: 2.7037 - val_accuracy: 0.5290\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5125 - accuracy: 0.8328 - val_loss: 3.0115 - val_accuracy: 0.5386\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.5120 - accuracy: 0.8183 - val_loss: 2.8394 - val_accuracy: 0.5085\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5065 - accuracy: 0.8292 - val_loss: 2.8374 - val_accuracy: 0.5229\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.4772 - accuracy: 0.8271 - val_loss: 3.1375 - val_accuracy: 0.5181\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5131 - accuracy: 0.8328 - val_loss: 3.0833 - val_accuracy: 0.5205\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5097 - accuracy: 0.8282 - val_loss: 2.8459 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5044 - accuracy: 0.8318 - val_loss: 2.8745 - val_accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41887d32b0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 787)]             0         \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 787, 100)          920500    \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 787, 100)          0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32)                12864     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 934,024\n",
      "Trainable params: 934,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzd6af/.local/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(32, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.2)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(20, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.007, decay=.0008, centered=True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 22s 236ms/step - loss: 2.6651 - accuracy: 0.2292 - val_loss: 2.5141 - val_accuracy: 0.3207\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 2.2748 - accuracy: 0.3786 - val_loss: 2.2696 - val_accuracy: 0.3603\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 19s 222ms/step - loss: 2.0948 - accuracy: 0.4132 - val_loss: 1.9617 - val_accuracy: 0.4217\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 19s 223ms/step - loss: 1.8591 - accuracy: 0.4717 - val_loss: 1.8413 - val_accuracy: 0.4680\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 19s 223ms/step - loss: 1.6512 - accuracy: 0.5218 - val_loss: 1.6956 - val_accuracy: 0.4949\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 1.5162 - accuracy: 0.5431 - val_loss: 1.6302 - val_accuracy: 0.5177\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 19s 223ms/step - loss: 1.3892 - accuracy: 0.5770 - val_loss: 1.6235 - val_accuracy: 0.5160\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 1.2875 - accuracy: 0.6070 - val_loss: 1.7391 - val_accuracy: 0.4874\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 1.2044 - accuracy: 0.6258 - val_loss: 1.6226 - val_accuracy: 0.5219\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 1.1290 - accuracy: 0.6496 - val_loss: 1.6663 - val_accuracy: 0.5185\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 1.0448 - accuracy: 0.6774 - val_loss: 1.7191 - val_accuracy: 0.5227\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 0.9938 - accuracy: 0.6871 - val_loss: 1.7202 - val_accuracy: 0.5236\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 19s 223ms/step - loss: 0.9459 - accuracy: 0.6997 - val_loss: 1.8136 - val_accuracy: 0.5059\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.8881 - accuracy: 0.7145 - val_loss: 1.8520 - val_accuracy: 0.5227\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.8427 - accuracy: 0.7340 - val_loss: 1.8531 - val_accuracy: 0.5109\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.7796 - accuracy: 0.7568 - val_loss: 1.8678 - val_accuracy: 0.5311\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 0.7588 - accuracy: 0.7571 - val_loss: 1.9605 - val_accuracy: 0.4992\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.7011 - accuracy: 0.7864 - val_loss: 2.0277 - val_accuracy: 0.5210\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 0.6775 - accuracy: 0.7961 - val_loss: 2.0158 - val_accuracy: 0.5101\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.6468 - accuracy: 0.8026 - val_loss: 2.0626 - val_accuracy: 0.5152\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 0.6012 - accuracy: 0.8131 - val_loss: 2.0966 - val_accuracy: 0.5328\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.5805 - accuracy: 0.8174 - val_loss: 2.1690 - val_accuracy: 0.5253\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 0.5548 - accuracy: 0.8257 - val_loss: 2.2001 - val_accuracy: 0.5093\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.5397 - accuracy: 0.8315 - val_loss: 2.1297 - val_accuracy: 0.5202\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 0.5161 - accuracy: 0.8409 - val_loss: 2.1810 - val_accuracy: 0.5295\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.4769 - accuracy: 0.8481 - val_loss: 2.2246 - val_accuracy: 0.5202\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.4862 - accuracy: 0.8455 - val_loss: 2.2064 - val_accuracy: 0.5219\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.4407 - accuracy: 0.8585 - val_loss: 2.3899 - val_accuracy: 0.5210\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 0.4422 - accuracy: 0.8618 - val_loss: 2.2783 - val_accuracy: 0.5278\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 20s 229ms/step - loss: 0.4134 - accuracy: 0.8690 - val_loss: 2.4530 - val_accuracy: 0.4966\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 0.3919 - accuracy: 0.8791 - val_loss: 2.3955 - val_accuracy: 0.5118\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.3854 - accuracy: 0.8795 - val_loss: 2.4782 - val_accuracy: 0.5067\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 0.3789 - accuracy: 0.8827 - val_loss: 2.4590 - val_accuracy: 0.5093\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 0.3628 - accuracy: 0.8896 - val_loss: 2.5238 - val_accuracy: 0.4992\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.3460 - accuracy: 0.8943 - val_loss: 2.5288 - val_accuracy: 0.4983\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.3386 - accuracy: 0.8928 - val_loss: 2.5892 - val_accuracy: 0.5059\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.3074 - accuracy: 0.9033 - val_loss: 2.6306 - val_accuracy: 0.4924\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2973 - accuracy: 0.9087 - val_loss: 2.7299 - val_accuracy: 0.5084\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 19s 224ms/step - loss: 0.3121 - accuracy: 0.9087 - val_loss: 2.7173 - val_accuracy: 0.5017\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2998 - accuracy: 0.9008 - val_loss: 2.7150 - val_accuracy: 0.4857\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2860 - accuracy: 0.9148 - val_loss: 2.7328 - val_accuracy: 0.5051\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2657 - accuracy: 0.9206 - val_loss: 2.7669 - val_accuracy: 0.5076\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2621 - accuracy: 0.9202 - val_loss: 2.8298 - val_accuracy: 0.4891\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 0.2532 - accuracy: 0.9231 - val_loss: 2.8413 - val_accuracy: 0.5017\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2501 - accuracy: 0.9249 - val_loss: 2.8530 - val_accuracy: 0.4992\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2570 - accuracy: 0.9199 - val_loss: 2.9408 - val_accuracy: 0.4949\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2197 - accuracy: 0.9350 - val_loss: 2.9588 - val_accuracy: 0.4848\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 0.2237 - accuracy: 0.9307 - val_loss: 2.9554 - val_accuracy: 0.5067\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 0.2173 - accuracy: 0.9358 - val_loss: 2.9721 - val_accuracy: 0.4848\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 0.2075 - accuracy: 0.9376 - val_loss: 2.9986 - val_accuracy: 0.4941\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 0.2171 - accuracy: 0.9350 - val_loss: 3.0351 - val_accuracy: 0.4975\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 20s 228ms/step - loss: 0.1977 - accuracy: 0.9437 - val_loss: 3.0618 - val_accuracy: 0.5067\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 20s 230ms/step - loss: 0.1935 - accuracy: 0.9477 - val_loss: 3.0649 - val_accuracy: 0.4983\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 0.1942 - accuracy: 0.9408 - val_loss: 3.1507 - val_accuracy: 0.4815\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 20s 228ms/step - loss: 0.1943 - accuracy: 0.9408 - val_loss: 3.1536 - val_accuracy: 0.4840\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 20s 229ms/step - loss: 0.1805 - accuracy: 0.9480 - val_loss: 3.1405 - val_accuracy: 0.4899\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 20s 228ms/step - loss: 0.1869 - accuracy: 0.9426 - val_loss: 3.1623 - val_accuracy: 0.4832\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 0.1804 - accuracy: 0.9502 - val_loss: 3.1650 - val_accuracy: 0.4865\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 0.1768 - accuracy: 0.9470 - val_loss: 3.2046 - val_accuracy: 0.4949\n",
      "Epoch 60/100\n",
      "26/87 [=======>......................] - ETA: 12s - loss: 0.1814 - accuracy: 0.9423"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-5ea1866fd44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 880)]             0         \n",
      "                                                                 \n",
      " embedding_9 (Embedding)     (None, 880, 100)          925700    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 880, 100)          0         \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 64)                31872     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 958,807\n",
      "Trainable params: 958,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.35)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(64, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.35)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(20, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.005, decay=.0008, centered = True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 [==============================] - 94s 261ms/step - loss: 2.5274 - sparse_top_k_categorical_accuracy: 0.5057 - val_loss: 2.0911 - val_sparse_top_k_categorical_accuracy: 0.6247\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 2.0542 - sparse_top_k_categorical_accuracy: 0.6485 - val_loss: 1.8773 - val_sparse_top_k_categorical_accuracy: 0.6885\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 1.8230 - sparse_top_k_categorical_accuracy: 0.6944 - val_loss: 1.6556 - val_sparse_top_k_categorical_accuracy: 0.7332\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 1.6400 - sparse_top_k_categorical_accuracy: 0.7434 - val_loss: 1.5777 - val_sparse_top_k_categorical_accuracy: 0.7581\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 96s 272ms/step - loss: 1.5243 - sparse_top_k_categorical_accuracy: 0.7733 - val_loss: 1.4617 - val_sparse_top_k_categorical_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 1.4194 - sparse_top_k_categorical_accuracy: 0.7971 - val_loss: 1.4207 - val_sparse_top_k_categorical_accuracy: 0.7912\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 1.3449 - sparse_top_k_categorical_accuracy: 0.8216 - val_loss: 1.4142 - val_sparse_top_k_categorical_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 95s 270ms/step - loss: 1.2827 - sparse_top_k_categorical_accuracy: 0.8234 - val_loss: 1.3817 - val_sparse_top_k_categorical_accuracy: 0.8028\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 95s 269ms/step - loss: 1.2289 - sparse_top_k_categorical_accuracy: 0.8337 - val_loss: 1.3729 - val_sparse_top_k_categorical_accuracy: 0.8111\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 95s 271ms/step - loss: 1.1704 - sparse_top_k_categorical_accuracy: 0.8454 - val_loss: 1.3874 - val_sparse_top_k_categorical_accuracy: 0.8111\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 93s 265ms/step - loss: 1.1082 - sparse_top_k_categorical_accuracy: 0.8600 - val_loss: 1.3951 - val_sparse_top_k_categorical_accuracy: 0.8094\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 1.0573 - sparse_top_k_categorical_accuracy: 0.8660 - val_loss: 1.4087 - val_sparse_top_k_categorical_accuracy: 0.8152\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 1.0315 - sparse_top_k_categorical_accuracy: 0.8795 - val_loss: 1.3828 - val_sparse_top_k_categorical_accuracy: 0.8194\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.9790 - sparse_top_k_categorical_accuracy: 0.8820 - val_loss: 1.3853 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.9404 - sparse_top_k_categorical_accuracy: 0.8959 - val_loss: 1.3853 - val_sparse_top_k_categorical_accuracy: 0.8169\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.9340 - sparse_top_k_categorical_accuracy: 0.8973 - val_loss: 1.4279 - val_sparse_top_k_categorical_accuracy: 0.8186\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 91s 260ms/step - loss: 0.8876 - sparse_top_k_categorical_accuracy: 0.8984 - val_loss: 1.4392 - val_sparse_top_k_categorical_accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 92s 263ms/step - loss: 0.8531 - sparse_top_k_categorical_accuracy: 0.9080 - val_loss: 1.4393 - val_sparse_top_k_categorical_accuracy: 0.8260\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 96s 272ms/step - loss: 0.8282 - sparse_top_k_categorical_accuracy: 0.9119 - val_loss: 1.4265 - val_sparse_top_k_categorical_accuracy: 0.8268\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.8170 - sparse_top_k_categorical_accuracy: 0.9094 - val_loss: 1.4708 - val_sparse_top_k_categorical_accuracy: 0.8210\n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.7747 - sparse_top_k_categorical_accuracy: 0.9172 - val_loss: 1.4463 - val_sparse_top_k_categorical_accuracy: 0.8268\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 95s 270ms/step - loss: 0.7517 - sparse_top_k_categorical_accuracy: 0.9193 - val_loss: 1.5004 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.7454 - sparse_top_k_categorical_accuracy: 0.9325 - val_loss: 1.4870 - val_sparse_top_k_categorical_accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 94s 267ms/step - loss: 0.7521 - sparse_top_k_categorical_accuracy: 0.9247 - val_loss: 1.4721 - val_sparse_top_k_categorical_accuracy: 0.8244\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.6869 - sparse_top_k_categorical_accuracy: 0.9364 - val_loss: 1.5367 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 96s 273ms/step - loss: 0.6904 - sparse_top_k_categorical_accuracy: 0.9350 - val_loss: 1.5360 - val_sparse_top_k_categorical_accuracy: 0.8260\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.6535 - sparse_top_k_categorical_accuracy: 0.9367 - val_loss: 1.5488 - val_sparse_top_k_categorical_accuracy: 0.8169\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 93s 264ms/step - loss: 0.6460 - sparse_top_k_categorical_accuracy: 0.9378 - val_loss: 1.5701 - val_sparse_top_k_categorical_accuracy: 0.8219\n",
      "Epoch 29/100\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.6258 - sparse_top_k_categorical_accuracy: 0.9435 - val_loss: 1.5538 - val_sparse_top_k_categorical_accuracy: 0.8210\n",
      "Epoch 30/100\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.6072 - sparse_top_k_categorical_accuracy: 0.9428 - val_loss: 1.6035 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.5934 - sparse_top_k_categorical_accuracy: 0.9421 - val_loss: 1.6080 - val_sparse_top_k_categorical_accuracy: 0.8252\n",
      "Epoch 32/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.5759 - sparse_top_k_categorical_accuracy: 0.9460"
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "check = 'distilbert-base-uncased'\n",
    "token = AutoTokenizer.from_pretrained(check)\n",
    "input_tokens = token(list(xtrain), padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tokens = token(list(xtest), padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "train_data = tf.data.Dataset.from_tensor_slices((dict(input_tokens), ytrain))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((dict(eval_tokens), ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_26']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(check, num_labels=20)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = .00018,decay=.0008)#, centered=True)\n",
    "model.compile(optimizer=optimizer,loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  15380     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,968,852\n",
      "Trainable params: 66,968,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "166/176 [===========================>..] - ETA: 37s - loss: 2.5442 - accuracy: 0.2127"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8319e2208dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_data.shuffle(1000).batch(16), validation_data = test_data.shuffle(1000).batch(16), batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss=loss, metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "174/174 [==============================] - 1260s 7s/step - loss: 2.0395 - sparse_top_k_categorical_accuracy: 0.6283 - val_loss: 1.7268 - val_sparse_top_k_categorical_accuracy: 0.7382\n",
      "Epoch 2/15\n",
      "174/174 [==============================] - 1237s 7s/step - loss: 1.6074 - sparse_top_k_categorical_accuracy: 0.7488 - val_loss: 1.6142 - val_sparse_top_k_categorical_accuracy: 0.7525\n",
      "Epoch 3/15\n",
      "174/174 [==============================] - 1238s 7s/step - loss: 1.3726 - sparse_top_k_categorical_accuracy: 0.8160 - val_loss: 1.4395 - val_sparse_top_k_categorical_accuracy: 0.8148\n",
      "Epoch 4/15\n",
      "174/174 [==============================] - 1237s 7s/step - loss: 1.1236 - sparse_top_k_categorical_accuracy: 0.8704 - val_loss: 1.3942 - val_sparse_top_k_categorical_accuracy: 0.8215\n",
      "Epoch 5/15\n",
      "174/174 [==============================] - 1237s 7s/step - loss: 0.9143 - sparse_top_k_categorical_accuracy: 0.9130 - val_loss: 1.5269 - val_sparse_top_k_categorical_accuracy: 0.8157\n",
      "Epoch 6/15\n",
      "174/174 [==============================] - 1233s 7s/step - loss: 0.7167 - sparse_top_k_categorical_accuracy: 0.9498 - val_loss: 1.6157 - val_sparse_top_k_categorical_accuracy: 0.7955\n",
      "Epoch 7/15\n",
      "174/174 [==============================] - ETA: 0s - loss: 0.5564 - sparse_top_k_categorical_accuracy: 0.9592"
     ]
    }
   ],
   "source": [
    "model.fit(train_data.shuffle(1000).batch(16), validation_data = test_data.shuffle(1000).batch(16), batch_size=16, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "176/176 [==============================] - 1423s 8s/step - loss: 2.1344 - sparse_top_k_categorical_accuracy: 0.6436 - val_loss: 1.7439 - val_sparse_top_k_categorical_accuracy: 0.7514\n",
      "Epoch 2/3\n",
      "176/176 [==============================] - 1409s 8s/step - loss: 1.6062 - sparse_top_k_categorical_accuracy: 0.7900 - val_loss: 1.4481 - val_sparse_top_k_categorical_accuracy: 0.8078\n",
      "Epoch 3/3\n",
      "176/176 [==============================] - 1410s 8s/step - loss: 1.3266 - sparse_top_k_categorical_accuracy: 0.8429 - val_loss: 1.3275 - val_sparse_top_k_categorical_accuracy: 0.8492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a3f9a3b50>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data.shuffle(1000).batch(16), validation_data = test_data.shuffle(1000).batch(16), batch_size=16, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
