{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Apple Cranberry Pecan Salad</td>\n",
       "      <td>6 cups baby spinach 1 Granny Smith apple, thi...</td>\n",
       "      <td>To make the vinaigrette, whisk together olive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salad</td>\n",
       "      <td>Asian Pasta Salad</td>\n",
       "      <td>8 ounces elbows pasta 1 California Avocado, h...</td>\n",
       "      <td>To make the dressing, whisk together soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick-easy</td>\n",
       "      <td>Vegetable Kabobs</td>\n",
       "      <td>2 cups cremini mushrooms 1 cup cherry tomatoe...</td>\n",
       "      <td>Preheat oven to 400 degrees F. In a small bow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salad</td>\n",
       "      <td>Harvest Cobb Salad</td>\n",
       "      <td>4 slices bacon, diced 2 large eggs 6 cups cho...</td>\n",
       "      <td>To make the poppy seed dressing, whisk togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicken-recipes</td>\n",
       "      <td>Quick Chicken and Broccoli Stir Fry</td>\n",
       "      <td>1 pound boneless, skinless chicken breasts, c...</td>\n",
       "      <td>In a small bowl, whisk together soy sauce, oy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                title  \\\n",
       "0        appetizer          Apple Cranberry Pecan Salad   \n",
       "1            salad                    Asian Pasta Salad   \n",
       "2       quick-easy                     Vegetable Kabobs   \n",
       "3            salad                   Harvest Cobb Salad   \n",
       "4  chicken-recipes  Quick Chicken and Broccoli Stir Fry   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0   6 cups baby spinach 1 Granny Smith apple, thi...   \n",
       "1   8 ounces elbows pasta 1 California Avocado, h...   \n",
       "2   2 cups cremini mushrooms 1 cup cherry tomatoe...   \n",
       "3   4 slices bacon, diced 2 large eggs 6 cups cho...   \n",
       "4   1 pound boneless, skinless chicken breasts, c...   \n",
       "\n",
       "                                        instructions  \n",
       "0   To make the vinaigrette, whisk together olive...  \n",
       "1   To make the dressing, whisk together soy sauc...  \n",
       "2   Preheat oven to 400 degrees F. In a small bow...  \n",
       "3   To make the poppy seed dressing, whisk togeth...  \n",
       "4   In a small bowl, whisk together soy sauce, oy...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "colin = pd.read_csv('colin_webscrap.csv')\n",
    "colin.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(colin.shape)\n",
    "colin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4479, 4)\n",
      "(1608, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Greek Orzo Salad With Feta</td>\n",
       "      <td>1/3 cup olive oil 3 Tbsp fresh lemon juice 1 c...</td>\n",
       "      <td>In a medium mixing bowl whisk together olive o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Lemon Parmesan Kale Salad</td>\n",
       "      <td>2/3 cup olive oil 1/4 cup fresh lemon juice 1 ...</td>\n",
       "      <td>In a mixing bowl whisk together olive oil, lem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Arugula Salad</td>\n",
       "      <td>5 oz. baby arugula ((full grown works too)) 2/...</td>\n",
       "      <td>Make the dressing: In a small mixing bowl whis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Avocado Fries - Fried or Baked</td>\n",
       "      <td>2 large (8.5 oz each) avocados, (firm but just...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>appetizer</td>\n",
       "      <td>Couscous Salad Recipe</td>\n",
       "      <td>1 cup dry Moroccan couscous* 1 cup warm water*...</td>\n",
       "      <td>Bring water to a boil in a medium saucepan. Ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                           title  \\\n",
       "0  appetizer      Greek Orzo Salad With Feta   \n",
       "1  appetizer       Lemon Parmesan Kale Salad   \n",
       "2  appetizer                   Arugula Salad   \n",
       "3  appetizer  Avocado Fries - Fried or Baked   \n",
       "4  appetizer           Couscous Salad Recipe   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  1/3 cup olive oil 3 Tbsp fresh lemon juice 1 c...   \n",
       "1  2/3 cup olive oil 1/4 cup fresh lemon juice 1 ...   \n",
       "2  5 oz. baby arugula ((full grown works too)) 2/...   \n",
       "3  2 large (8.5 oz each) avocados, (firm but just...   \n",
       "4  1 cup dry Moroccan couscous* 1 cup warm water*...   \n",
       "\n",
       "                                        instructions  \n",
       "0  In a medium mixing bowl whisk together olive o...  \n",
       "1  In a mixing bowl whisk together olive oil, lem...  \n",
       "2  Make the dressing: In a small mixing bowl whis...  \n",
       "3                                                NaN  \n",
       "4  Bring water to a boil in a medium saucepan. Ri...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan = pd.read_csv('cooking_classy_text_data.csv')\n",
    "ryan.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(ryan.shape)\n",
    "ryan.isna().sum()\n",
    "#ryan.head()\n",
    "print(ryan.drop_duplicates('title').shape)\n",
    "ryan = ryan.drop_duplicates('title')\n",
    "ryan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ryan = ryan.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicates\n",
    "colin.drop_duplicates('title').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Title</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Gnocchi, Mushroom and Kale Soup</td>\n",
       "      <td>Sauté the veggies. Heat oil in a large stockpo...</td>\n",
       "      <td>2 tablespoons olive oil 1 medium white onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Greek Salmon Salad Bowls</td>\n",
       "      <td>Cook the salmon. Season the salmon with a few ...</td>\n",
       "      <td>1 pound salmon filets fine sea salt and freshl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Pasta alla Boscaiola</td>\n",
       "      <td>Soften the mushrooms. In a medium saucepan, st...</td>\n",
       "      <td>3 cups vegetable broth 1 ounce dried porcini m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Lemony Lentil Soup</td>\n",
       "      <td>Stovetop Instructions:  Sauté the veggies. Hea...</td>\n",
       "      <td>1 tablespoon olive oil 1 medium white onion, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-course</td>\n",
       "      <td>Guinness Beef Stew</td>\n",
       "      <td>Sear the beef. Generously season the beef with...</td>\n",
       "      <td>3 tablespoons olive oil, divided 3 pounds beef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cat                            Title  \\\n",
       "0  main-course  Gnocchi, Mushroom and Kale Soup   \n",
       "1  main-course         Greek Salmon Salad Bowls   \n",
       "2  main-course             Pasta alla Boscaiola   \n",
       "3  main-course               Lemony Lentil Soup   \n",
       "4  main-course               Guinness Beef Stew   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Sauté the veggies. Heat oil in a large stockpo...   \n",
       "1  Cook the salmon. Season the salmon with a few ...   \n",
       "2  Soften the mushrooms. In a medium saucepan, st...   \n",
       "3  Stovetop Instructions:  Sauté the veggies. Hea...   \n",
       "4  Sear the beef. Generously season the beef with...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  2 tablespoons olive oil 1 medium white onion, ...  \n",
       "1  1 pound salmon filets fine sea salt and freshl...  \n",
       "2  3 cups vegetable broth 1 ounce dried porcini m...  \n",
       "3  1 tablespoon olive oil 1 medium white onion, p...  \n",
       "4  3 tablespoons olive oil, divided 3 pounds beef...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = pd.read_csv('GSOScrapped.csv')\n",
    "print(ed.shape)\n",
    "ed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.drop_duplicates('Title').shape\n",
    "ed = ed.drop_duplicates('Title')\n",
    "ed = ed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1362, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'Title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'title', 'ingredients', 'instructions'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cat', 'title', 'ingredients', 'instructions'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'instructions', 'ingredients'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = ed.rename(columns={'Title':'title'})\n",
    "ryan = ryan.rename(columns={'category':'cat'})\n",
    "print(ryan.columns)\n",
    "ed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4051, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = colin.append(ed).reset_index().drop('index',axis=1)\n",
    "merged = merged.append(ryan).reset_index().drop('index', axis=1)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>treats</td>\n",
       "      <td>Chocolate Chip Cookie Dough Fudge</td>\n",
       "      <td>1 cup granulated sugar 1 cup light-brown sugar...</td>\n",
       "      <td>In a 3 quart saucepan combine granulated sugar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>treats</td>\n",
       "      <td>Peanut Butter Pretzel Rice Krispie Treats</td>\n",
       "      <td>1/4 cup butter 1  (10.5 oz) package miniature ...</td>\n",
       "      <td>Butter a 9x13 dish, set aside.  Melt butter in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>treats</td>\n",
       "      <td>Fancy Caramel Popcorn</td>\n",
       "      <td>1/3 cup un-popped popcorn kernels 2 ½ cups min...</td>\n",
       "      <td>Pop popcorn kernels in a popcorn popper into a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>treats</td>\n",
       "      <td>Cookies and Cream Rice Krispie Treats</td>\n",
       "      <td>1/4 cup salted butter 1  (10.5) oz bag mini ma...</td>\n",
       "      <td>Butter a 13 x 9 pan, set aside.  Melt butter i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>treats</td>\n",
       "      <td>Old Fashioned Pink Popcorn</td>\n",
       "      <td>2/3 cup un-popped popcorn kernels 2 cups granu...</td>\n",
       "      <td>Pop popcorn into a large bowl according to man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat                                      title  \\\n",
       "4046  treats          Chocolate Chip Cookie Dough Fudge   \n",
       "4047  treats  Peanut Butter Pretzel Rice Krispie Treats   \n",
       "4048  treats                      Fancy Caramel Popcorn   \n",
       "4049  treats      Cookies and Cream Rice Krispie Treats   \n",
       "4050  treats                 Old Fashioned Pink Popcorn   \n",
       "\n",
       "                                            ingredients  \\\n",
       "4046  1 cup granulated sugar 1 cup light-brown sugar...   \n",
       "4047  1/4 cup butter 1  (10.5 oz) package miniature ...   \n",
       "4048  1/3 cup un-popped popcorn kernels 2 ½ cups min...   \n",
       "4049  1/4 cup salted butter 1  (10.5) oz bag mini ma...   \n",
       "4050  2/3 cup un-popped popcorn kernels 2 cups granu...   \n",
       "\n",
       "                                           instructions  \n",
       "4046  In a 3 quart saucepan combine granulated sugar...  \n",
       "4047  Butter a 9x13 dish, set aside.  Melt butter in...  \n",
       "4048  Pop popcorn kernels in a popcorn popper into a...  \n",
       "4049  Butter a 13 x 9 pan, set aside.  Melt butter i...  \n",
       "4050  Pop popcorn into a large bowl according to man...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( 'dip' in merged[merged.cat == 'game-day'].title):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow Cooker Corn and Jalapeno Dip\n",
      "Crab Rangoon Dip\n",
      "Beef Queso Dip\n",
      "Beef Enchilada Dip\n",
      "Hot Cheesy Corn Dip\n",
      "Cheesy Bacon Spinach Dip\n",
      "Bacon Corn Dip\n",
      "French Onion Dip\n"
     ]
    }
   ],
   "source": [
    "for x in merged[merged.cat == 'game-day'].title:\n",
    "    if('Dip' in x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>side</td>\n",
       "      <td>Hasselback Potatoes Recipe</td>\n",
       "      <td>6 (7 to 8 oz) red potatoes (or Yukon gold pota...</td>\n",
       "      <td>Preheat oven to 425 degrees. Line a 13 by 9-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>side</td>\n",
       "      <td>Baked Sweet Potato Fries</td>\n",
       "      <td>2 lbs sweet potatoes peeled and cut into 1/2-i...</td>\n",
       "      <td>Heat oven and prepare baking sheets: Set oven ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>side</td>\n",
       "      <td>Garlic Butter Rice Recipe</td>\n",
       "      <td>1 1/2 cups dry long grain white rice, (or jasm...</td>\n",
       "      <td>Melt 1 Tbsp butter in a large saucepan over me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>side</td>\n",
       "      <td>Crockpot Mashed Potatoes Recipe</td>\n",
       "      <td>2 1/2 cups water 2 cups low-sodium chicken bro...</td>\n",
       "      <td>Pour water and chicken broth into a 4 - 6 quar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>side</td>\n",
       "      <td>How to Make Bread Crumbs</td>\n",
       "      <td>4 to 5 slices white bread ((about 4 to 6 oz de...</td>\n",
       "      <td>Preheat oven to 275 degrees. Tear bread into s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>side</td>\n",
       "      <td>Lemon Couscous Recipe</td>\n",
       "      <td>2 Tbsp extra virgin olive oil 1 1/2 tsp minced...</td>\n",
       "      <td>Heat olive oil in a medium saucepan over mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>side</td>\n",
       "      <td>German Potato Salad</td>\n",
       "      <td>2 lbs red potatoes (or Yukon gold potatoes (ea...</td>\n",
       "      <td>Place red potatoes on a steamer basket* set in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>side</td>\n",
       "      <td>Homemade BBQ Sauce Recipe</td>\n",
       "      <td>3/4 cup ketchup ((preferably without corn syru...</td>\n",
       "      <td>Add all ingredients to a small saucepan. Bring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>side</td>\n",
       "      <td>Pizza Sauce Recipe</td>\n",
       "      <td>1 1/2 Tbsp extra virgin olive oil 2 tsp minced...</td>\n",
       "      <td>Heat olive oil in a medium saucepan over mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>side</td>\n",
       "      <td>Mashed Potatoes Recipe</td>\n",
       "      <td>3 lbs. russet potatoes, (peeled and rinsed cle...</td>\n",
       "      <td>Place potatoes in a colander and rinse under c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>side</td>\n",
       "      <td>Twice Baked Potatoes</td>\n",
       "      <td>4 (13 - 14 oz. each) large baker russet potato...</td>\n",
       "      <td>Preheat oven and prep potatoes: Preheat oven t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>side</td>\n",
       "      <td>French Fries {Oven Baked}</td>\n",
       "      <td>1 1/2 lbs Russet Potatoes, (about 3 medium) (c...</td>\n",
       "      <td>Preheat oven to 475 degrees. Place potatoes in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>side</td>\n",
       "      <td>Cheesy Potatoes (Loaded with Bacon and Ranch)</td>\n",
       "      <td>6 slices bacon, (cooked and crumbled or choppe...</td>\n",
       "      <td>Preheat oven to 400 degrees. Spray a rimmed ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>side</td>\n",
       "      <td>Parmesan Mashed Potatoes (Baked)</td>\n",
       "      <td>4 lbs yellow potatoes or russet potatoes, (pee...</td>\n",
       "      <td>Preheat oven to 400 degrees. Grease a 13 by 9-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>side</td>\n",
       "      <td>How to Make Chicken Stock</td>\n",
       "      <td>1  bones from one large chicken 1/2 large yell...</td>\n",
       "      <td>Place chicken carcass (including any wing bone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>side</td>\n",
       "      <td>Mac and Cheese (Easy Stovetop Recipe)</td>\n",
       "      <td>14 oz. dry elbow macaroni Salt 3 1/2 Tbsp butt...</td>\n",
       "      <td>Bring a large pot of salted water to a boil, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>side</td>\n",
       "      <td>Greek Pasta Salad</td>\n",
       "      <td>1 (16 oz.) box Barilla Rotini 1  English cucum...</td>\n",
       "      <td>Prepare the dressing by whisking together extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>side</td>\n",
       "      <td>Easy Gravy</td>\n",
       "      <td>3 Tbsp fat drippings  ((from any type of roast...</td>\n",
       "      <td>Cook fat drippings and broth in a saucepan or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>side</td>\n",
       "      <td>Grilled Mexican Street Corn (Elotes)</td>\n",
       "      <td>6 ears yellow corn (, shucked (that pictured h...</td>\n",
       "      <td>Preheat a grill to medium-high heat (to about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>side</td>\n",
       "      <td>Broccoli Mac and Cheese (Easy Stovetop Recipe)</td>\n",
       "      <td>8 oz. dry elbow pasta Salt 4 cups broccoli flo...</td>\n",
       "      <td>Cook pasta in salted boiling water according t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat                                           title  \\\n",
       "4015  side                      Hasselback Potatoes Recipe   \n",
       "4016  side                        Baked Sweet Potato Fries   \n",
       "4017  side                       Garlic Butter Rice Recipe   \n",
       "4018  side                 Crockpot Mashed Potatoes Recipe   \n",
       "4019  side                        How to Make Bread Crumbs   \n",
       "4020  side                           Lemon Couscous Recipe   \n",
       "4021  side                             German Potato Salad   \n",
       "4022  side                       Homemade BBQ Sauce Recipe   \n",
       "4023  side                              Pizza Sauce Recipe   \n",
       "4024  side                          Mashed Potatoes Recipe   \n",
       "4025  side                            Twice Baked Potatoes   \n",
       "4026  side                       French Fries {Oven Baked}   \n",
       "4027  side   Cheesy Potatoes (Loaded with Bacon and Ranch)   \n",
       "4028  side                Parmesan Mashed Potatoes (Baked)   \n",
       "4029  side                       How to Make Chicken Stock   \n",
       "4030  side           Mac and Cheese (Easy Stovetop Recipe)   \n",
       "4031  side                               Greek Pasta Salad   \n",
       "4032  side                                      Easy Gravy   \n",
       "4033  side            Grilled Mexican Street Corn (Elotes)   \n",
       "4034  side  Broccoli Mac and Cheese (Easy Stovetop Recipe)   \n",
       "\n",
       "                                            ingredients  \\\n",
       "4015  6 (7 to 8 oz) red potatoes (or Yukon gold pota...   \n",
       "4016  2 lbs sweet potatoes peeled and cut into 1/2-i...   \n",
       "4017  1 1/2 cups dry long grain white rice, (or jasm...   \n",
       "4018  2 1/2 cups water 2 cups low-sodium chicken bro...   \n",
       "4019  4 to 5 slices white bread ((about 4 to 6 oz de...   \n",
       "4020  2 Tbsp extra virgin olive oil 1 1/2 tsp minced...   \n",
       "4021  2 lbs red potatoes (or Yukon gold potatoes (ea...   \n",
       "4022  3/4 cup ketchup ((preferably without corn syru...   \n",
       "4023  1 1/2 Tbsp extra virgin olive oil 2 tsp minced...   \n",
       "4024  3 lbs. russet potatoes, (peeled and rinsed cle...   \n",
       "4025  4 (13 - 14 oz. each) large baker russet potato...   \n",
       "4026  1 1/2 lbs Russet Potatoes, (about 3 medium) (c...   \n",
       "4027  6 slices bacon, (cooked and crumbled or choppe...   \n",
       "4028  4 lbs yellow potatoes or russet potatoes, (pee...   \n",
       "4029  1  bones from one large chicken 1/2 large yell...   \n",
       "4030  14 oz. dry elbow macaroni Salt 3 1/2 Tbsp butt...   \n",
       "4031  1 (16 oz.) box Barilla Rotini 1  English cucum...   \n",
       "4032  3 Tbsp fat drippings  ((from any type of roast...   \n",
       "4033  6 ears yellow corn (, shucked (that pictured h...   \n",
       "4034  8 oz. dry elbow pasta Salt 4 cups broccoli flo...   \n",
       "\n",
       "                                           instructions  \n",
       "4015  Preheat oven to 425 degrees. Line a 13 by 9-in...  \n",
       "4016  Heat oven and prepare baking sheets: Set oven ...  \n",
       "4017  Melt 1 Tbsp butter in a large saucepan over me...  \n",
       "4018  Pour water and chicken broth into a 4 - 6 quar...  \n",
       "4019  Preheat oven to 275 degrees. Tear bread into s...  \n",
       "4020  Heat olive oil in a medium saucepan over mediu...  \n",
       "4021  Place red potatoes on a steamer basket* set in...  \n",
       "4022  Add all ingredients to a small saucepan. Bring...  \n",
       "4023  Heat olive oil in a medium saucepan over mediu...  \n",
       "4024  Place potatoes in a colander and rinse under c...  \n",
       "4025  Preheat oven and prep potatoes: Preheat oven t...  \n",
       "4026  Preheat oven to 475 degrees. Place potatoes in...  \n",
       "4027  Preheat oven to 400 degrees. Spray a rimmed ba...  \n",
       "4028  Preheat oven to 400 degrees. Grease a 13 by 9-...  \n",
       "4029  Place chicken carcass (including any wing bone...  \n",
       "4030  Bring a large pot of salted water to a boil, b...  \n",
       "4031  Prepare the dressing by whisking together extr...  \n",
       "4032  Cook fat drippings and broth in a saucepan or ...  \n",
       "4033  Preheat a grill to medium-high heat (to about ...  \n",
       "4034  Cook pasta in salted boiling water according t...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged.cat == 'side'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course            618\n",
       "dessert                419\n",
       "breakfast              341\n",
       "appetizer              285\n",
       "healthy                213\n",
       "main-dish              182\n",
       "quick-easy             164\n",
       "cake                   127\n",
       "appetizers             100\n",
       "chicken-recipes        100\n",
       "holidays/christmas      95\n",
       "drinks                  91\n",
       "cookies                 90\n",
       "asian-inspired          87\n",
       "meat                    79\n",
       "pasta                   79\n",
       "soup                    76\n",
       "salad                   66\n",
       "vegetarian              58\n",
       "side-dish               55\n",
       "asian                   53\n",
       "fall-faves              47\n",
       "slow-cooker             43\n",
       "bread                   41\n",
       "bars                    41\n",
       "one-pot                 39\n",
       "entree                  38\n",
       "summer                  36\n",
       "game-day                35\n",
       "instant-pot-recipes     26\n",
       "drink                   26\n",
       "christmas               26\n",
       "thanksgiving            25\n",
       "side                    21\n",
       "meal-prep               21\n",
       "baked-goods             21\n",
       "fall                    20\n",
       "beverages               19\n",
       "dip                     17\n",
       "holidays                16\n",
       "snacks                  14\n",
       "treats                  14\n",
       "salsas-sauces           14\n",
       "pastas                  13\n",
       "sandwiches              11\n",
       "smoothies               11\n",
       "mexican                  9\n",
       "pizzas                   8\n",
       "sandwich                 7\n",
       "spreads                  6\n",
       "italian                  4\n",
       "instant-pot              2\n",
       "poultry                  1\n",
       "ice-cream                1\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main-course        925\n",
       "dessert            692\n",
       "appetizers         454\n",
       "breakfast          341\n",
       "healthy            213\n",
       "quick-easy         203\n",
       "holidays           162\n",
       "drinks             147\n",
       "asian              140\n",
       "vegetarian         124\n",
       "seasonal           103\n",
       "chicken-recipes    101\n",
       "pasta               96\n",
       "soup                76\n",
       "slow-cooker         71\n",
       "baked-goods         62\n",
       "one-pot             39\n",
       "sauces              37\n",
       "game-day            35\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged.cat == 'ice-cream', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'poultry', 'cat'] = 'chicken-recipes'\n",
    "merged.loc[merged.cat == 'instant-pot', 'cat'] = 'slow-cooker'\n",
    "merged.loc[merged.cat == 'italian', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'treats', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'bars', 'cat'] = 'dessert'\n",
    "merged = merged.drop(merged[merged.cat == 'mexican'].index)\n",
    "merged = merged.drop(merged[merged.cat == 'side'].index)\n",
    "merged.loc[merged.cat == 'appetizer', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'pastas', 'cat'] = 'pasta'\n",
    "merged.loc[merged.cat == 'bread', 'cat'] = 'baked-goods'\n",
    "merged.loc[merged.cat == 'snacks', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'beverages', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'entree','cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'drink', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'smoothies', 'cat'] = 'drinks'\n",
    "merged.loc[merged.cat == 'spreads', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'salsas-sauces', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'dip', 'cat'] = 'sauces'\n",
    "merged.loc[merged.cat == 'pizzas', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'sandwiches', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'sandwich', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'fall', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'summer', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'side-dish', 'cat'] = 'appetizers'\n",
    "merged.loc[merged.cat == 'salad', 'cat'] = 'vegetarian'\n",
    "merged.loc[merged.cat == 'meal-prep', 'cat'] = 'quick-easy'\n",
    "merged.loc[merged.cat == 'thanksgiving', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'christmas', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'instant-pot-recipes', 'cat'] = 'slow-cooker'\n",
    "merged.loc[merged.cat == 'fall-faves', 'cat'] = 'seasonal'\n",
    "merged.loc[merged.cat == 'cookies', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'holidays/christmas', 'cat'] = 'holidays'\n",
    "merged.loc[merged.cat == 'cake', 'cat'] = 'dessert'\n",
    "merged.loc[merged.cat == 'meat', 'cat'] = 'main-course'\n",
    "merged.loc[merged.cat == 'asian-inspired', 'cat'] = 'asian'\n",
    "merged.loc[merged.cat == 'main-dish', 'cat'] = 'main-course'\n",
    "\n",
    "\n",
    "merged.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged.cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.cat = pd.Categorical(merged.cat)\n",
    "merged['y'] = merged.cat.cat.codes\n",
    "merged.y = [np.int64(x) for x in merged.y]\n",
    "merged.y = pd.Series(merged.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =merged.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1       18\n",
       "2       13\n",
       "3       18\n",
       "4        4\n",
       "        ..\n",
       "4046     5\n",
       "4047     5\n",
       "4048     5\n",
       "4049     5\n",
       "4050     5\n",
       "Name: y, Length: 4021, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat', 'title', 'ingredients', 'instructions', 'y'], dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4021,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.hstack(merged['title'] + merged['ingredients']+ merged['instructions'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import one_hot , Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain, ttest, ingtrain, ingtest, insttrain, insttest, y1train, y1test = train_test_split(merged.title, merged.ingredients, \n",
    "                                                                                        merged.instructions, merged.cat, test_size=.3, \n",
    "                                                                                        random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 25, 1413, 490, 25, 525, 628, 13, 1759, 358, 128, 22, 2, 2, 11, 77, 195, 2, 4, 10, 345, 675, 380, 2, 26, 49, 86, 75, 4, 26, 1662, 1632, 593, 454, 279, 1046, 248, 11, 23, 3546, 155, 182, 302, 467, 594, 248, 148, 3157, 1046, 2, 23, 1181, 4, 23, 598, 378, 248, 4, 26, 95, 38, 248, 4, 26, 149, 1, 95, 199, 248, 16, 1, 61, 46, 64, 20, 5, 47, 11, 26, 29, 128, 22, 195, 2, 2, 4, 35, 45, 316, 68, 510, 20, 5, 47, 2, 350, 58, 97, 114, 62, 979, 403, 144, 14, 11, 10, 221, 48, 2, 11, 10, 116, 381, 25, 160, 12, 6, 477, 98, 5, 388, 42, 188, 14, 26, 180, 45, 12, 345, 155, 7, 6, 28, 102, 27, 121, 56, 25, 195, 380, 86, 75, 2, 26, 1662, 1632, 14, 23, 3546, 155, 3, 1181, 2, 4, 23, 598, 378, 2, 26, 38, 2, 26, 199, 1, 16, 5, 47, 148, 177, 2, 23, 143, 27, 1, 110, 5, 289, 1, 118, 820, 101, 409, 4, 245, 1, 141, 5, 708, 245, 467, 2522, 110, 25, 5, 6, 821, 391, 201, 320, 77, 665, 34, 87, 1, 190, 22, 63, 268, 153, 1227, 37, 229, 14, 543, 410, 991, 7, 37, 137, 991, 5, 74, 21, 193, 621, 67, 25, 7, 37, 1, 633, 9, 126, 135, 1, 239, 18, 115, 142, 15, 363, 291, 29, 7, 6, 127, 39, 31, 74, 21, 19, 68, 1, 197, 9, 182, 162, 70, 18, 359, 15, 19, 113, 2, 26, 38, 1, 2, 26, 199, 1, 197, 2, 165, 266, 40, 7, 113, 2, 26, 1662, 1632, 1, 2, 2, 4, 23, 598, 378, 1, 2, 23, 3546, 197, 169, 263, 105, 7, 144, 143, 1, 174, 39, 116, 21, 115, 15, 110, 312, 30, 5, 6, 395, 143, 8, 526, 1, 79, 228, 1305, 69, 395, 526, 143, 8, 6, 2257, 1156, 533, 12, 563, 159, 576, 279, 43, 36, 116, 9, 189, 419, 43, 5, 127, 39, 31, 116, 21, 1633, 330, 352, 69, 395, 733, 22, 88, 105, 7, 221, 48, 1, 25, 160, 1, 40, 78, 43, 8, 16, 1, 20, 5, 47, 1, 510, 20, 5, 47, 19, 7, 126, 25, 195, 1, 1547, 737, 69, 34, 87, 143, 1, 138, 135, 17, 6, 332, 15, 33, 44, 138, 39, 196, 12, 8, 2157, 42, 80]\n",
      "880\n"
     ]
    }
   ],
   "source": [
    "## To DO: tokenize using keras tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(xtrain)\n",
    "vocabsize = len(t.word_index) + 1\n",
    "encoded = t.texts_to_sequences(xtrain)\n",
    "tencoded = t.texts_to_sequences(ttrain)\n",
    "ingencoded = t.texts_to_sequences(str(ingtrain))\n",
    "instencoded = t.texts_to_sequences([str(x) for x in insttrain])\n",
    "encodedtest = t.texts_to_sequences(xtest)\n",
    "print(encoded[1])\n",
    "\n",
    "maxlength = max([len(x) for x in encoded])\n",
    "print(maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_glove():\n",
    "    embeddings_index = dict()\n",
    "    f = open('./glove.6B.100d.txt') # replace this with the path to your downloaded txt file\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    # create a weight matrix for words in training docs\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "[2366 4116   35  147  257   49  205  155    2    4   10   61  217  131\n",
      "    2   14   10 2084 1304   14  108   38    2   53  324   16    2    4\n",
      "   53   61  479   64   20    2    4   10  183  697   52 3544    6  323\n",
      "  448   12  395 2009    3  205  131 1304   38   16    1   20   56    9\n",
      "  204   45    8    3  323  448   12  395  580 1095  472  297    7    3\n",
      "   52   24    9   59   54  227   81   60 4117    3  323  448   12  395\n",
      "    1  586  305    3  220   33  575  861    9    3   30   54  189   44\n",
      "   82   60 3545    7    6  545  250   17  141    5   14  511   12  581\n",
      "   17  141    5   14  838    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.initializers import Constant\n",
    "import math\n",
    "# to Do: add constants that you might need here\n",
    "n_classes=19\n",
    "embeddingdim = 100\n",
    "\n",
    "word_index=t.word_index\n",
    "\n",
    "embeddings_index = load_glove()\n",
    "embedding_matrix = np.random.random((len(word_index)+1, embeddingdim))\n",
    "for word, i in word_index.items():\n",
    "    embeddingvector = embeddings_index.get(word)\n",
    "    if embeddingvector is not None:\n",
    "        if len(embedding_matrix[i]) != len(embeddingvector):\n",
    "            print('could not be broadcast input array from shape ', str(len(embedding_matrix[i])),\n",
    "                 ' into shape ', str(len(embeddingvector)), ' Please make sure your embedding dim is equal to embedding vector file Glove')\n",
    "            exit(1)\n",
    "        \n",
    "        embedding_matrix[i] = embeddingvector\n",
    "        \n",
    "\n",
    "###To Do:  pad the train and test data \n",
    "padded = pad_sequences(encoded, maxlen=maxlength, padding='post')\n",
    "tpadded = pad_sequences(tencoded, maxlen=maxlength, padding='post')\n",
    "ingpadded = pad_sequences(ingencoded, maxlen=maxlength, padding='post')\n",
    "instpadded = pad_sequences(instencoded, maxlen=maxlength, padding='post')\n",
    "paddedtest = pad_sequences(encodedtest, maxlen=maxlength, padding='post')\n",
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 880, 100)     733700      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 880, 100)     0           ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 880, 64)      19264       ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 880, 32)      9632        ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 880, 16)      4816        ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_40 (MaxPooling1D  (None, 176, 64)     0           ['conv1d_41[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_42 (MaxPooling1D  (None, 176, 32)     0           ['conv1d_43[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_44 (MaxPooling1D  (None, 176, 16)     0           ['conv1d_45[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 176, 64)      0           ['max_pooling1d_40[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 176, 32)      0           ['max_pooling1d_42[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 176, 16)      0           ['max_pooling1d_44[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 174, 128)     24704       ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 174, 128)     12416       ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 174, 128)     6272        ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_41 (MaxPooling1D  (None, 58, 128)     0           ['conv1d_42[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_43 (MaxPooling1D  (None, 58, 128)     0           ['conv1d_44[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_45 (MaxPooling1D  (None, 58, 128)     0           ['conv1d_46[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 58, 384)      0           ['max_pooling1d_41[0][0]',       \n",
      "                                                                  'max_pooling1d_43[0][0]',       \n",
      "                                                                  'max_pooling1d_45[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 22272)        0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          2850944     ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 64)           8256        ['dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 64)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 32)           2080        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 32)           0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 19)           627         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,672,711\n",
      "Trainable params: 3,672,711\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                          input_length=maxlength, trainable=True)\n",
    "sequence_input = Input(shape=(maxlength,),dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "x = Dropout(.2)(embeddedsequences)\n",
    "x1 = Conv1D(64, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x1 = MaxPooling1D(5)(x1)\n",
    "x1 = Dropout(.2)(x1)\n",
    "x1 = Conv1D(128, 3, activation='softplus')(x1)\n",
    "x1 = MaxPooling1D(3)(x1)\n",
    "#x1 = Conv1D(256, 5, activation = 'softplus')(x1)\n",
    "#x1 = MaxPooling1D(10)(x1)\n",
    "\n",
    "x2 = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x2 = MaxPooling1D(5)(x2)\n",
    "x2 = Dropout(.2)(x2)\n",
    "x2 = Conv1D(128, 3, activation='softplus')(x2)\n",
    "x2 = MaxPooling1D(3)(x2)\n",
    "#x2 = Conv1D(256, 5, activation = 'softplus')(x2)\n",
    "#x2 = MaxPooling1D(10)(x2)\n",
    "\n",
    "x3 = Conv1D(16, kernel_size=3, padding='same', activation = 'relu')(x)\n",
    "x3 = MaxPooling1D(5)(x3)\n",
    "x3 = Dropout(.2)(x3)\n",
    "x3 = Conv1D(128, 3, activation='softplus')(x3)\n",
    "x3 = MaxPooling1D(3)(x3)\n",
    "#x3 = Conv1D(256, 5, activation = 'softplus')(x3)\n",
    "#x3 = MaxPooling1D(10)(x3)\n",
    "\n",
    "x = Concatenate()([x1,x2,x3])\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(32, activation = 'softplus')(x)\n",
    "x = Dropout(.4)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=.003, decay=.0008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 880, 100)     733700      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 880, 100)     0           ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 880, 32)      9632        ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 880, 24)      9624        ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 880, 64)      32064       ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 880, 120)     0           ['conv1d_47[0][0]',              \n",
      "                                                                  'conv1d_48[0][0]',              \n",
      "                                                                  'conv1d_49[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_46 (MaxPooling1D  (None, 176, 120)    0           ['concatenate_6[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 176, 120)     0           ['max_pooling1d_46[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 174, 128)     46208       ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_47 (MaxPooling1D  (None, 21, 128)     0           ['conv1d_50[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 17, 256)      164096      ['max_pooling1d_47[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_48 (MaxPooling1D  (None, 1, 256)      0           ['conv1d_51[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 256)          0           ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          32896       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 64)           8256        ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 64)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 19)           1235        ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,037,711\n",
      "Trainable params: 1,037,711\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(8)(x)\n",
    "x = Conv1D(256, 5, activation = 'softplus')(x)\n",
    "x = MaxPooling1D(10)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='softplus')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'softplus')(x)\n",
    "x = Dropout(.25)(x)\n",
    "#x = Dense(32, activation = 'softplus')(x)\n",
    "#x = Dropout(.2)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=.0003, decay=.00008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 4s 81ms/step - loss: 2.9222 - accuracy: 0.1858 - val_loss: 2.5904 - val_accuracy: 0.2802\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.6968 - accuracy: 0.2184 - val_loss: 2.5555 - val_accuracy: 0.2802\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.6309 - accuracy: 0.2288 - val_loss: 2.4865 - val_accuracy: 0.2802\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 2.5716 - accuracy: 0.2329 - val_loss: 2.4762 - val_accuracy: 0.2802\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.5450 - accuracy: 0.2583 - val_loss: 2.4102 - val_accuracy: 0.2802\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.4935 - accuracy: 0.2531 - val_loss: 2.3630 - val_accuracy: 0.2802\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.4322 - accuracy: 0.2567 - val_loss: 2.4158 - val_accuracy: 0.2947\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 2.4013 - accuracy: 0.2671 - val_loss: 2.3038 - val_accuracy: 0.2802\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.3359 - accuracy: 0.2945 - val_loss: 2.2490 - val_accuracy: 0.3092\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.3000 - accuracy: 0.2867 - val_loss: 2.2453 - val_accuracy: 0.3152\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.2236 - accuracy: 0.3116 - val_loss: 2.1097 - val_accuracy: 0.3080\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.1711 - accuracy: 0.3323 - val_loss: 2.1983 - val_accuracy: 0.2983\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 2.1040 - accuracy: 0.3535 - val_loss: 1.9723 - val_accuracy: 0.3937\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.0795 - accuracy: 0.3649 - val_loss: 1.9344 - val_accuracy: 0.4312\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.0025 - accuracy: 0.3923 - val_loss: 1.8970 - val_accuracy: 0.4384\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 2.0044 - accuracy: 0.4006 - val_loss: 1.8769 - val_accuracy: 0.4372\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.9642 - accuracy: 0.4079 - val_loss: 2.0110 - val_accuracy: 0.4215\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.9211 - accuracy: 0.4146 - val_loss: 1.8526 - val_accuracy: 0.4589\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.8950 - accuracy: 0.4265 - val_loss: 1.8198 - val_accuracy: 0.4336\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.8672 - accuracy: 0.4249 - val_loss: 1.8136 - val_accuracy: 0.4384\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.8643 - accuracy: 0.4224 - val_loss: 1.7839 - val_accuracy: 0.4686\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.8428 - accuracy: 0.4363 - val_loss: 1.8502 - val_accuracy: 0.4481\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.8117 - accuracy: 0.4275 - val_loss: 1.7687 - val_accuracy: 0.4541\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.7886 - accuracy: 0.4498 - val_loss: 1.7152 - val_accuracy: 0.4638\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.7737 - accuracy: 0.4596 - val_loss: 1.8115 - val_accuracy: 0.4505\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.7581 - accuracy: 0.4560 - val_loss: 1.6936 - val_accuracy: 0.4662\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.7654 - accuracy: 0.4436 - val_loss: 1.7104 - val_accuracy: 0.4626\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.7506 - accuracy: 0.4689 - val_loss: 1.9428 - val_accuracy: 0.4022\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.7028 - accuracy: 0.4705 - val_loss: 1.8228 - val_accuracy: 0.4457\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.6831 - accuracy: 0.4679 - val_loss: 1.7454 - val_accuracy: 0.4626\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.7024 - accuracy: 0.4581 - val_loss: 1.7253 - val_accuracy: 0.4553\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.6724 - accuracy: 0.4819 - val_loss: 1.7171 - val_accuracy: 0.4734\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.6284 - accuracy: 0.4772 - val_loss: 1.6445 - val_accuracy: 0.4867\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.6358 - accuracy: 0.4798 - val_loss: 1.9623 - val_accuracy: 0.4082\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.6475 - accuracy: 0.4845 - val_loss: 1.6281 - val_accuracy: 0.4746\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 1.6070 - accuracy: 0.4860 - val_loss: 1.5914 - val_accuracy: 0.4952\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.5907 - accuracy: 0.4917 - val_loss: 1.5809 - val_accuracy: 0.5048\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.5742 - accuracy: 0.5052 - val_loss: 1.6158 - val_accuracy: 0.4879\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.5818 - accuracy: 0.5016 - val_loss: 1.7780 - val_accuracy: 0.4734\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.5380 - accuracy: 0.5041 - val_loss: 1.8456 - val_accuracy: 0.4324\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.5350 - accuracy: 0.4969 - val_loss: 1.6204 - val_accuracy: 0.4988\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.5077 - accuracy: 0.5135 - val_loss: 1.5699 - val_accuracy: 0.5085\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.5046 - accuracy: 0.5186 - val_loss: 1.7272 - val_accuracy: 0.4662\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.5244 - accuracy: 0.5186 - val_loss: 1.5412 - val_accuracy: 0.4928\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.4797 - accuracy: 0.5217 - val_loss: 1.5188 - val_accuracy: 0.5205\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.4532 - accuracy: 0.5331 - val_loss: 1.6655 - val_accuracy: 0.4940\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.4568 - accuracy: 0.5269 - val_loss: 1.6183 - val_accuracy: 0.4976\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.4273 - accuracy: 0.5254 - val_loss: 1.5204 - val_accuracy: 0.5157\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.4230 - accuracy: 0.5414 - val_loss: 1.5264 - val_accuracy: 0.5217\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.4135 - accuracy: 0.5393 - val_loss: 1.5347 - val_accuracy: 0.5193\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.3941 - accuracy: 0.5414 - val_loss: 1.5627 - val_accuracy: 0.5145\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 1.3715 - accuracy: 0.5487 - val_loss: 1.5587 - val_accuracy: 0.5133\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.3933 - accuracy: 0.5450 - val_loss: 1.5132 - val_accuracy: 0.5169\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.3405 - accuracy: 0.5699 - val_loss: 1.4492 - val_accuracy: 0.5519\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.3680 - accuracy: 0.5502 - val_loss: 1.6550 - val_accuracy: 0.5048\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.3149 - accuracy: 0.5663 - val_loss: 1.4850 - val_accuracy: 0.5471\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.3036 - accuracy: 0.5756 - val_loss: 1.5068 - val_accuracy: 0.5459\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.2894 - accuracy: 0.5673 - val_loss: 1.5298 - val_accuracy: 0.5314\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2597 - accuracy: 0.5864 - val_loss: 1.5157 - val_accuracy: 0.5386\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2490 - accuracy: 0.5952 - val_loss: 1.4873 - val_accuracy: 0.5604\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.2587 - accuracy: 0.5932 - val_loss: 1.5201 - val_accuracy: 0.5290\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.2251 - accuracy: 0.6014 - val_loss: 1.5729 - val_accuracy: 0.5242\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.1974 - accuracy: 0.6051 - val_loss: 1.7417 - val_accuracy: 0.4915\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2087 - accuracy: 0.5978 - val_loss: 1.4918 - val_accuracy: 0.5374\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.2017 - accuracy: 0.5927 - val_loss: 1.7676 - val_accuracy: 0.4988\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.1902 - accuracy: 0.6082 - val_loss: 1.5060 - val_accuracy: 0.5411\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.1707 - accuracy: 0.5983 - val_loss: 1.5540 - val_accuracy: 0.5278\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.1856 - accuracy: 0.6030 - val_loss: 1.5014 - val_accuracy: 0.5386\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 1.1622 - accuracy: 0.6175 - val_loss: 1.5228 - val_accuracy: 0.5471\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.1329 - accuracy: 0.6366 - val_loss: 1.4684 - val_accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0931 - accuracy: 0.6299 - val_loss: 1.4832 - val_accuracy: 0.5483\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.0923 - accuracy: 0.6408 - val_loss: 1.4461 - val_accuracy: 0.5676\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0975 - accuracy: 0.6444 - val_loss: 1.6667 - val_accuracy: 0.5097\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.0989 - accuracy: 0.6392 - val_loss: 1.4600 - val_accuracy: 0.5713\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0698 - accuracy: 0.6403 - val_loss: 1.4993 - val_accuracy: 0.5399\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 1.0368 - accuracy: 0.6460 - val_loss: 1.5931 - val_accuracy: 0.5399\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.0321 - accuracy: 0.6563 - val_loss: 1.4839 - val_accuracy: 0.5700\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.0330 - accuracy: 0.6573 - val_loss: 1.5540 - val_accuracy: 0.5411\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.0191 - accuracy: 0.6553 - val_loss: 1.7085 - val_accuracy: 0.5278\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 1.0031 - accuracy: 0.6718 - val_loss: 1.6122 - val_accuracy: 0.5157\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.9608 - accuracy: 0.6744 - val_loss: 1.5011 - val_accuracy: 0.5604\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9974 - accuracy: 0.6542 - val_loss: 1.4616 - val_accuracy: 0.5664\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9711 - accuracy: 0.6672 - val_loss: 1.4851 - val_accuracy: 0.5592\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9597 - accuracy: 0.6812 - val_loss: 1.6515 - val_accuracy: 0.5012\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.9649 - accuracy: 0.6853 - val_loss: 1.6524 - val_accuracy: 0.5290\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9415 - accuracy: 0.6863 - val_loss: 1.5455 - val_accuracy: 0.5640\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.9347 - accuracy: 0.6915 - val_loss: 1.5832 - val_accuracy: 0.5568\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.9559 - accuracy: 0.6682 - val_loss: 1.7735 - val_accuracy: 0.5459\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.9276 - accuracy: 0.6931 - val_loss: 1.6377 - val_accuracy: 0.5664\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.9144 - accuracy: 0.7024 - val_loss: 1.5451 - val_accuracy: 0.5725\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.8861 - accuracy: 0.7013 - val_loss: 1.5385 - val_accuracy: 0.5568\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.8891 - accuracy: 0.7127 - val_loss: 1.5317 - val_accuracy: 0.5628\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8650 - accuracy: 0.7086 - val_loss: 1.4990 - val_accuracy: 0.5700\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8542 - accuracy: 0.7246 - val_loss: 1.5195 - val_accuracy: 0.5483\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8404 - accuracy: 0.7277 - val_loss: 1.5015 - val_accuracy: 0.5737\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.8268 - accuracy: 0.7246 - val_loss: 1.8011 - val_accuracy: 0.4891\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.8528 - accuracy: 0.7029 - val_loss: 1.5954 - val_accuracy: 0.5592\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.7974 - accuracy: 0.7360 - val_loss: 1.6785 - val_accuracy: 0.5350\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.8210 - accuracy: 0.7257 - val_loss: 1.5686 - val_accuracy: 0.5664\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.8051 - accuracy: 0.7277 - val_loss: 1.7368 - val_accuracy: 0.5435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2ae7a6f40>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.8344 - accuracy: 0.7298 - val_loss: 1.7000 - val_accuracy: 0.5338\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.8321 - accuracy: 0.7246 - val_loss: 1.6812 - val_accuracy: 0.5109\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7752 - accuracy: 0.7386 - val_loss: 1.5505 - val_accuracy: 0.5845\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7763 - accuracy: 0.7448 - val_loss: 1.6949 - val_accuracy: 0.5483\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7692 - accuracy: 0.7433 - val_loss: 1.6405 - val_accuracy: 0.5628\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7337 - accuracy: 0.7562 - val_loss: 1.5994 - val_accuracy: 0.5531\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7443 - accuracy: 0.7500 - val_loss: 1.5639 - val_accuracy: 0.5628\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.7183 - accuracy: 0.7619 - val_loss: 1.6930 - val_accuracy: 0.5326\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6960 - accuracy: 0.7733 - val_loss: 1.6621 - val_accuracy: 0.5471\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6635 - accuracy: 0.7738 - val_loss: 1.6573 - val_accuracy: 0.5604\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6652 - accuracy: 0.7754 - val_loss: 1.7681 - val_accuracy: 0.5773\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6695 - accuracy: 0.7723 - val_loss: 1.6626 - val_accuracy: 0.5700\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6823 - accuracy: 0.7666 - val_loss: 1.7230 - val_accuracy: 0.5737\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.6428 - accuracy: 0.7867 - val_loss: 1.7677 - val_accuracy: 0.5543\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.6092 - accuracy: 0.8023 - val_loss: 1.7571 - val_accuracy: 0.5604\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.6069 - accuracy: 0.7945 - val_loss: 1.8707 - val_accuracy: 0.5471\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5748 - accuracy: 0.8012 - val_loss: 1.8201 - val_accuracy: 0.5640\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5795 - accuracy: 0.8023 - val_loss: 1.8575 - val_accuracy: 0.5531\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5394 - accuracy: 0.8126 - val_loss: 1.8769 - val_accuracy: 0.5725\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5463 - accuracy: 0.8188 - val_loss: 1.8264 - val_accuracy: 0.5664\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5257 - accuracy: 0.8240 - val_loss: 1.8461 - val_accuracy: 0.5616\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5592 - accuracy: 0.8173 - val_loss: 1.8229 - val_accuracy: 0.5519\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.5516 - accuracy: 0.8168 - val_loss: 1.8489 - val_accuracy: 0.5688\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4972 - accuracy: 0.8323 - val_loss: 1.9127 - val_accuracy: 0.5435\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5241 - accuracy: 0.8328 - val_loss: 1.8880 - val_accuracy: 0.5616\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.5001 - accuracy: 0.8344 - val_loss: 1.8723 - val_accuracy: 0.5737\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4913 - accuracy: 0.8333 - val_loss: 1.9116 - val_accuracy: 0.5797\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4878 - accuracy: 0.8354 - val_loss: 1.9895 - val_accuracy: 0.5362\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4762 - accuracy: 0.8483 - val_loss: 1.8567 - val_accuracy: 0.5604\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.4629 - accuracy: 0.8494 - val_loss: 1.9160 - val_accuracy: 0.5459\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4294 - accuracy: 0.8582 - val_loss: 2.1348 - val_accuracy: 0.5290\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4287 - accuracy: 0.8566 - val_loss: 2.2891 - val_accuracy: 0.5386\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4559 - accuracy: 0.8463 - val_loss: 2.0919 - val_accuracy: 0.5640\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.4115 - accuracy: 0.8649 - val_loss: 2.1222 - val_accuracy: 0.5447\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4254 - accuracy: 0.8561 - val_loss: 2.0461 - val_accuracy: 0.5519\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4032 - accuracy: 0.8701 - val_loss: 2.1206 - val_accuracy: 0.5531\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.4100 - accuracy: 0.8597 - val_loss: 2.0970 - val_accuracy: 0.5749\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3831 - accuracy: 0.8742 - val_loss: 2.2270 - val_accuracy: 0.5580\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3677 - accuracy: 0.8722 - val_loss: 2.3200 - val_accuracy: 0.5616\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3649 - accuracy: 0.8804 - val_loss: 2.1318 - val_accuracy: 0.5568\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3743 - accuracy: 0.8804 - val_loss: 2.2667 - val_accuracy: 0.5519\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3682 - accuracy: 0.8830 - val_loss: 2.3790 - val_accuracy: 0.5254\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3382 - accuracy: 0.8913 - val_loss: 2.1369 - val_accuracy: 0.5604\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3354 - accuracy: 0.8960 - val_loss: 2.1730 - val_accuracy: 0.5725\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3458 - accuracy: 0.8841 - val_loss: 2.3391 - val_accuracy: 0.5640\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3527 - accuracy: 0.8846 - val_loss: 2.1676 - val_accuracy: 0.5616\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 2.2158 - val_accuracy: 0.5652\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3340 - accuracy: 0.8887 - val_loss: 2.4837 - val_accuracy: 0.5411\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3326 - accuracy: 0.8934 - val_loss: 2.3919 - val_accuracy: 0.5266\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3141 - accuracy: 0.8970 - val_loss: 2.4366 - val_accuracy: 0.5676\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.3164 - accuracy: 0.8954 - val_loss: 2.5164 - val_accuracy: 0.5628\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3087 - accuracy: 0.9032 - val_loss: 2.3958 - val_accuracy: 0.5713\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.3034 - accuracy: 0.9042 - val_loss: 2.3130 - val_accuracy: 0.5640\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.3028 - accuracy: 0.9053 - val_loss: 2.3583 - val_accuracy: 0.5568\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2900 - accuracy: 0.9073 - val_loss: 2.4301 - val_accuracy: 0.5652\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2966 - accuracy: 0.9073 - val_loss: 2.4691 - val_accuracy: 0.5640\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2925 - accuracy: 0.9058 - val_loss: 2.4759 - val_accuracy: 0.5580\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2813 - accuracy: 0.9125 - val_loss: 2.3099 - val_accuracy: 0.5725\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2492 - accuracy: 0.9198 - val_loss: 2.5422 - val_accuracy: 0.5616\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2836 - accuracy: 0.9068 - val_loss: 2.5740 - val_accuracy: 0.5543\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2695 - accuracy: 0.9156 - val_loss: 2.5470 - val_accuracy: 0.5640\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2864 - accuracy: 0.9110 - val_loss: 2.4118 - val_accuracy: 0.5568\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2580 - accuracy: 0.9151 - val_loss: 2.5301 - val_accuracy: 0.5507\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2889 - accuracy: 0.9068 - val_loss: 2.4856 - val_accuracy: 0.5459\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2358 - accuracy: 0.9203 - val_loss: 2.6055 - val_accuracy: 0.5399\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2406 - accuracy: 0.9270 - val_loss: 2.5767 - val_accuracy: 0.5531\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2440 - accuracy: 0.9234 - val_loss: 2.6720 - val_accuracy: 0.5229\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2641 - accuracy: 0.9130 - val_loss: 2.5234 - val_accuracy: 0.5700\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2411 - accuracy: 0.9239 - val_loss: 2.5553 - val_accuracy: 0.5556\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2229 - accuracy: 0.9296 - val_loss: 2.8188 - val_accuracy: 0.5362\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2460 - accuracy: 0.9193 - val_loss: 2.5636 - val_accuracy: 0.5543\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2153 - accuracy: 0.9369 - val_loss: 2.6629 - val_accuracy: 0.5604\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2356 - accuracy: 0.9281 - val_loss: 2.6128 - val_accuracy: 0.5688\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2298 - accuracy: 0.9286 - val_loss: 2.7357 - val_accuracy: 0.5399\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2254 - accuracy: 0.9327 - val_loss: 2.5903 - val_accuracy: 0.5483\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2225 - accuracy: 0.9281 - val_loss: 2.6758 - val_accuracy: 0.5556\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2071 - accuracy: 0.9384 - val_loss: 2.7835 - val_accuracy: 0.5628\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 0.2386 - accuracy: 0.9234 - val_loss: 2.5736 - val_accuracy: 0.5471\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2356 - accuracy: 0.9229 - val_loss: 2.6060 - val_accuracy: 0.5543\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2136 - accuracy: 0.9343 - val_loss: 2.7526 - val_accuracy: 0.5483\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2088 - accuracy: 0.9332 - val_loss: 2.9039 - val_accuracy: 0.5447\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2218 - accuracy: 0.9348 - val_loss: 2.6253 - val_accuracy: 0.5568\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1933 - accuracy: 0.9415 - val_loss: 2.8037 - val_accuracy: 0.5399\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1938 - accuracy: 0.9457 - val_loss: 2.7095 - val_accuracy: 0.5374\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1794 - accuracy: 0.9384 - val_loss: 3.0129 - val_accuracy: 0.5350\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.2080 - accuracy: 0.9317 - val_loss: 2.9309 - val_accuracy: 0.5435\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1752 - accuracy: 0.9462 - val_loss: 3.1121 - val_accuracy: 0.5483\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1960 - accuracy: 0.9363 - val_loss: 3.2041 - val_accuracy: 0.5302\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1921 - accuracy: 0.9441 - val_loss: 2.6933 - val_accuracy: 0.5568\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1832 - accuracy: 0.9436 - val_loss: 2.7708 - val_accuracy: 0.5640\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1998 - accuracy: 0.9389 - val_loss: 2.7818 - val_accuracy: 0.5556\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1806 - accuracy: 0.9410 - val_loss: 3.1756 - val_accuracy: 0.5157\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.2294 - accuracy: 0.9332 - val_loss: 3.0955 - val_accuracy: 0.5435\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1700 - accuracy: 0.9508 - val_loss: 2.9247 - val_accuracy: 0.5507\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1851 - accuracy: 0.9462 - val_loss: 2.8565 - val_accuracy: 0.5399\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1726 - accuracy: 0.9462 - val_loss: 2.8646 - val_accuracy: 0.5592\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1726 - accuracy: 0.9482 - val_loss: 2.9335 - val_accuracy: 0.5483\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1733 - accuracy: 0.9493 - val_loss: 2.8635 - val_accuracy: 0.5604\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1799 - accuracy: 0.9436 - val_loss: 2.8477 - val_accuracy: 0.5459\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1922 - accuracy: 0.9410 - val_loss: 3.1516 - val_accuracy: 0.5254\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1782 - accuracy: 0.9508 - val_loss: 2.9707 - val_accuracy: 0.5700\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1725 - accuracy: 0.9467 - val_loss: 3.0551 - val_accuracy: 0.5435\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1487 - accuracy: 0.9565 - val_loss: 3.1147 - val_accuracy: 0.5519\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1566 - accuracy: 0.9508 - val_loss: 3.0883 - val_accuracy: 0.5616\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1654 - accuracy: 0.9503 - val_loss: 2.9570 - val_accuracy: 0.5471\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 0.1590 - accuracy: 0.9513 - val_loss: 3.1268 - val_accuracy: 0.5543\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.1765 - accuracy: 0.9472 - val_loss: 3.0911 - val_accuracy: 0.5447\n",
      "Epoch 108/200\n",
      "49/61 [=======================>......] - ETA: 0s - loss: 0.1669 - accuracy: 0.9483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cb67e54f027f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=200, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 880, 100)     733700      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 880, 100)     0           ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 880, 32)      9632        ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 880, 24)      9624        ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 880, 64)      32064       ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 880, 120)     0           ['conv1d_52[0][0]',              \n",
      "                                                                  'conv1d_53[0][0]',              \n",
      "                                                                  'conv1d_54[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_49 (MaxPooling1D  (None, 176, 120)    0           ['concatenate_7[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 176, 120)     0           ['max_pooling1d_49[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 174, 128)     46208       ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_50 (MaxPooling1D  (None, 34, 128)     0           ['conv1d_55[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 30, 256)      164096      ['max_pooling1d_50[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_51 (MaxPooling1D  (None, 6, 256)      0           ['conv1d_56[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1536)         0           ['max_pooling1d_51[0][0]']       \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 128)          196736      ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 128)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 64)           8256        ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 64)           0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           2080        ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 32)           0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 19)           627         ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,203,023\n",
      "Trainable params: 1,203,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To Do: build model use the embedding_index from glove\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "x = Conv1D(32, kernel_size=3, padding='same', activation = 'relu')(y)\n",
    "x1 = Conv1D(24, kernel_size=4, padding = 'same',activation = 'relu')(y)\n",
    "x2 = Conv1D(64, kernel_size=5, padding = 'same',activation = 'relu')(y)\n",
    "x = Concatenate()([x,x1,x2]) \n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Conv1D(128, 3, activation = 'relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "x = Dropout(.4)(x)\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=.0003, decay=.00008)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 5s 113ms/step - loss: 2.8861 - accuracy: 0.1372 - val_loss: 2.8414 - val_accuracy: 0.2705\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.7813 - accuracy: 0.1698 - val_loss: 2.7391 - val_accuracy: 0.2935\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.7435 - accuracy: 0.1962 - val_loss: 2.6966 - val_accuracy: 0.2862\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.6838 - accuracy: 0.2086 - val_loss: 2.6847 - val_accuracy: 0.3019\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.6588 - accuracy: 0.2267 - val_loss: 2.6552 - val_accuracy: 0.3031\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.5905 - accuracy: 0.2241 - val_loss: 2.5774 - val_accuracy: 0.3056\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.5783 - accuracy: 0.2433 - val_loss: 2.6359 - val_accuracy: 0.3031\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.5855 - accuracy: 0.2350 - val_loss: 2.6490 - val_accuracy: 0.3007\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.5557 - accuracy: 0.2547 - val_loss: 2.5974 - val_accuracy: 0.3080\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.5328 - accuracy: 0.2474 - val_loss: 2.5703 - val_accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4958 - accuracy: 0.2593 - val_loss: 2.6696 - val_accuracy: 0.2923\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.4786 - accuracy: 0.2629 - val_loss: 2.5173 - val_accuracy: 0.3104\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4641 - accuracy: 0.2671 - val_loss: 2.5879 - val_accuracy: 0.3092\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4288 - accuracy: 0.2847 - val_loss: 2.4172 - val_accuracy: 0.3213\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.4224 - accuracy: 0.2759 - val_loss: 2.6320 - val_accuracy: 0.3056\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.4142 - accuracy: 0.2733 - val_loss: 2.6044 - val_accuracy: 0.3128\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.3851 - accuracy: 0.2878 - val_loss: 2.5480 - val_accuracy: 0.3152\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.3780 - accuracy: 0.2826 - val_loss: 2.5274 - val_accuracy: 0.3345\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.3502 - accuracy: 0.2883 - val_loss: 2.5622 - val_accuracy: 0.3611\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.3318 - accuracy: 0.3002 - val_loss: 2.3440 - val_accuracy: 0.3249\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.2937 - accuracy: 0.3194 - val_loss: 2.4831 - val_accuracy: 0.3599\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.2563 - accuracy: 0.3256 - val_loss: 2.2549 - val_accuracy: 0.3780\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.2147 - accuracy: 0.3364 - val_loss: 2.3244 - val_accuracy: 0.4046\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.1704 - accuracy: 0.3613 - val_loss: 2.1982 - val_accuracy: 0.3611\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.1139 - accuracy: 0.3846 - val_loss: 2.1691 - val_accuracy: 0.4348\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 2.1089 - accuracy: 0.3841 - val_loss: 2.0710 - val_accuracy: 0.4360\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.0701 - accuracy: 0.4042 - val_loss: 1.9678 - val_accuracy: 0.4348\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.0812 - accuracy: 0.4073 - val_loss: 2.0774 - val_accuracy: 0.4324\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 2.0019 - accuracy: 0.4042 - val_loss: 2.1909 - val_accuracy: 0.4227\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 2.0089 - accuracy: 0.4032 - val_loss: 1.9518 - val_accuracy: 0.4553\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9738 - accuracy: 0.4161 - val_loss: 2.0418 - val_accuracy: 0.4360\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9823 - accuracy: 0.4187 - val_loss: 1.9178 - val_accuracy: 0.4432\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9183 - accuracy: 0.4306 - val_loss: 1.9730 - val_accuracy: 0.4469\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9306 - accuracy: 0.4203 - val_loss: 2.0924 - val_accuracy: 0.4143\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.9257 - accuracy: 0.4286 - val_loss: 1.8768 - val_accuracy: 0.4517\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.9058 - accuracy: 0.4343 - val_loss: 1.9270 - val_accuracy: 0.4420\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.9272 - accuracy: 0.4244 - val_loss: 1.8690 - val_accuracy: 0.4432\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.8843 - accuracy: 0.4343 - val_loss: 2.1538 - val_accuracy: 0.3647\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.8751 - accuracy: 0.4343 - val_loss: 1.8161 - val_accuracy: 0.4662\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.8696 - accuracy: 0.4332 - val_loss: 2.0487 - val_accuracy: 0.4118\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.8392 - accuracy: 0.4513 - val_loss: 1.9274 - val_accuracy: 0.4384\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.8227 - accuracy: 0.4534 - val_loss: 1.8324 - val_accuracy: 0.4601\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.8035 - accuracy: 0.4576 - val_loss: 1.8228 - val_accuracy: 0.4553\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 3s 108ms/step - loss: 1.7906 - accuracy: 0.4570 - val_loss: 1.8620 - val_accuracy: 0.4553\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.7686 - accuracy: 0.4689 - val_loss: 1.8172 - val_accuracy: 0.4662\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7810 - accuracy: 0.4638 - val_loss: 1.7665 - val_accuracy: 0.4734\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 3s 109ms/step - loss: 1.7533 - accuracy: 0.4638 - val_loss: 1.7826 - val_accuracy: 0.4710\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7564 - accuracy: 0.4612 - val_loss: 1.8147 - val_accuracy: 0.4541\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.7398 - accuracy: 0.4658 - val_loss: 1.7743 - val_accuracy: 0.4722\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7018 - accuracy: 0.4746 - val_loss: 1.9958 - val_accuracy: 0.4070\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7199 - accuracy: 0.4669 - val_loss: 1.8051 - val_accuracy: 0.4505\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.6844 - accuracy: 0.4803 - val_loss: 1.7470 - val_accuracy: 0.4686\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.6850 - accuracy: 0.4902 - val_loss: 1.9132 - val_accuracy: 0.4505\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.7062 - accuracy: 0.4933 - val_loss: 1.8077 - val_accuracy: 0.4734\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6832 - accuracy: 0.4808 - val_loss: 1.7211 - val_accuracy: 0.4867\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.6318 - accuracy: 0.4855 - val_loss: 1.6945 - val_accuracy: 0.4855\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.6112 - accuracy: 0.4912 - val_loss: 1.7454 - val_accuracy: 0.4903\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6356 - accuracy: 0.4979 - val_loss: 1.7414 - val_accuracy: 0.4843\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.6088 - accuracy: 0.5093 - val_loss: 1.9024 - val_accuracy: 0.4710\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6263 - accuracy: 0.4953 - val_loss: 1.7104 - val_accuracy: 0.4867\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.5872 - accuracy: 0.4990 - val_loss: 1.8437 - val_accuracy: 0.4903\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 1.5903 - accuracy: 0.5140 - val_loss: 1.8010 - val_accuracy: 0.4734\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.5554 - accuracy: 0.5098 - val_loss: 1.7542 - val_accuracy: 0.4771\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.5564 - accuracy: 0.5098 - val_loss: 1.7008 - val_accuracy: 0.4928\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.5449 - accuracy: 0.5295 - val_loss: 1.7116 - val_accuracy: 0.4903\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 1.5328 - accuracy: 0.5336 - val_loss: 1.7193 - val_accuracy: 0.4976\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.5640 - accuracy: 0.5207 - val_loss: 1.7871 - val_accuracy: 0.4674\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.5119 - accuracy: 0.5259 - val_loss: 1.7909 - val_accuracy: 0.4601\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4950 - accuracy: 0.5305 - val_loss: 1.7466 - val_accuracy: 0.5181\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.5127 - accuracy: 0.5295 - val_loss: 1.7308 - val_accuracy: 0.5133\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.4852 - accuracy: 0.5383 - val_loss: 1.8060 - val_accuracy: 0.4928\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.4547 - accuracy: 0.5476 - val_loss: 1.7213 - val_accuracy: 0.4988\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.4612 - accuracy: 0.5481 - val_loss: 1.7221 - val_accuracy: 0.4879\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4276 - accuracy: 0.5528 - val_loss: 1.7502 - val_accuracy: 0.4952\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.4349 - accuracy: 0.5450 - val_loss: 1.9402 - val_accuracy: 0.4408\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4636 - accuracy: 0.5321 - val_loss: 1.7491 - val_accuracy: 0.5145\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.4394 - accuracy: 0.5383 - val_loss: 1.7698 - val_accuracy: 0.4771\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.4339 - accuracy: 0.5569 - val_loss: 1.7234 - val_accuracy: 0.5145\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3815 - accuracy: 0.5533 - val_loss: 1.8676 - val_accuracy: 0.4722\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3974 - accuracy: 0.5559 - val_loss: 1.7777 - val_accuracy: 0.4819\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3820 - accuracy: 0.5564 - val_loss: 1.8286 - val_accuracy: 0.4879\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3891 - accuracy: 0.5606 - val_loss: 1.7829 - val_accuracy: 0.4891\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3521 - accuracy: 0.5631 - val_loss: 1.8666 - val_accuracy: 0.4444\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.3729 - accuracy: 0.5580 - val_loss: 1.8108 - val_accuracy: 0.4638\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 1.3771 - accuracy: 0.5476 - val_loss: 1.8383 - val_accuracy: 0.4855\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3699 - accuracy: 0.5621 - val_loss: 2.0245 - val_accuracy: 0.4746\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3054 - accuracy: 0.5802 - val_loss: 1.7982 - val_accuracy: 0.4928\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.3088 - accuracy: 0.5771 - val_loss: 1.7773 - val_accuracy: 0.5133\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.3272 - accuracy: 0.5719 - val_loss: 1.7869 - val_accuracy: 0.5157\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.3065 - accuracy: 0.5823 - val_loss: 1.8656 - val_accuracy: 0.4928\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 1.3325 - accuracy: 0.5704 - val_loss: 1.8879 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.2893 - accuracy: 0.5761 - val_loss: 1.8474 - val_accuracy: 0.4903\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2831 - accuracy: 0.5839 - val_loss: 1.8044 - val_accuracy: 0.5133\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.3047 - accuracy: 0.5833 - val_loss: 1.7492 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.2885 - accuracy: 0.5761 - val_loss: 1.8039 - val_accuracy: 0.4964\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.2596 - accuracy: 0.5813 - val_loss: 1.8194 - val_accuracy: 0.4903\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2678 - accuracy: 0.5828 - val_loss: 1.8426 - val_accuracy: 0.5072\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2283 - accuracy: 0.6020 - val_loss: 1.8291 - val_accuracy: 0.4819\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 1.2206 - accuracy: 0.5989 - val_loss: 1.8002 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 1.2405 - accuracy: 0.5818 - val_loss: 2.2062 - val_accuracy: 0.4626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4298425100>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2784 - accuracy: 0.5844 - val_loss: 1.7574 - val_accuracy: 0.4964\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2457 - accuracy: 0.5942 - val_loss: 1.8897 - val_accuracy: 0.5072\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2404 - accuracy: 0.5937 - val_loss: 1.8630 - val_accuracy: 0.5109\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 1.2265 - accuracy: 0.6035 - val_loss: 1.7694 - val_accuracy: 0.5060\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2094 - accuracy: 0.5989 - val_loss: 1.8367 - val_accuracy: 0.5133\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1796 - accuracy: 0.6035 - val_loss: 2.0629 - val_accuracy: 0.3998\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.2013 - accuracy: 0.6071 - val_loss: 1.8257 - val_accuracy: 0.5109\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1526 - accuracy: 0.6185 - val_loss: 1.8691 - val_accuracy: 0.5254\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 1.1574 - accuracy: 0.6123 - val_loss: 1.8108 - val_accuracy: 0.5036\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1529 - accuracy: 0.6263 - val_loss: 1.8755 - val_accuracy: 0.5109\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1092 - accuracy: 0.6310 - val_loss: 1.8763 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1256 - accuracy: 0.6284 - val_loss: 2.0322 - val_accuracy: 0.5145\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.1215 - accuracy: 0.6413 - val_loss: 1.9290 - val_accuracy: 0.5205\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0654 - accuracy: 0.6372 - val_loss: 1.9509 - val_accuracy: 0.5072\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0581 - accuracy: 0.6449 - val_loss: 1.9835 - val_accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0589 - accuracy: 0.6527 - val_loss: 1.9572 - val_accuracy: 0.5181\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0569 - accuracy: 0.6563 - val_loss: 1.9781 - val_accuracy: 0.5254\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0661 - accuracy: 0.6449 - val_loss: 1.9489 - val_accuracy: 0.5133\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0308 - accuracy: 0.6429 - val_loss: 1.9786 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 1.0227 - accuracy: 0.6630 - val_loss: 1.8873 - val_accuracy: 0.5278\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 1.0157 - accuracy: 0.6511 - val_loss: 2.0042 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.9873 - accuracy: 0.6713 - val_loss: 2.1186 - val_accuracy: 0.5350\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.9612 - accuracy: 0.6770 - val_loss: 1.9654 - val_accuracy: 0.4915\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9762 - accuracy: 0.6755 - val_loss: 2.0648 - val_accuracy: 0.5290\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9915 - accuracy: 0.6713 - val_loss: 2.3275 - val_accuracy: 0.4891\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9297 - accuracy: 0.6817 - val_loss: 2.1610 - val_accuracy: 0.5072\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.9424 - accuracy: 0.6744 - val_loss: 2.1035 - val_accuracy: 0.5181\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9515 - accuracy: 0.6724 - val_loss: 2.0163 - val_accuracy: 0.5109\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9469 - accuracy: 0.6749 - val_loss: 2.0647 - val_accuracy: 0.5374\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9365 - accuracy: 0.6869 - val_loss: 2.2604 - val_accuracy: 0.5048\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9597 - accuracy: 0.6848 - val_loss: 2.1316 - val_accuracy: 0.4879\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.9028 - accuracy: 0.6832 - val_loss: 2.1520 - val_accuracy: 0.5217\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8621 - accuracy: 0.6962 - val_loss: 2.2660 - val_accuracy: 0.5314\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8855 - accuracy: 0.6920 - val_loss: 2.0611 - val_accuracy: 0.5121\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8844 - accuracy: 0.6915 - val_loss: 2.2029 - val_accuracy: 0.5085\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8578 - accuracy: 0.6977 - val_loss: 2.1734 - val_accuracy: 0.5229\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8387 - accuracy: 0.7008 - val_loss: 2.2852 - val_accuracy: 0.5254\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8444 - accuracy: 0.7091 - val_loss: 2.2293 - val_accuracy: 0.5193\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8455 - accuracy: 0.7008 - val_loss: 2.2512 - val_accuracy: 0.5036\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8886 - accuracy: 0.7029 - val_loss: 2.2100 - val_accuracy: 0.5205\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8362 - accuracy: 0.7122 - val_loss: 2.1289 - val_accuracy: 0.5097\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8160 - accuracy: 0.7122 - val_loss: 2.3446 - val_accuracy: 0.5254\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.8296 - accuracy: 0.7091 - val_loss: 2.1915 - val_accuracy: 0.5338\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8256 - accuracy: 0.7060 - val_loss: 2.2858 - val_accuracy: 0.5350\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.8116 - accuracy: 0.7164 - val_loss: 2.1918 - val_accuracy: 0.5266\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7862 - accuracy: 0.7195 - val_loss: 2.3047 - val_accuracy: 0.5399\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7909 - accuracy: 0.7236 - val_loss: 2.3242 - val_accuracy: 0.5145\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7761 - accuracy: 0.7350 - val_loss: 2.2756 - val_accuracy: 0.5024\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7540 - accuracy: 0.7396 - val_loss: 2.4233 - val_accuracy: 0.5338\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7312 - accuracy: 0.7376 - val_loss: 2.3827 - val_accuracy: 0.5326\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7493 - accuracy: 0.7402 - val_loss: 2.2171 - val_accuracy: 0.5242\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7452 - accuracy: 0.7448 - val_loss: 2.5775 - val_accuracy: 0.5085\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7500 - accuracy: 0.7417 - val_loss: 2.2388 - val_accuracy: 0.5386\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7109 - accuracy: 0.7443 - val_loss: 2.4954 - val_accuracy: 0.5145\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.7347 - accuracy: 0.7407 - val_loss: 2.5598 - val_accuracy: 0.5338\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7297 - accuracy: 0.7459 - val_loss: 2.5323 - val_accuracy: 0.5435\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6978 - accuracy: 0.7609 - val_loss: 2.6251 - val_accuracy: 0.5205\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6960 - accuracy: 0.7531 - val_loss: 2.5936 - val_accuracy: 0.5435\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.6847 - accuracy: 0.7614 - val_loss: 2.4615 - val_accuracy: 0.5338\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6648 - accuracy: 0.7697 - val_loss: 2.4331 - val_accuracy: 0.5133\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6939 - accuracy: 0.7541 - val_loss: 2.5501 - val_accuracy: 0.5326\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.7023 - accuracy: 0.7583 - val_loss: 2.6862 - val_accuracy: 0.5205\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6686 - accuracy: 0.7697 - val_loss: 2.4433 - val_accuracy: 0.5229\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6924 - accuracy: 0.7557 - val_loss: 2.4473 - val_accuracy: 0.5326\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6847 - accuracy: 0.7635 - val_loss: 2.3938 - val_accuracy: 0.5447\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6777 - accuracy: 0.7697 - val_loss: 2.3531 - val_accuracy: 0.5193\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6504 - accuracy: 0.7785 - val_loss: 2.6729 - val_accuracy: 0.5217\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6452 - accuracy: 0.7852 - val_loss: 2.6209 - val_accuracy: 0.5072\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6348 - accuracy: 0.7852 - val_loss: 2.5896 - val_accuracy: 0.5302\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6170 - accuracy: 0.7888 - val_loss: 2.5461 - val_accuracy: 0.5157\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6082 - accuracy: 0.7873 - val_loss: 2.7019 - val_accuracy: 0.5411\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6353 - accuracy: 0.7940 - val_loss: 2.5372 - val_accuracy: 0.5254\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6040 - accuracy: 0.7945 - val_loss: 2.5384 - val_accuracy: 0.5193\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5934 - accuracy: 0.7992 - val_loss: 2.6678 - val_accuracy: 0.5290\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6143 - accuracy: 0.7867 - val_loss: 2.6392 - val_accuracy: 0.5229\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.6195 - accuracy: 0.7873 - val_loss: 2.8649 - val_accuracy: 0.5471\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.6145 - accuracy: 0.7914 - val_loss: 2.7866 - val_accuracy: 0.5169\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.6032 - accuracy: 0.7935 - val_loss: 2.7970 - val_accuracy: 0.5254\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5726 - accuracy: 0.7966 - val_loss: 2.6996 - val_accuracy: 0.5266\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5559 - accuracy: 0.8069 - val_loss: 2.8125 - val_accuracy: 0.5242\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5538 - accuracy: 0.8100 - val_loss: 2.7374 - val_accuracy: 0.5193\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5673 - accuracy: 0.8111 - val_loss: 2.8036 - val_accuracy: 0.5326\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5464 - accuracy: 0.8126 - val_loss: 2.9280 - val_accuracy: 0.5447\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5694 - accuracy: 0.8033 - val_loss: 3.0114 - val_accuracy: 0.5338\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5332 - accuracy: 0.8225 - val_loss: 2.6997 - val_accuracy: 0.5290\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5260 - accuracy: 0.8225 - val_loss: 3.0751 - val_accuracy: 0.5242\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5481 - accuracy: 0.8142 - val_loss: 2.9539 - val_accuracy: 0.5133\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5501 - accuracy: 0.8178 - val_loss: 2.7995 - val_accuracy: 0.5181\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5386 - accuracy: 0.8131 - val_loss: 2.5509 - val_accuracy: 0.5121\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5267 - accuracy: 0.8219 - val_loss: 2.7742 - val_accuracy: 0.5302\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5257 - accuracy: 0.8307 - val_loss: 2.9228 - val_accuracy: 0.5302\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5350 - accuracy: 0.8137 - val_loss: 2.8183 - val_accuracy: 0.5205\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5475 - accuracy: 0.8204 - val_loss: 2.7037 - val_accuracy: 0.5290\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5125 - accuracy: 0.8328 - val_loss: 3.0115 - val_accuracy: 0.5386\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 3s 57ms/step - loss: 0.5120 - accuracy: 0.8183 - val_loss: 2.8394 - val_accuracy: 0.5085\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5065 - accuracy: 0.8292 - val_loss: 2.8374 - val_accuracy: 0.5229\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.4772 - accuracy: 0.8271 - val_loss: 3.1375 - val_accuracy: 0.5181\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5131 - accuracy: 0.8328 - val_loss: 3.0833 - val_accuracy: 0.5205\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 3s 55ms/step - loss: 0.5097 - accuracy: 0.8282 - val_loss: 2.8459 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 0.5044 - accuracy: 0.8318 - val_loss: 2.8745 - val_accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41887d32b0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 880)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 880, 100)          925700    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 880, 100)          0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32)                12864     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19)                627       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 939,191\n",
      "Trainable params: 939,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzd6af/.local/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(32, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.2)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(19, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.007, decay=.0008, centered=True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 28s 299ms/step - loss: 2.6432 - accuracy: 0.1912 - val_loss: 2.5375 - val_accuracy: 0.2386\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 25s 288ms/step - loss: 2.2968 - accuracy: 0.3337 - val_loss: 2.0177 - val_accuracy: 0.3886\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 26s 291ms/step - loss: 1.9653 - accuracy: 0.4193 - val_loss: 1.8154 - val_accuracy: 0.4482\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 25s 286ms/step - loss: 1.7679 - accuracy: 0.4815 - val_loss: 1.7174 - val_accuracy: 0.4905\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 25s 288ms/step - loss: 1.6293 - accuracy: 0.5206 - val_loss: 1.6145 - val_accuracy: 0.5153\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 25s 283ms/step - loss: 1.5103 - accuracy: 0.5561 - val_loss: 1.5879 - val_accuracy: 0.5178\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 25s 289ms/step - loss: 1.4226 - accuracy: 0.5718 - val_loss: 1.5211 - val_accuracy: 0.5534\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 26s 293ms/step - loss: 1.3085 - accuracy: 0.5995 - val_loss: 1.5419 - val_accuracy: 0.5460\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 25s 285ms/step - loss: 1.2576 - accuracy: 0.6187 - val_loss: 1.5095 - val_accuracy: 0.5650\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 24s 278ms/step - loss: 1.1616 - accuracy: 0.6429 - val_loss: 1.4892 - val_accuracy: 0.5700\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 25s 288ms/step - loss: 1.0891 - accuracy: 0.6588 - val_loss: 1.4939 - val_accuracy: 0.5708\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 25s 286ms/step - loss: 1.0340 - accuracy: 0.6830 - val_loss: 1.5502 - val_accuracy: 0.5592\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 24s 272ms/step - loss: 0.9621 - accuracy: 0.7079 - val_loss: 1.6074 - val_accuracy: 0.5485\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 24s 274ms/step - loss: 0.9204 - accuracy: 0.7079 - val_loss: 1.5770 - val_accuracy: 0.5609\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 24s 272ms/step - loss: 0.8558 - accuracy: 0.7257 - val_loss: 1.6038 - val_accuracy: 0.5601\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 26s 294ms/step - loss: 0.7955 - accuracy: 0.7488 - val_loss: 1.5975 - val_accuracy: 0.5675\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 25s 281ms/step - loss: 0.7536 - accuracy: 0.7651 - val_loss: 1.6521 - val_accuracy: 0.5510\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 25s 279ms/step - loss: 0.7073 - accuracy: 0.7779 - val_loss: 1.7106 - val_accuracy: 0.5601\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6821 - accuracy: 0.7889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-5ea1866fd44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1418\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1420\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1421\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 880)]             0         \n",
      "                                                                 \n",
      " embedding_9 (Embedding)     (None, 880, 100)          925700    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 880, 100)          0         \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 64)                31872     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 958,807\n",
      "Trainable params: 958,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.35)(embeddedsequences)\n",
    "#conv1 = Conv1D(filters=64,\n",
    "#               kernel_size=5,\n",
    "#               strides=1,\n",
    "#               activation='softplus',\n",
    "#               padding='same')(embeddedsequences)\n",
    "lstm1 = GRU(64, return_sequences=False)(y)\n",
    "#lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
    "#lstm3 = GRU(19)(lstm2)\n",
    "#x = Flatten()(lstm2)\n",
    "x = Dropout(.35)(lstm1)\n",
    "#x = Dense(25, activation = 'softplus')(lstm2)\n",
    "#x = Dropout(.2)(x)\n",
    "output_layer = Dense(19, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.005, decay=.0008, centered = True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 [==============================] - 94s 261ms/step - loss: 2.5274 - sparse_top_k_categorical_accuracy: 0.5057 - val_loss: 2.0911 - val_sparse_top_k_categorical_accuracy: 0.6247\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 2.0542 - sparse_top_k_categorical_accuracy: 0.6485 - val_loss: 1.8773 - val_sparse_top_k_categorical_accuracy: 0.6885\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 1.8230 - sparse_top_k_categorical_accuracy: 0.6944 - val_loss: 1.6556 - val_sparse_top_k_categorical_accuracy: 0.7332\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 1.6400 - sparse_top_k_categorical_accuracy: 0.7434 - val_loss: 1.5777 - val_sparse_top_k_categorical_accuracy: 0.7581\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 96s 272ms/step - loss: 1.5243 - sparse_top_k_categorical_accuracy: 0.7733 - val_loss: 1.4617 - val_sparse_top_k_categorical_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 1.4194 - sparse_top_k_categorical_accuracy: 0.7971 - val_loss: 1.4207 - val_sparse_top_k_categorical_accuracy: 0.7912\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 1.3449 - sparse_top_k_categorical_accuracy: 0.8216 - val_loss: 1.4142 - val_sparse_top_k_categorical_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 95s 270ms/step - loss: 1.2827 - sparse_top_k_categorical_accuracy: 0.8234 - val_loss: 1.3817 - val_sparse_top_k_categorical_accuracy: 0.8028\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 95s 269ms/step - loss: 1.2289 - sparse_top_k_categorical_accuracy: 0.8337 - val_loss: 1.3729 - val_sparse_top_k_categorical_accuracy: 0.8111\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 95s 271ms/step - loss: 1.1704 - sparse_top_k_categorical_accuracy: 0.8454 - val_loss: 1.3874 - val_sparse_top_k_categorical_accuracy: 0.8111\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 93s 265ms/step - loss: 1.1082 - sparse_top_k_categorical_accuracy: 0.8600 - val_loss: 1.3951 - val_sparse_top_k_categorical_accuracy: 0.8094\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 1.0573 - sparse_top_k_categorical_accuracy: 0.8660 - val_loss: 1.4087 - val_sparse_top_k_categorical_accuracy: 0.8152\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 1.0315 - sparse_top_k_categorical_accuracy: 0.8795 - val_loss: 1.3828 - val_sparse_top_k_categorical_accuracy: 0.8194\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.9790 - sparse_top_k_categorical_accuracy: 0.8820 - val_loss: 1.3853 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.9404 - sparse_top_k_categorical_accuracy: 0.8959 - val_loss: 1.3853 - val_sparse_top_k_categorical_accuracy: 0.8169\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.9340 - sparse_top_k_categorical_accuracy: 0.8973 - val_loss: 1.4279 - val_sparse_top_k_categorical_accuracy: 0.8186\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 91s 260ms/step - loss: 0.8876 - sparse_top_k_categorical_accuracy: 0.8984 - val_loss: 1.4392 - val_sparse_top_k_categorical_accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 92s 263ms/step - loss: 0.8531 - sparse_top_k_categorical_accuracy: 0.9080 - val_loss: 1.4393 - val_sparse_top_k_categorical_accuracy: 0.8260\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 96s 272ms/step - loss: 0.8282 - sparse_top_k_categorical_accuracy: 0.9119 - val_loss: 1.4265 - val_sparse_top_k_categorical_accuracy: 0.8268\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.8170 - sparse_top_k_categorical_accuracy: 0.9094 - val_loss: 1.4708 - val_sparse_top_k_categorical_accuracy: 0.8210\n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.7747 - sparse_top_k_categorical_accuracy: 0.9172 - val_loss: 1.4463 - val_sparse_top_k_categorical_accuracy: 0.8268\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 95s 270ms/step - loss: 0.7517 - sparse_top_k_categorical_accuracy: 0.9193 - val_loss: 1.5004 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.7454 - sparse_top_k_categorical_accuracy: 0.9325 - val_loss: 1.4870 - val_sparse_top_k_categorical_accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 94s 267ms/step - loss: 0.7521 - sparse_top_k_categorical_accuracy: 0.9247 - val_loss: 1.4721 - val_sparse_top_k_categorical_accuracy: 0.8244\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.6869 - sparse_top_k_categorical_accuracy: 0.9364 - val_loss: 1.5367 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 96s 273ms/step - loss: 0.6904 - sparse_top_k_categorical_accuracy: 0.9350 - val_loss: 1.5360 - val_sparse_top_k_categorical_accuracy: 0.8260\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.6535 - sparse_top_k_categorical_accuracy: 0.9367 - val_loss: 1.5488 - val_sparse_top_k_categorical_accuracy: 0.8169\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 93s 264ms/step - loss: 0.6460 - sparse_top_k_categorical_accuracy: 0.9378 - val_loss: 1.5701 - val_sparse_top_k_categorical_accuracy: 0.8219\n",
      "Epoch 29/100\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.6258 - sparse_top_k_categorical_accuracy: 0.9435 - val_loss: 1.5538 - val_sparse_top_k_categorical_accuracy: 0.8210\n",
      "Epoch 30/100\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.6072 - sparse_top_k_categorical_accuracy: 0.9428 - val_loss: 1.6035 - val_sparse_top_k_categorical_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.5934 - sparse_top_k_categorical_accuracy: 0.9421 - val_loss: 1.6080 - val_sparse_top_k_categorical_accuracy: 0.8252\n",
      "Epoch 32/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.5759 - sparse_top_k_categorical_accuracy: 0.9460"
     ]
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 880)]             0         \n",
      "                                                                 \n",
      " embedding_47 (Embedding)    (None, 880, 100)          733700    \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 880, 100)          0         \n",
      "                                                                 \n",
      " conv1d_155 (Conv1D)         (None, 880, 64)           32064     \n",
      "                                                                 \n",
      " max_pooling1d_76 (MaxPoolin  (None, 176, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " gru_38 (GRU)                (None, 32)                9408      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 25)                825       \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 19)                494       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 776,491\n",
      "Trainable params: 776,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "embedding_layer = Embedding(len(word_index) + 1, embeddingdim, embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length=maxlength, trainable = True)\n",
    "sequence_input = Input(shape=(maxlength,), dtype='int32')\n",
    "embeddedsequences = embedding_layer(sequence_input)\n",
    "y = Dropout(0.3)(embeddedsequences)\n",
    "conv1 = Conv1D(filters=64,\n",
    "               kernel_size=5,\n",
    "               strides=1,\n",
    "               activation='softplus',\n",
    "               padding='same')(y)\n",
    "x = MaxPooling1D(5)(conv1)\n",
    "#x = GRU(128, return_sequences=True)(x)\n",
    "#lstm1 = GRU(64, return_sequences=True)(x)\n",
    "lstm2 = GRU(32)(x)\n",
    "x = Flatten()(lstm2)\n",
    "x = Dropout(.3)(x)\n",
    "x = Dense(25, activation = 'softplus')(lstm2)\n",
    "x = Dropout(.2)(x)\n",
    "output_layer = Dense(19, activation='softmax')(x)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=.01, decay=.008, centered=True)\n",
    "model = Model(sequence_input, output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 8s 93ms/step - loss: 2.5949 - accuracy: 0.2464 - val_loss: 2.4962 - val_accuracy: 0.2802\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 2.5004 - accuracy: 0.2681 - val_loss: 2.3404 - val_accuracy: 0.2802\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 2.2940 - accuracy: 0.2966 - val_loss: 2.1310 - val_accuracy: 0.3309\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 2.1026 - accuracy: 0.3701 - val_loss: 1.9592 - val_accuracy: 0.4384\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.9492 - accuracy: 0.4027 - val_loss: 1.9536 - val_accuracy: 0.3708\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.8361 - accuracy: 0.4322 - val_loss: 1.8164 - val_accuracy: 0.4529\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.7831 - accuracy: 0.4420 - val_loss: 1.8469 - val_accuracy: 0.4215\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.7078 - accuracy: 0.4664 - val_loss: 1.7478 - val_accuracy: 0.4505\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.6347 - accuracy: 0.4886 - val_loss: 1.7235 - val_accuracy: 0.4758\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.5844 - accuracy: 0.5052 - val_loss: 1.7156 - val_accuracy: 0.4807\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.5071 - accuracy: 0.5295 - val_loss: 1.7362 - val_accuracy: 0.4758\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.4821 - accuracy: 0.5274 - val_loss: 1.6873 - val_accuracy: 0.4722\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.4226 - accuracy: 0.5326 - val_loss: 1.7354 - val_accuracy: 0.4589\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.3964 - accuracy: 0.5352 - val_loss: 1.7519 - val_accuracy: 0.4529\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.3743 - accuracy: 0.5657 - val_loss: 1.7511 - val_accuracy: 0.4722\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.3208 - accuracy: 0.5637 - val_loss: 1.7030 - val_accuracy: 0.4746\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.2886 - accuracy: 0.5782 - val_loss: 1.6838 - val_accuracy: 0.4807\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.2685 - accuracy: 0.5864 - val_loss: 1.7062 - val_accuracy: 0.4783\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.2313 - accuracy: 0.5973 - val_loss: 1.7116 - val_accuracy: 0.4662\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1791 - accuracy: 0.6035 - val_loss: 1.7134 - val_accuracy: 0.5024\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1885 - accuracy: 0.6051 - val_loss: 1.7311 - val_accuracy: 0.5085\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.1474 - accuracy: 0.6123 - val_loss: 1.7464 - val_accuracy: 0.4976\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1278 - accuracy: 0.6232 - val_loss: 1.7445 - val_accuracy: 0.5229\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.1091 - accuracy: 0.6304 - val_loss: 1.7956 - val_accuracy: 0.5145\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0858 - accuracy: 0.6351 - val_loss: 1.7629 - val_accuracy: 0.5169\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0636 - accuracy: 0.6403 - val_loss: 1.7847 - val_accuracy: 0.5254\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0553 - accuracy: 0.6403 - val_loss: 1.7724 - val_accuracy: 0.5060\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0354 - accuracy: 0.6589 - val_loss: 1.7901 - val_accuracy: 0.5133\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.0193 - accuracy: 0.6599 - val_loss: 1.7862 - val_accuracy: 0.5266\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 1.0058 - accuracy: 0.6729 - val_loss: 1.8010 - val_accuracy: 0.5145\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9834 - accuracy: 0.6687 - val_loss: 1.8142 - val_accuracy: 0.5205\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9701 - accuracy: 0.6713 - val_loss: 1.8145 - val_accuracy: 0.5229\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9591 - accuracy: 0.6801 - val_loss: 1.8069 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.9454 - accuracy: 0.6894 - val_loss: 1.8313 - val_accuracy: 0.5217\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.9426 - accuracy: 0.6749 - val_loss: 1.8662 - val_accuracy: 0.5169\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.9400 - accuracy: 0.6801 - val_loss: 1.8860 - val_accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.9148 - accuracy: 0.6946 - val_loss: 1.8532 - val_accuracy: 0.5048\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.8936 - accuracy: 0.6967 - val_loss: 1.8755 - val_accuracy: 0.5072\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8978 - accuracy: 0.7008 - val_loss: 1.9088 - val_accuracy: 0.5133\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 5s 89ms/step - loss: 0.8908 - accuracy: 0.7029 - val_loss: 1.9784 - val_accuracy: 0.5193\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8467 - accuracy: 0.7200 - val_loss: 1.9003 - val_accuracy: 0.5097\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8613 - accuracy: 0.7112 - val_loss: 1.9439 - val_accuracy: 0.4903\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8401 - accuracy: 0.7164 - val_loss: 1.9203 - val_accuracy: 0.5036\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8448 - accuracy: 0.7179 - val_loss: 1.9173 - val_accuracy: 0.5024\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8306 - accuracy: 0.7262 - val_loss: 1.9547 - val_accuracy: 0.5121\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8071 - accuracy: 0.7329 - val_loss: 2.0185 - val_accuracy: 0.5302\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.8097 - accuracy: 0.7236 - val_loss: 1.9943 - val_accuracy: 0.5217\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7805 - accuracy: 0.7371 - val_loss: 2.0075 - val_accuracy: 0.5133\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8069 - accuracy: 0.7319 - val_loss: 2.0982 - val_accuracy: 0.5193\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.7958 - accuracy: 0.7350 - val_loss: 1.9832 - val_accuracy: 0.5072\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7935 - accuracy: 0.7334 - val_loss: 2.0065 - val_accuracy: 0.5121\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7680 - accuracy: 0.7360 - val_loss: 2.0158 - val_accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7710 - accuracy: 0.7324 - val_loss: 2.0036 - val_accuracy: 0.5024\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7831 - accuracy: 0.7350 - val_loss: 2.0191 - val_accuracy: 0.4976\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7551 - accuracy: 0.7495 - val_loss: 2.0443 - val_accuracy: 0.5181\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7369 - accuracy: 0.7547 - val_loss: 2.0775 - val_accuracy: 0.5097\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7296 - accuracy: 0.7598 - val_loss: 2.0721 - val_accuracy: 0.5109\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7191 - accuracy: 0.7629 - val_loss: 2.1017 - val_accuracy: 0.4988\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7053 - accuracy: 0.7598 - val_loss: 2.0827 - val_accuracy: 0.5205\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7327 - accuracy: 0.7598 - val_loss: 2.0984 - val_accuracy: 0.5229\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7039 - accuracy: 0.7635 - val_loss: 2.0736 - val_accuracy: 0.5060\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7002 - accuracy: 0.7697 - val_loss: 2.1503 - val_accuracy: 0.5133\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6867 - accuracy: 0.7686 - val_loss: 2.1141 - val_accuracy: 0.5157\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6891 - accuracy: 0.7738 - val_loss: 2.1361 - val_accuracy: 0.5254\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6914 - accuracy: 0.7676 - val_loss: 2.1893 - val_accuracy: 0.5048\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6994 - accuracy: 0.7754 - val_loss: 2.1630 - val_accuracy: 0.5205\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.7125 - accuracy: 0.7598 - val_loss: 2.1377 - val_accuracy: 0.5157\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6687 - accuracy: 0.7764 - val_loss: 2.1403 - val_accuracy: 0.5109\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6619 - accuracy: 0.7836 - val_loss: 2.1675 - val_accuracy: 0.5121\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6720 - accuracy: 0.7774 - val_loss: 2.1554 - val_accuracy: 0.5157\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6654 - accuracy: 0.7790 - val_loss: 2.1775 - val_accuracy: 0.5193\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6320 - accuracy: 0.7955 - val_loss: 2.1686 - val_accuracy: 0.5109\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6333 - accuracy: 0.7842 - val_loss: 2.2219 - val_accuracy: 0.5314\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6330 - accuracy: 0.7847 - val_loss: 2.2013 - val_accuracy: 0.5314\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6367 - accuracy: 0.7867 - val_loss: 2.2452 - val_accuracy: 0.5181\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6336 - accuracy: 0.7800 - val_loss: 2.2365 - val_accuracy: 0.5205\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6215 - accuracy: 0.7945 - val_loss: 2.2594 - val_accuracy: 0.5157\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6347 - accuracy: 0.7919 - val_loss: 2.2492 - val_accuracy: 0.5169\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6486 - accuracy: 0.7748 - val_loss: 2.2870 - val_accuracy: 0.5217\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6334 - accuracy: 0.7930 - val_loss: 2.2525 - val_accuracy: 0.5242\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6281 - accuracy: 0.7873 - val_loss: 2.3356 - val_accuracy: 0.5048\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6212 - accuracy: 0.8043 - val_loss: 2.2567 - val_accuracy: 0.5133\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6082 - accuracy: 0.8038 - val_loss: 2.3658 - val_accuracy: 0.5157\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6066 - accuracy: 0.8059 - val_loss: 2.2928 - val_accuracy: 0.5181\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.6284 - accuracy: 0.7842 - val_loss: 2.3505 - val_accuracy: 0.5109\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6245 - accuracy: 0.7981 - val_loss: 2.2692 - val_accuracy: 0.5121\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.6036 - accuracy: 0.8028 - val_loss: 2.3103 - val_accuracy: 0.5205\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5886 - accuracy: 0.7940 - val_loss: 2.3923 - val_accuracy: 0.5109\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5747 - accuracy: 0.8121 - val_loss: 2.3057 - val_accuracy: 0.5133\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5574 - accuracy: 0.8188 - val_loss: 2.3466 - val_accuracy: 0.5290\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5684 - accuracy: 0.8137 - val_loss: 2.3323 - val_accuracy: 0.5205\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5689 - accuracy: 0.8085 - val_loss: 2.3653 - val_accuracy: 0.5145\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.5557 - accuracy: 0.8116 - val_loss: 2.4121 - val_accuracy: 0.5205\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5772 - accuracy: 0.8121 - val_loss: 2.4116 - val_accuracy: 0.5169\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5738 - accuracy: 0.8116 - val_loss: 2.3635 - val_accuracy: 0.5217\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5631 - accuracy: 0.8157 - val_loss: 2.3268 - val_accuracy: 0.5157\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.5838 - accuracy: 0.8090 - val_loss: 2.3874 - val_accuracy: 0.5181\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.5628 - accuracy: 0.8173 - val_loss: 2.4396 - val_accuracy: 0.5254\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 0.5888 - accuracy: 0.8054 - val_loss: 2.3745 - val_accuracy: 0.5121\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.5668 - accuracy: 0.8204 - val_loss: 2.4050 - val_accuracy: 0.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f42b1003a30>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, ytrain, validation_data=(paddedtest, ytest), epochs=100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
